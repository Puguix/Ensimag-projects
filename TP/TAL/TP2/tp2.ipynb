{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TP2: Traduction automatique</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: OpenNMT-py in /home/puguix/.local/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: configargparse in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (1.7)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from OpenNMT-py) (1.16.0)\n",
      "Requirement already satisfied: flask in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (3.0.2)\n",
      "Requirement already satisfied: tensorboard>=2.3 in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (2.16.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from OpenNMT-py) (5.4.1)\n",
      "Requirement already satisfied: sacrebleu in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (2.4.0)\n",
      "Requirement already satisfied: pyonmttok<2,>=1.35 in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (1.37.1)\n",
      "Requirement already satisfied: ctranslate2<5,>=3.24 in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (4.0.0)\n",
      "Requirement already satisfied: waitress in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (3.0.0)\n",
      "Requirement already satisfied: pyahocorasick in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (2.0.0)\n",
      "Requirement already satisfied: fasttext-wheel in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (0.9.2)\n",
      "Requirement already satisfied: spacy in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (3.7.4)\n",
      "Requirement already satisfied: rapidfuzz in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (3.6.2)\n",
      "Requirement already satisfied: torch<2.3,>=2.0.1 in /home/puguix/.local/lib/python3.10/site-packages (from OpenNMT-py) (2.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=3.24->OpenNMT-py) (1.26.2)\n",
      "Requirement already satisfied: setuptools in /home/puguix/.local/lib/python3.10/site-packages (from ctranslate2<5,>=3.24->OpenNMT-py) (65.5.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/puguix/.local/lib/python3.10/site-packages (from tensorboard>=2.3->OpenNMT-py) (2.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.3.6)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/puguix/.local/lib/python3.10/site-packages (from tensorboard>=2.3->OpenNMT-py) (1.62.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/puguix/.local/lib/python3.10/site-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/puguix/.local/lib/python3.10/site-packages (from tensorboard>=2.3->OpenNMT-py) (4.25.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/puguix/.local/lib/python3.10/site-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (10.3.2.106)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (11.4.5.107)\n",
      "Requirement already satisfied: fsspec in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (2.19.3)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (2.2.0)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (1.9)\n",
      "Requirement already satisfied: jinja2 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (3.1.3)\n",
      "Requirement already satisfied: filelock in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/puguix/.local/lib/python3.10/site-packages (from torch<2.3,>=2.0.1->OpenNMT-py) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/puguix/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.0.1->OpenNMT-py) (12.4.99)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/puguix/.local/lib/python3.10/site-packages (from fasttext-wheel->OpenNMT-py) (2.11.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/puguix/.local/lib/python3.10/site-packages (from flask->OpenNMT-py) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/puguix/.local/lib/python3.10/site-packages (from flask->OpenNMT-py) (1.7.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/puguix/.local/lib/python3.10/site-packages (from flask->OpenNMT-py) (8.1.7)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.3)\n",
      "Requirement already satisfied: portalocker in /home/puguix/.local/lib/python3.10/site-packages (from sacrebleu->OpenNMT-py) (2.8.2)\n",
      "Requirement already satisfied: regex in /home/puguix/.local/lib/python3.10/site-packages (from sacrebleu->OpenNMT-py) (2022.3.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/puguix/.local/lib/python3.10/site-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from sacrebleu->OpenNMT-py) (0.4.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (2.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (1.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (23.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (6.4.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (8.2.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (2.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (4.65.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (1.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (3.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (0.9.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (0.3.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.31.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/puguix/.local/lib/python3.10/site-packages (from spacy->OpenNMT-py) (2.0.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/puguix/.local/lib/python3.10/site-packages (from jinja2->torch<2.3,>=2.0.1->OpenNMT-py) (2.1.5)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /home/puguix/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (2.16.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/puguix/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (0.6.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/puguix/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2.1.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/puguix/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy->OpenNMT-py) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/puguix/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy->OpenNMT-py) (0.7.11)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/puguix/.local/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy->OpenNMT-py) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install OpenNMT-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**:  les fichiers IWSLT10_BTEC.train.en.txt et IWSLT10_BTEC.train.fr.txt contiennent les mêmes phrases, l'une en anglais et l'autre en français."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 1\n",
      "Tokenizer Version 1.1\n",
      "Language: fr\n",
      "Number of threads: 1\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 1\n",
      "Tokenizer Version 1.1\n",
      "Language: fr\n",
      "Number of threads: 1\n",
      "Tokenizer Version 1.1\n",
      "Language: fr\n",
      "Number of threads: 1\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk -F '\\' '{print $NF}' ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt > ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.clean.txt\n",
    "awk -F '\\' '{print $NF}' ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt > ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.clean.txt\n",
    "awk -F '\\' '{print $NF}' ./BTEC-en-fr/train/IWSLT10_BTEC.train.en.txt > ./BTEC-en-fr/train/IWSLT10_BTEC.train.en.clean.txt\n",
    "awk -F '\\' '{print $NF}' ./BTEC-en-fr/train/IWSLT10_BTEC.train.fr.txt > ./BTEC-en-fr/train/IWSLT10_BTEC.train.fr.clean.txt\n",
    "awk -F '\\' '{print $NF}' ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.txt > ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.clean.txt\n",
    "awk -F '\\' '{print $NF}' ./BTEC-en-fr/test/IWSLT09_BTEC.testset.en.txt > ./BTEC-en-fr/test/IWSLT09_BTEC.testset.en.clean.txt\n",
    "\n",
    "perl tokenizer.perl -l en -lc < ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.clean.txt > ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.tok.txt\n",
    "perl tokenizer.perl -l fr -lc < ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.clean.txt > ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.tok.txt\n",
    "perl tokenizer.perl -l en -lc < ./BTEC-en-fr/train/IWSLT10_BTEC.train.en.clean.txt > ./BTEC-en-fr/train/IWSLT10_BTEC.train.en.tok.txt\n",
    "perl tokenizer.perl -l fr -lc < ./BTEC-en-fr/train/IWSLT10_BTEC.train.fr.clean.txt > ./BTEC-en-fr/train/IWSLT10_BTEC.train.fr.tok.txt\n",
    "perl tokenizer.perl -l fr -lc < ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.clean.txt > ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt\n",
    "perl tokenizer.perl -l en -lc < ./BTEC-en-fr/test/IWSLT09_BTEC.testset.en.clean.txt > ./BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - Create directory for models and predictions - -\n",
    "mkdir models\n",
    "mkdir models/base\n",
    "mkdir BTEC-en-fr/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Des espaces ont été ajoutés entre les mots et les points. Les apostrophes ont été remplacés par &apos;. L'intérêt de l'opération effectué est d'avoir des fichiers plus lisible par le programme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: L'ensemble train est utilisé pour former le modèle. L'ensemble de test est ensuite utilisé pour évaluer ses performances. L'ensemble développement est utilisé pour évaluer les performances finales du modèle, après que les étapes d'entraînement et de test aient été effectuées. Il simule les conditions du monde réel et mesure la capacité du modèle à généraliser sur de nouvelles données qu'il n'a pas vues auparavant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Un système de TA a besoin d'un vocabulaire pour segmenter les textes en tokens afin de faciliter la construction du modèle et réduire la complexité du modèle. On utilise pas un vocabulaire universel parce qu'on veut s'adapter à nos données, réduire la dimension du vocabulaire, et avoir un modèle plus spécialisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2024-03-11 09:41:01,055 INFO] Counter vocab from -1 samples.\n",
      "[2024-03-11 09:41:01,055 INFO] n_sample=-1: Build vocab on full datasets.\n",
      "[2024-03-11 09:41:01,406 INFO] Counters src: 9978\n",
      "[2024-03-11 09:41:01,406 INFO] Counters tgt: 8194\n"
     ]
    }
   ],
   "source": [
    "!onmt_build_vocab -config config-base.yaml -n_sample -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**: Ces nombres nous indiquent le nombre de tokens uniques dans le corpus source (src) et dans le corpus cible (tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 09:50:23,398 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2024-03-11 09:50:23,398 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2024-03-11 09:50:23,398 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2024-03-11 09:50:23,398 INFO] Parsed 2 corpora from -data.\n",
      "[2024-03-11 09:50:23,398 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2024-03-11 09:50:23,420 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '.', '?', 'de', ',', 'vous', 'Je']\n",
      "[2024-03-11 09:50:23,420 INFO] The decoder start token is: <s>\n",
      "[2024-03-11 09:50:23,420 INFO] Building model...\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 09:50:23,909 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2024-03-11 09:50:23,909 INFO] Non quantized layer compute is fp32\n",
      "[2024-03-11 09:50:23,909 INFO] NMTModel(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(9984, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (rnn): LSTM(500, 250, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): InputFeedRNNDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(8200, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(1000, 500)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=500, out_features=8200, bias=True)\n",
      ")\n",
      "[2024-03-11 09:50:23,910 INFO] encoder: 6496000\n",
      "[2024-03-11 09:50:23,910 INFO] decoder: 11212200\n",
      "[2024-03-11 09:50:23,910 INFO] * number of parameters: 17708200\n",
      "[2024-03-11 09:50:23,910 INFO] Trainable parameters = {'torch.float32': 17708200, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 09:50:23,910 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 09:50:23,910 INFO]  * src vocab size = 9984\n",
      "[2024-03-11 09:50:23,910 INFO]  * tgt vocab size = 8200\n",
      "[2024-03-11 09:50:24,212 INFO] Starting training on CPU, could be very slow\n",
      "[2024-03-11 09:50:24,212 INFO] Start training loop and validate every 625 steps...\n",
      "[2024-03-11 09:50:24,213 INFO] Scoring with: TransformPipe()\n",
      "[2024-03-11 09:50:26,001 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 09:50:27,773 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 09:50:27,866 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 09:50:27,889 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 09:50:28,102 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 09:50:28,120 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 09:50:28,354 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 09:50:28,379 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 09:50:28,494 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 09:50:28,504 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 09:50:28,808 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 09:50:28,818 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 09:50:28,938 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 09:50:28,956 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 09:50:29,378 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 09:50:29,386 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 09:50:29,512 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 09:50:29,520 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 09:50:29,640 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 09:50:29,650 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 09:50:30,080 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 09:50:30,097 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 09:50:30,198 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 09:50:30,213 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 09:50:30,325 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 09:50:30,338 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 09:50:30,825 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 09:50:30,825 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 09:50:30,940 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 09:50:30,945 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 09:50:31,064 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 09:50:31,076 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 09:50:31,189 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 09:50:31,196 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 09:50:31,778 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 09:50:31,786 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 09:50:31,904 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 09:50:31,904 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 09:50:32,021 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 09:50:32,022 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 09:50:32,143 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 09:50:32,145 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 09:50:32,258 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 09:50:32,262 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 09:50:32,976 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 09:50:32,981 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 09:50:33,093 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 09:50:33,105 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 09:50:33,231 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 09:50:33,240 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 09:50:33,349 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 09:50:33,371 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 09:50:33,475 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 09:50:33,493 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 09:50:45,080 INFO] Step 20/ 2000; acc: 10.1; ppl: 2519.2; xent: 7.8; lr: 1.00000; sents:     640; bsz:  282/ 304/32; 270/291 tok/s;     21 sec;\n",
      "[2024-03-11 09:50:48,039 INFO] Step 40/ 2000; acc: 19.5; ppl: 300.9; xent: 5.7; lr: 1.00000; sents:     640; bsz:  235/ 253/32; 1590/1709 tok/s;     24 sec;\n",
      "[2024-03-11 09:50:51,301 INFO] Step 60/ 2000; acc: 20.8; ppl: 228.5; xent: 5.4; lr: 1.00000; sents:     640; bsz:  267/ 288/32; 1639/1766 tok/s;     27 sec;\n",
      "[2024-03-11 09:50:54,781 INFO] Step 80/ 2000; acc: 21.7; ppl: 184.6; xent: 5.2; lr: 1.00000; sents:     640; bsz:  288/ 309/32; 1655/1775 tok/s;     31 sec;\n",
      "[2024-03-11 09:50:58,331 INFO] Step 100/ 2000; acc: 22.2; ppl: 173.8; xent: 5.2; lr: 1.00000; sents:     640; bsz:  306/ 338/32; 1722/1903 tok/s;     34 sec;\n",
      "[2024-03-11 09:51:02,125 INFO] Step 120/ 2000; acc: 22.7; ppl: 166.6; xent: 5.1; lr: 1.00000; sents:     640; bsz:  334/ 365/32; 1763/1923 tok/s;     38 sec;\n",
      "[2024-03-11 09:51:05,607 INFO] Step 140/ 2000; acc: 32.4; ppl:  95.0; xent: 4.6; lr: 1.00000; sents:     640; bsz:  285/ 288/32; 1636/1655 tok/s;     41 sec;\n",
      "[2024-03-11 09:51:09,737 INFO] Step 160/ 2000; acc: 26.6; ppl: 117.2; xent: 4.8; lr: 1.00000; sents:     640; bsz:  358/ 366/32; 1736/1774 tok/s;     46 sec;\n",
      "[2024-03-11 09:51:13,680 INFO] Step 180/ 2000; acc: 33.6; ppl:  77.5; xent: 4.3; lr: 1.00000; sents:     640; bsz:  264/ 282/32; 1339/1428 tok/s;     49 sec;\n",
      "[2024-03-11 09:51:17,239 INFO] Step 200/ 2000; acc: 34.7; ppl:  73.0; xent: 4.3; lr: 1.00000; sents:     640; bsz:  256/ 272/32; 1439/1529 tok/s;     53 sec;\n",
      "[2024-03-11 09:51:20,399 INFO] Step 220/ 2000; acc: 41.0; ppl:  48.9; xent: 3.9; lr: 1.00000; sents:     640; bsz:  226/ 251/32; 1428/1590 tok/s;     56 sec;\n",
      "[2024-03-11 09:51:24,835 INFO] Step 240/ 2000; acc: 31.4; ppl:  79.9; xent: 4.4; lr: 1.00000; sents:     640; bsz:  357/ 362/32; 1609/1631 tok/s;     61 sec;\n",
      "[2024-03-11 09:51:28,855 INFO] Step 260/ 2000; acc: 33.3; ppl:  71.6; xent: 4.3; lr: 1.00000; sents:     640; bsz:  334/ 349/32; 1664/1735 tok/s;     65 sec;\n",
      "[2024-03-11 09:51:32,190 INFO] Step 280/ 2000; acc: 39.0; ppl:  48.9; xent: 3.9; lr: 1.00000; sents:     640; bsz:  248/ 275/32; 1487/1650 tok/s;     68 sec;\n",
      "[2024-03-11 09:51:36,179 INFO] Step 300/ 2000; acc: 34.0; ppl:  71.2; xent: 4.3; lr: 1.00000; sents:     640; bsz:  335/ 332/32; 1682/1664 tok/s;     72 sec;\n",
      "[2024-03-11 09:51:39,708 INFO] Step 320/ 2000; acc: 39.5; ppl:  46.2; xent: 3.8; lr: 1.00000; sents:     640; bsz:  274/ 293/32; 1551/1660 tok/s;     75 sec;\n",
      "[2024-03-11 09:51:43,159 INFO] Step 340/ 2000; acc: 34.8; ppl:  57.7; xent: 4.1; lr: 1.00000; sents:     640; bsz:  318/ 322/32; 1846/1864 tok/s;     79 sec;\n",
      "[2024-03-11 09:51:46,733 INFO] Step 360/ 2000; acc: 34.0; ppl:  57.1; xent: 4.0; lr: 1.00000; sents:     640; bsz:  326/ 352/32; 1827/1970 tok/s;     83 sec;\n",
      "[2024-03-11 09:51:49,927 INFO] Step 380/ 2000; acc: 40.0; ppl:  44.0; xent: 3.8; lr: 1.00000; sents:     640; bsz:  277/ 286/32; 1733/1794 tok/s;     86 sec;\n",
      "[2024-03-11 09:51:52,978 INFO] Step 400/ 2000; acc: 40.5; ppl:  43.1; xent: 3.8; lr: 1.00000; sents:     640; bsz:  262/ 290/32; 1720/1899 tok/s;     89 sec;\n",
      "[2024-03-11 09:51:56,262 INFO] Step 420/ 2000; acc: 40.0; ppl:  45.3; xent: 3.8; lr: 1.00000; sents:     640; bsz:  278/ 283/32; 1695/1724 tok/s;     92 sec;\n",
      "[2024-03-11 09:52:00,231 INFO] Step 440/ 2000; acc: 45.4; ppl:  30.6; xent: 3.4; lr: 1.00000; sents:     640; bsz:  226/ 262/32; 1137/1323 tok/s;     96 sec;\n",
      "[2024-03-11 09:52:04,108 INFO] Step 460/ 2000; acc: 40.2; ppl:  43.4; xent: 3.8; lr: 1.00000; sents:     640; bsz:  304/ 309/32; 1568/1593 tok/s;    100 sec;\n",
      "[2024-03-11 09:52:06,936 INFO] Step 480/ 2000; acc: 42.3; ppl:  37.3; xent: 3.6; lr: 1.00000; sents:     640; bsz:  230/ 258/32; 1630/1822 tok/s;    103 sec;\n",
      "[2024-03-11 09:52:10,544 INFO] Step 500/ 2000; acc: 42.2; ppl:  36.1; xent: 3.6; lr: 1.00000; sents:     640; bsz:  278/ 302/32; 1543/1676 tok/s;    106 sec;\n",
      "[2024-03-11 09:52:14,065 INFO] Step 520/ 2000; acc: 40.2; ppl:  41.0; xent: 3.7; lr: 1.00000; sents:     640; bsz:  286/ 311/32; 1627/1767 tok/s;    110 sec;\n",
      "[2024-03-11 09:52:17,603 INFO] Step 540/ 2000; acc: 42.5; ppl:  35.8; xent: 3.6; lr: 1.00000; sents:     640; bsz:  282/ 292/32; 1592/1649 tok/s;    113 sec;\n",
      "[2024-03-11 09:52:20,656 INFO] Step 560/ 2000; acc: 46.6; ppl:  27.2; xent: 3.3; lr: 1.00000; sents:     640; bsz:  242/ 270/32; 1583/1771 tok/s;    116 sec;\n",
      "[2024-03-11 09:52:23,633 INFO] Step 580/ 2000; acc: 46.1; ppl:  27.7; xent: 3.3; lr: 1.00000; sents:     640; bsz:  240/ 275/32; 1613/1849 tok/s;    119 sec;\n",
      "[2024-03-11 09:52:26,498 INFO] Step 600/ 2000; acc: 46.5; ppl:  24.3; xent: 3.2; lr: 1.00000; sents:     640; bsz:  205/ 259/32; 1429/1807 tok/s;    122 sec;\n",
      "[2024-03-11 09:52:29,689 INFO] Step 620/ 2000; acc: 44.0; ppl:  28.3; xent: 3.3; lr: 1.00000; sents:     640; bsz:  277/ 299/32; 1735/1876 tok/s;    125 sec;\n",
      "[2024-03-11 09:52:37,130 INFO] valid stats calculation\n",
      "                           took: 6.71524977684021 s.\n",
      "[2024-03-11 09:52:37,131 INFO] Train perplexity: 70.4377\n",
      "[2024-03-11 09:52:37,131 INFO] Train accuracy: 34.7547\n",
      "[2024-03-11 09:52:37,131 INFO] Sentences processed: 20000\n",
      "[2024-03-11 09:52:37,131 INFO] Average bsz:  280/ 300/32\n",
      "[2024-03-11 09:52:37,131 INFO] Validation perplexity: 22.7192\n",
      "[2024-03-11 09:52:37,131 INFO] Validation accuracy: 49.4205\n",
      "[2024-03-11 09:52:37,132 INFO] Saving checkpoint ./models/base/model_step_625.pt\n",
      "[2024-03-11 09:52:40,385 INFO] Step 640/ 2000; acc: 42.5; ppl:  33.6; xent: 3.5; lr: 1.00000; sents:     640; bsz:  293/ 301/32; 547/562 tok/s;    136 sec;\n",
      "[2024-03-11 09:52:44,292 INFO] Step 660/ 2000; acc: 42.7; ppl:  31.3; xent: 3.4; lr: 1.00000; sents:     640; bsz:  310/ 322/32; 1589/1647 tok/s;    140 sec;\n",
      "[2024-03-11 09:52:47,852 INFO] Step 680/ 2000; acc: 45.2; ppl:  28.3; xent: 3.3; lr: 1.00000; sents:     640; bsz:  262/ 298/32; 1474/1672 tok/s;    144 sec;\n",
      "[2024-03-11 09:52:51,467 INFO] Step 700/ 2000; acc: 46.2; ppl:  25.5; xent: 3.2; lr: 1.00000; sents:     640; bsz:  288/ 299/32; 1594/1656 tok/s;    147 sec;\n",
      "[2024-03-11 09:52:55,217 INFO] Step 720/ 2000; acc: 45.5; ppl:  28.2; xent: 3.3; lr: 1.00000; sents:     640; bsz:  286/ 309/32; 1528/1647 tok/s;    151 sec;\n",
      "[2024-03-11 09:52:59,067 INFO] Step 740/ 2000; acc: 43.9; ppl:  27.4; xent: 3.3; lr: 1.00000; sents:     640; bsz:  293/ 339/32; 1521/1762 tok/s;    155 sec;\n",
      "[2024-03-11 09:53:02,398 INFO] Step 760/ 2000; acc: 48.5; ppl:  22.5; xent: 3.1; lr: 1.00000; sents:     640; bsz:  275/ 275/32; 1653/1649 tok/s;    158 sec;\n",
      "[2024-03-11 09:53:05,608 INFO] Step 780/ 2000; acc: 47.9; ppl:  22.8; xent: 3.1; lr: 1.00000; sents:     640; bsz:  246/ 278/32; 1535/1734 tok/s;    161 sec;\n",
      "[2024-03-11 09:53:09,299 INFO] Step 800/ 2000; acc: 43.9; ppl:  30.4; xent: 3.4; lr: 1.00000; sents:     640; bsz:  330/ 330/32; 1787/1790 tok/s;    165 sec;\n",
      "[2024-03-11 09:53:13,275 INFO] Step 820/ 2000; acc: 44.2; ppl:  29.0; xent: 3.4; lr: 1.00000; sents:     640; bsz:  299/ 313/32; 1506/1572 tok/s;    169 sec;\n",
      "[2024-03-11 09:53:16,616 INFO] Step 840/ 2000; acc: 49.9; ppl:  22.3; xent: 3.1; lr: 1.00000; sents:     640; bsz:  274/ 278/32; 1638/1667 tok/s;    172 sec;\n",
      "[2024-03-11 09:53:20,004 INFO] Step 860/ 2000; acc: 50.7; ppl:  18.7; xent: 2.9; lr: 1.00000; sents:     640; bsz:  269/ 275/32; 1587/1625 tok/s;    176 sec;\n",
      "[2024-03-11 09:53:23,974 INFO] Step 880/ 2000; acc: 43.9; ppl:  27.7; xent: 3.3; lr: 1.00000; sents:     640; bsz:  346/ 357/32; 1741/1798 tok/s;    180 sec;\n",
      "[2024-03-11 09:53:27,422 INFO] Step 900/ 2000; acc: 52.0; ppl:  17.2; xent: 2.8; lr: 1.00000; sents:     640; bsz:  248/ 269/32; 1438/1559 tok/s;    183 sec;\n",
      "[2024-03-11 09:53:31,180 INFO] Step 920/ 2000; acc: 46.8; ppl:  24.7; xent: 3.2; lr: 1.00000; sents:     640; bsz:  322/ 327/32; 1712/1741 tok/s;    187 sec;\n",
      "[2024-03-11 09:53:34,707 INFO] Step 940/ 2000; acc: 48.3; ppl:  23.2; xent: 3.1; lr: 1.00000; sents:     640; bsz:  274/ 282/32; 1552/1599 tok/s;    190 sec;\n",
      "[2024-03-11 09:53:38,089 INFO] Step 960/ 2000; acc: 51.1; ppl:  17.8; xent: 2.9; lr: 1.00000; sents:     640; bsz:  250/ 293/32; 1476/1732 tok/s;    194 sec;\n",
      "[2024-03-11 09:53:41,802 INFO] Step 980/ 2000; acc: 48.0; ppl:  21.2; xent: 3.1; lr: 1.00000; sents:     640; bsz:  314/ 321/32; 1689/1728 tok/s;    198 sec;\n",
      "[2024-03-11 09:53:45,219 INFO] Step 1000/ 2000; acc: 49.5; ppl:  19.8; xent: 3.0; lr: 1.00000; sents:     640; bsz:  286/ 306/32; 1677/1789 tok/s;    201 sec;\n",
      "[2024-03-11 09:53:48,538 INFO] Step 1020/ 2000; acc: 51.2; ppl:  17.9; xent: 2.9; lr: 1.00000; sents:     640; bsz:  266/ 280/32; 1601/1690 tok/s;    204 sec;\n",
      "[2024-03-11 09:53:52,522 INFO] Step 1040/ 2000; acc: 48.3; ppl:  21.4; xent: 3.1; lr: 1.00000; sents:     640; bsz:  302/ 338/32; 1518/1695 tok/s;    208 sec;\n",
      "[2024-03-11 09:53:55,901 INFO] Step 1060/ 2000; acc: 50.2; ppl:  18.0; xent: 2.9; lr: 1.00000; sents:     640; bsz:  266/ 302/32; 1573/1790 tok/s;    212 sec;\n",
      "[2024-03-11 09:53:59,354 INFO] Step 1080/ 2000; acc: 49.5; ppl:  19.6; xent: 3.0; lr: 1.00000; sents:     640; bsz:  277/ 301/32; 1604/1743 tok/s;    215 sec;\n",
      "[2024-03-11 09:54:02,975 INFO] Step 1100/ 2000; acc: 49.0; ppl:  19.5; xent: 3.0; lr: 1.00000; sents:     640; bsz:  275/ 317/32; 1520/1750 tok/s;    219 sec;\n",
      "[2024-03-11 09:54:06,678 INFO] Step 1120/ 2000; acc: 48.5; ppl:  20.9; xent: 3.0; lr: 1.00000; sents:     640; bsz:  318/ 322/32; 1720/1737 tok/s;    222 sec;\n",
      "[2024-03-11 09:54:10,599 INFO] Step 1140/ 2000; acc: 47.5; ppl:  22.4; xent: 3.1; lr: 1.00000; sents:     640; bsz:  330/ 349/32; 1681/1779 tok/s;    226 sec;\n",
      "[2024-03-11 09:54:14,589 INFO] Step 1160/ 2000; acc: 45.4; ppl:  25.3; xent: 3.2; lr: 1.00000; sents:     640; bsz:  328/ 349/32; 1644/1749 tok/s;    230 sec;\n",
      "[2024-03-11 09:54:17,905 INFO] Step 1180/ 2000; acc: 50.3; ppl:  18.1; xent: 2.9; lr: 1.00000; sents:     640; bsz:  272/ 288/32; 1640/1737 tok/s;    234 sec;\n",
      "[2024-03-11 09:54:21,296 INFO] Step 1200/ 2000; acc: 50.1; ppl:  17.3; xent: 2.8; lr: 1.00000; sents:     640; bsz:  286/ 300/32; 1689/1770 tok/s;    237 sec;\n",
      "[2024-03-11 09:54:24,812 INFO] Step 1220/ 2000; acc: 51.0; ppl:  18.2; xent: 2.9; lr: 1.00000; sents:     640; bsz:  274/ 293/32; 1557/1666 tok/s;    241 sec;\n",
      "[2024-03-11 09:54:28,320 INFO] Step 1240/ 2000; acc: 53.2; ppl:  15.0; xent: 2.7; lr: 1.00000; sents:     640; bsz:  282/ 282/32; 1606/1606 tok/s;    244 sec;\n",
      "[2024-03-11 09:54:35,986 INFO] valid stats calculation\n",
      "                           took: 6.08138632774353 s.\n",
      "[2024-03-11 09:54:35,986 INFO] Train perplexity: 39.3548\n",
      "[2024-03-11 09:54:35,986 INFO] Train accuracy: 41.3797\n",
      "[2024-03-11 09:54:35,986 INFO] Sentences processed: 40000\n",
      "[2024-03-11 09:54:35,986 INFO] Average bsz:  284/ 303/32\n",
      "[2024-03-11 09:54:35,986 INFO] Validation perplexity: 13.7013\n",
      "[2024-03-11 09:54:35,986 INFO] Validation accuracy: 55.1692\n",
      "[2024-03-11 09:54:35,988 INFO] Saving checkpoint ./models/base/model_step_1250.pt\n",
      "[2024-03-11 09:54:37,782 INFO] Step 1260/ 2000; acc: 53.9; ppl:  14.8; xent: 2.7; lr: 1.00000; sents:     640; bsz:  274/ 278/32; 578/588 tok/s;    254 sec;\n",
      "[2024-03-11 09:54:41,303 INFO] Step 1280/ 2000; acc: 53.0; ppl:  15.2; xent: 2.7; lr: 1.00000; sents:     640; bsz:  277/ 291/32; 1572/1654 tok/s;    257 sec;\n",
      "[2024-03-11 09:54:45,033 INFO] Step 1300/ 2000; acc: 52.2; ppl:  15.2; xent: 2.7; lr: 1.00000; sents:     640; bsz:  266/ 317/32; 1424/1699 tok/s;    261 sec;\n",
      "[2024-03-11 09:54:49,419 INFO] Step 1320/ 2000; acc: 49.8; ppl:  19.2; xent: 3.0; lr: 1.00000; sents:     640; bsz:  302/ 310/32; 1379/1412 tok/s;    265 sec;\n",
      "[2024-03-11 09:54:53,390 INFO] Step 1340/ 2000; acc: 53.4; ppl:  14.8; xent: 2.7; lr: 1.00000; sents:     640; bsz:  253/ 290/32; 1273/1458 tok/s;    269 sec;\n",
      "[2024-03-11 09:54:56,731 INFO] Step 1360/ 2000; acc: 53.6; ppl:  13.8; xent: 2.6; lr: 1.00000; sents:     640; bsz:  250/ 284/32; 1494/1700 tok/s;    273 sec;\n",
      "[2024-03-11 09:55:00,459 INFO] Step 1380/ 2000; acc: 53.0; ppl:  15.1; xent: 2.7; lr: 1.00000; sents:     640; bsz:  288/ 296/32; 1545/1586 tok/s;    276 sec;\n",
      "[2024-03-11 09:55:03,898 INFO] Step 1400/ 2000; acc: 55.1; ppl:  13.1; xent: 2.6; lr: 1.00000; sents:     640; bsz:  251/ 282/32; 1461/1638 tok/s;    280 sec;\n",
      "[2024-03-11 09:55:07,744 INFO] Step 1420/ 2000; acc: 52.6; ppl:  14.3; xent: 2.7; lr: 1.00000; sents:     640; bsz:  280/ 299/32; 1456/1556 tok/s;    284 sec;\n",
      "[2024-03-11 09:55:12,022 INFO] Step 1440/ 2000; acc: 51.8; ppl:  15.3; xent: 2.7; lr: 1.00000; sents:     640; bsz:  285/ 318/32; 1332/1489 tok/s;    288 sec;\n",
      "[2024-03-11 09:55:15,872 INFO] Step 1460/ 2000; acc: 52.8; ppl:  15.7; xent: 2.8; lr: 1.00000; sents:     640; bsz:  293/ 294/32; 1521/1529 tok/s;    292 sec;\n",
      "[2024-03-11 09:55:21,005 INFO] Step 1480/ 2000; acc: 45.7; ppl:  26.0; xent: 3.3; lr: 1.00000; sents:     640; bsz:  356/ 366/32; 1388/1427 tok/s;    297 sec;\n",
      "[2024-03-11 09:55:25,148 INFO] Step 1500/ 2000; acc: 51.6; ppl:  15.8; xent: 2.8; lr: 1.00000; sents:     640; bsz:  296/ 318/32; 1429/1536 tok/s;    301 sec;\n",
      "[2024-03-11 09:55:29,783 INFO] Step 1520/ 2000; acc: 50.8; ppl:  16.1; xent: 2.8; lr: 1.00000; sents:     640; bsz:  323/ 346/32; 1395/1494 tok/s;    306 sec;\n",
      "[2024-03-11 09:55:34,045 INFO] Step 1540/ 2000; acc: 53.4; ppl:  13.4; xent: 2.6; lr: 1.00000; sents:     640; bsz:  286/ 320/32; 1344/1502 tok/s;    310 sec;\n",
      "[2024-03-11 09:55:37,594 INFO] Step 1560/ 2000; acc: 57.2; ppl:  11.8; xent: 2.5; lr: 1.00000; sents:     640; bsz:  264/ 271/32; 1486/1529 tok/s;    313 sec;\n",
      "[2024-03-11 09:55:42,131 INFO] Step 1580/ 2000; acc: 52.4; ppl:  13.8; xent: 2.6; lr: 1.00000; sents:     640; bsz:  304/ 335/32; 1340/1475 tok/s;    318 sec;\n",
      "[2024-03-11 09:55:45,978 INFO] Step 1600/ 2000; acc: 56.4; ppl:  11.9; xent: 2.5; lr: 1.00000; sents:     640; bsz:  238/ 266/32; 1240/1381 tok/s;    322 sec;\n",
      "[2024-03-11 09:55:50,264 INFO] Step 1620/ 2000; acc: 53.0; ppl:  14.2; xent: 2.6; lr: 1.00000; sents:     640; bsz:  296/ 294/32; 1381/1374 tok/s;    326 sec;\n",
      "[2024-03-11 09:55:54,503 INFO] Step 1640/ 2000; acc: 55.0; ppl:  12.8; xent: 2.5; lr: 1.00000; sents:     640; bsz:  270/ 291/32; 1276/1374 tok/s;    330 sec;\n",
      "[2024-03-11 09:55:59,396 INFO] Step 1660/ 2000; acc: 50.2; ppl:  16.6; xent: 2.8; lr: 1.00000; sents:     640; bsz:  362/ 360/32; 1478/1472 tok/s;    335 sec;\n",
      "[2024-03-11 09:56:04,322 INFO] Step 1680/ 2000; acc: 52.6; ppl:  13.2; xent: 2.6; lr: 1.00000; sents:     640; bsz:  347/ 365/32; 1410/1481 tok/s;    340 sec;\n",
      "[2024-03-11 09:56:08,979 INFO] Step 1700/ 2000; acc: 54.6; ppl:  12.9; xent: 2.6; lr: 1.00000; sents:     640; bsz:  297/ 303/32; 1277/1301 tok/s;    345 sec;\n",
      "[2024-03-11 09:56:12,919 INFO] Step 1720/ 2000; acc: 54.9; ppl:  13.6; xent: 2.6; lr: 1.00000; sents:     640; bsz:  264/ 291/32; 1340/1478 tok/s;    349 sec;\n",
      "[2024-03-11 09:56:16,488 INFO] Step 1740/ 2000; acc: 57.1; ppl:  11.2; xent: 2.4; lr: 1.00000; sents:     640; bsz:  227/ 264/32; 1273/1480 tok/s;    352 sec;\n",
      "[2024-03-11 09:56:20,252 INFO] Step 1760/ 2000; acc: 56.7; ppl:  11.3; xent: 2.4; lr: 1.00000; sents:     640; bsz:  251/ 275/32; 1335/1462 tok/s;    356 sec;\n",
      "[2024-03-11 09:56:24,868 INFO] Step 1780/ 2000; acc: 52.0; ppl:  13.8; xent: 2.6; lr: 1.00000; sents:     640; bsz:  328/ 339/32; 1421/1471 tok/s;    361 sec;\n",
      "[2024-03-11 09:56:28,974 INFO] Step 1800/ 2000; acc: 56.7; ppl:  11.9; xent: 2.5; lr: 1.00000; sents:     640; bsz:  294/ 304/32; 1434/1481 tok/s;    365 sec;\n",
      "[2024-03-11 09:56:33,265 INFO] Step 1820/ 2000; acc: 54.3; ppl:  12.4; xent: 2.5; lr: 1.00000; sents:     640; bsz:  328/ 322/32; 1529/1502 tok/s;    369 sec;\n",
      "[2024-03-11 09:56:36,939 INFO] Step 1840/ 2000; acc: 59.9; ppl:   9.3; xent: 2.2; lr: 1.00000; sents:     640; bsz:  282/ 290/32; 1533/1577 tok/s;    373 sec;\n",
      "[2024-03-11 09:56:40,254 INFO] Step 1860/ 2000; acc: 57.3; ppl:  10.3; xent: 2.3; lr: 1.00000; sents:     640; bsz:  240/ 266/32; 1448/1603 tok/s;    376 sec;\n",
      "[2024-03-11 09:56:50,862 INFO] valid stats calculation\n",
      "                           took: 7.580870151519775 s.\n",
      "[2024-03-11 09:56:50,862 INFO] Train perplexity: 27.8131\n",
      "[2024-03-11 09:56:50,862 INFO] Train accuracy: 45.4382\n",
      "[2024-03-11 09:56:50,863 INFO] Sentences processed: 60000\n",
      "[2024-03-11 09:56:50,863 INFO] Average bsz:  285/ 304/32\n",
      "[2024-03-11 09:56:50,863 INFO] Validation perplexity: 10.585\n",
      "[2024-03-11 09:56:50,863 INFO] Validation accuracy: 58.8317\n",
      "[2024-03-11 09:56:50,864 INFO] Saving checkpoint ./models/base/model_step_1875.pt\n",
      "[2024-03-11 09:56:52,293 INFO] Step 1880/ 2000; acc: 54.9; ppl:  11.4; xent: 2.4; lr: 1.00000; sents:     640; bsz:  325/ 323/32; 540/537 tok/s;    388 sec;\n",
      "[2024-03-11 09:56:56,865 INFO] Step 1900/ 2000; acc: 55.2; ppl:  11.0; xent: 2.4; lr: 1.00000; sents:     640; bsz:  278/ 310/32; 1218/1358 tok/s;    393 sec;\n",
      "[2024-03-11 09:57:00,709 INFO] Step 1920/ 2000; acc: 58.0; ppl:   9.9; xent: 2.3; lr: 1.00000; sents:     640; bsz:  238/ 277/32; 1241/1441 tok/s;    396 sec;\n",
      "[2024-03-11 09:57:03,851 INFO] Step 1940/ 2000; acc: 61.5; ppl:   8.3; xent: 2.1; lr: 1.00000; sents:     640; bsz:  243/ 253/32; 1548/1609 tok/s;    400 sec;\n",
      "[2024-03-11 09:57:06,866 INFO] Step 1960/ 2000; acc: 59.3; ppl:   9.4; xent: 2.2; lr: 1.00000; sents:     640; bsz:  256/ 277/32; 1698/1836 tok/s;    403 sec;\n",
      "[2024-03-11 09:57:10,313 INFO] Step 1980/ 2000; acc: 57.7; ppl:   9.4; xent: 2.2; lr: 1.00000; sents:     640; bsz:  272/ 312/32; 1579/1811 tok/s;    406 sec;\n",
      "[2024-03-11 09:57:13,453 INFO] Step 2000/ 2000; acc: 58.9; ppl:   8.9; xent: 2.2; lr: 1.00000; sents:     640; bsz:  253/ 296/32; 1610/1885 tok/s;    409 sec;\n",
      "[2024-03-11 09:57:15,065 INFO] Saving checkpoint ./models/base/model_step_2000.pt\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config config-base.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**:  \n",
    "acc correspond à l'accuracy, plus cette valeur est élevée, mieux c'est car le modèle est donc plus précis dans ses prédictions.  \n",
    "ppl correspond à la perplexity, plus cette valeur est faible, mieux c'est car cela signifie que le modèle a une meilleure compréhension des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**:  \n",
    "train_step: nombre d'étapes d'entrainement  \n",
    "valid_step: fréquence à laquelle l'évaluation sur les données de validation est effectuée  \n",
    "enc_layers: nombre de couches dans l'encodeur  \n",
    "dec_layers: nombre de couches dans le décodeur  \n",
    "enc_rnn_size: nombre de neuronnes par couche dans l'encodeur  \n",
    "dec_rnn_size: nombre de neuronnes par couche dans le décodeur  \n",
    "batch_size: nombre de données utilisées par pas d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 10:30:12,782 INFO] Loading checkpoint from ./models/base/model_step_625.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 10:30:13,070 INFO] Loading data into the model\n",
      "[2024-03-11 10:30:14,932 INFO] PRED SCORE: -0.8312, PRED PPL: 2.30 NB SENTENCES: 469\n",
      "Time w/o python interpreter load/terminate:  2.1559011936187744\n",
      "[2024-03-11 10:30:17,250 INFO] Loading checkpoint from ./models/base/model_step_1250.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 10:30:17,535 INFO] Loading data into the model\n",
      "[2024-03-11 10:30:19,578 INFO] PRED SCORE: -0.7194, PRED PPL: 2.05 NB SENTENCES: 469\n",
      "Time w/o python interpreter load/terminate:  2.334038257598877\n",
      "[2024-03-11 10:30:21,887 INFO] Loading checkpoint from ./models/base/model_step_1875.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 10:30:22,179 INFO] Loading data into the model\n",
      "[2024-03-11 10:30:24,343 INFO] PRED SCORE: -0.6348, PRED PPL: 1.89 NB SENTENCES: 469\n",
      "Time w/o python interpreter load/terminate:  2.4634475708007812\n",
      "[2024-03-11 10:30:26,699 INFO] Loading checkpoint from ./models/base/model_step_2000.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 10:30:27,016 INFO] Loading data into the model\n",
      "[2024-03-11 10:30:29,202 INFO] PRED SCORE: -0.6165, PRED PPL: 1.85 NB SENTENCES: 469\n",
      "Time w/o python interpreter load/terminate:  2.5108392238616943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!onmt_translate -model ./models/base/model_step_625.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_625.txt\n",
    "!onmt_translate -model ./models/base/model_step_1250.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_1250.txt\n",
    "!onmt_translate -model ./models/base/model_step_1875.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_1875.txt\n",
    "!onmt_translate -model ./models/base/model_step_2000.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_2000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8**:  \n",
    "Phrase à traduire: Pouvez-vous nettoyer ma chambre ?  \n",
    "Traduction model 625: Can you tell me how ?  \n",
    "Traduction model 1250: Can you keep my baggage ?  \n",
    "Traduction model 1875: Can you change my room?  \n",
    "Traduction model 2000: Could you keep my room ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**:  \n",
    "Un score BLEU est compris entre 0 et 100. Il faut un score le plus proche de 100 possible. Un score de 100 indique une traduction parfaite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 10.09, 49.3/18.1/10.3/3.5 (BP=0.752, ratio=0.778, hyp_len=2780, ref_len=3574)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 14.35, 51.2/21.2/12.6/5.8 (BP=0.857, ratio=0.866, hyp_len=3095, ref_len=3574)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 19.17, 55.0/25.5/16.1/8.6 (BP=0.912, ratio=0.916, hyp_len=3274, ref_len=3574)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 20.93, 54.0/26.3/17.0/9.4 (BP=0.957, ratio=0.958, hyp_len=3425, ref_len=3574)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_625.txt\n",
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_1250.txt\n",
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_1875.txt\n",
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_2000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**: Le modèle ayant le meilleur score BLEU est le modèle le plus entrainé (modèle 2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 10:42:20,385 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2024-03-11 10:42:20,385 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2024-03-11 10:42:20,385 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2024-03-11 10:42:20,385 INFO] Parsed 2 corpora from -data.\n",
      "[2024-03-11 10:42:20,385 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2024-03-11 10:42:20,407 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '.', '?', 'de', ',', 'vous', 'Je']\n",
      "[2024-03-11 10:42:20,408 INFO] The decoder start token is: <s>\n",
      "[2024-03-11 10:42:20,408 INFO] Building model...\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 10:42:20,743 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2024-03-11 10:42:20,743 INFO] Non quantized layer compute is fp32\n",
      "[2024-03-11 10:42:20,743 INFO] NMTModel(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(9984, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (rnn): LSTM(500, 250, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): InputFeedRNNDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(8200, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(1000, 500)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=500, out_features=8200, bias=True)\n",
      ")\n",
      "[2024-03-11 10:42:20,744 INFO] encoder: 6496000\n",
      "[2024-03-11 10:42:20,744 INFO] decoder: 11212200\n",
      "[2024-03-11 10:42:20,744 INFO] * number of parameters: 17708200\n",
      "[2024-03-11 10:42:20,744 INFO] Trainable parameters = {'torch.float32': 17708200, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 10:42:20,744 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 10:42:20,744 INFO]  * src vocab size = 9984\n",
      "[2024-03-11 10:42:20,744 INFO]  * tgt vocab size = 8200\n",
      "[2024-03-11 10:42:21,075 INFO] Starting training on CPU, could be very slow\n",
      "[2024-03-11 10:42:21,075 INFO] Start training loop and validate every 500 steps...\n",
      "[2024-03-11 10:42:21,075 INFO] Scoring with: TransformPipe()\n",
      "[2024-03-11 10:42:22,892 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 10:42:24,557 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 10:42:24,688 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 10:42:24,689 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 10:42:24,918 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 10:42:24,919 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 10:42:25,169 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 10:42:25,172 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 10:42:25,294 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 10:42:25,300 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 10:42:25,600 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 10:42:25,603 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 10:42:25,717 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 10:42:25,720 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 10:42:26,080 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 10:42:26,085 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 10:42:26,198 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 10:42:26,202 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 10:42:26,312 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 10:42:26,317 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 10:42:26,721 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 10:42:26,727 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 10:42:26,835 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 10:42:26,841 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 10:42:26,950 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 10:42:26,958 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 10:42:27,431 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 10:42:27,436 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 10:42:27,545 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 10:42:27,549 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 10:42:27,662 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 10:42:27,665 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 10:42:27,777 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 10:42:27,781 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 10:42:28,360 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 10:42:28,360 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 10:42:28,474 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 10:42:28,475 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 10:42:28,589 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 10:42:28,590 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 10:42:28,706 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 10:42:28,707 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 10:42:28,825 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 10:42:28,827 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 10:42:29,517 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 10:42:29,518 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 10:42:29,633 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 10:42:29,637 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 10:42:29,750 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 10:42:29,755 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 10:42:29,873 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 10:42:29,876 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 10:42:29,996 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 10:42:30,005 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 10:42:41,047 INFO] Step 20/50000; acc: 9.8; ppl: 2886.9; xent: 8.0; lr: 1.00000; sents:     640; bsz:  266/ 294/32; 266/295 tok/s;     20 sec;\n",
      "[2024-03-11 10:42:44,287 INFO] Step 40/50000; acc: 15.1; ppl: 443.9; xent: 6.1; lr: 1.00000; sents:     640; bsz:  304/ 309/32; 1877/1906 tok/s;     23 sec;\n",
      "[2024-03-11 10:42:47,306 INFO] Step 60/50000; acc: 21.8; ppl: 218.7; xent: 5.4; lr: 1.00000; sents:     640; bsz:  242/ 262/32; 1601/1739 tok/s;     26 sec;\n",
      "[2024-03-11 10:42:50,757 INFO] Step 80/50000; acc: 24.1; ppl: 172.5; xent: 5.2; lr: 1.00000; sents:     640; bsz:  269/ 283/32; 1558/1640 tok/s;     30 sec;\n",
      "[2024-03-11 10:42:54,064 INFO] Step 100/50000; acc: 23.5; ppl: 153.2; xent: 5.0; lr: 1.00000; sents:     640; bsz:  322/ 323/32; 1945/1955 tok/s;     33 sec;\n",
      "[2024-03-11 10:42:57,504 INFO] Step 120/50000; acc: 27.4; ppl: 118.8; xent: 4.8; lr: 1.00000; sents:     640; bsz:  261/ 282/32; 1516/1637 tok/s;     36 sec;\n",
      "[2024-03-11 10:43:00,772 INFO] Step 140/50000; acc: 30.5; ppl:  89.1; xent: 4.5; lr: 1.00000; sents:     640; bsz:  242/ 277/32; 1479/1695 tok/s;     40 sec;\n",
      "[2024-03-11 10:43:04,282 INFO] Step 160/50000; acc: 29.7; ppl: 105.5; xent: 4.7; lr: 1.00000; sents:     640; bsz:  317/ 310/32; 1805/1769 tok/s;     43 sec;\n",
      "[2024-03-11 10:43:08,368 INFO] Step 180/50000; acc: 30.1; ppl:  98.2; xent: 4.6; lr: 1.00000; sents:     640; bsz:  299/ 320/32; 1465/1566 tok/s;     47 sec;\n",
      "[2024-03-11 10:43:12,233 INFO] Step 200/50000; acc: 32.1; ppl:  82.9; xent: 4.4; lr: 1.00000; sents:     640; bsz:  288/ 302/32; 1491/1565 tok/s;     51 sec;\n",
      "[2024-03-11 10:43:15,885 INFO] Step 220/50000; acc: 29.7; ppl: 106.8; xent: 4.7; lr: 1.00000; sents:     640; bsz:  250/ 272/32; 1369/1492 tok/s;     55 sec;\n",
      "[2024-03-11 10:43:19,903 INFO] Step 240/50000; acc: 32.2; ppl:  83.5; xent: 4.4; lr: 1.00000; sents:     640; bsz:  309/ 323/32; 1540/1606 tok/s;     59 sec;\n",
      "[2024-03-11 10:43:23,728 INFO] Step 260/50000; acc: 36.4; ppl:  61.8; xent: 4.1; lr: 1.00000; sents:     640; bsz:  277/ 291/32; 1448/1523 tok/s;     63 sec;\n",
      "[2024-03-11 10:43:27,310 INFO] Step 280/50000; acc: 34.8; ppl:  61.7; xent: 4.1; lr: 1.00000; sents:     640; bsz:  301/ 312/32; 1680/1742 tok/s;     66 sec;\n",
      "[2024-03-11 10:43:31,080 INFO] Step 300/50000; acc: 36.8; ppl:  53.9; xent: 4.0; lr: 1.00000; sents:     640; bsz:  266/ 293/32; 1409/1553 tok/s;     70 sec;\n",
      "[2024-03-11 10:43:34,993 INFO] Step 320/50000; acc: 38.7; ppl:  54.6; xent: 4.0; lr: 1.00000; sents:     640; bsz:  278/ 290/32; 1423/1483 tok/s;     74 sec;\n",
      "[2024-03-11 10:43:39,373 INFO] Step 340/50000; acc: 35.7; ppl:  58.6; xent: 4.1; lr: 1.00000; sents:     640; bsz:  320/ 333/32; 1461/1521 tok/s;     78 sec;\n",
      "[2024-03-11 10:43:43,218 INFO] Step 360/50000; acc: 35.3; ppl:  53.9; xent: 4.0; lr: 1.00000; sents:     640; bsz:  302/ 322/32; 1573/1673 tok/s;     82 sec;\n",
      "[2024-03-11 10:43:46,827 INFO] Step 380/50000; acc: 40.9; ppl:  40.6; xent: 3.7; lr: 1.00000; sents:     640; bsz:  246/ 286/32; 1366/1587 tok/s;     86 sec;\n",
      "[2024-03-11 10:43:50,765 INFO] Step 400/50000; acc: 37.8; ppl:  50.2; xent: 3.9; lr: 1.00000; sents:     640; bsz:  282/ 306/32; 1430/1556 tok/s;     90 sec;\n",
      "[2024-03-11 10:43:54,705 INFO] Step 420/50000; acc: 37.7; ppl:  51.0; xent: 3.9; lr: 1.00000; sents:     640; bsz:  323/ 314/32; 1641/1592 tok/s;     94 sec;\n",
      "[2024-03-11 10:43:59,159 INFO] Step 440/50000; acc: 36.2; ppl:  53.9; xent: 4.0; lr: 1.00000; sents:     640; bsz:  333/ 353/32; 1495/1584 tok/s;     98 sec;\n",
      "[2024-03-11 10:44:02,582 INFO] Step 460/50000; acc: 46.4; ppl:  29.4; xent: 3.4; lr: 1.00000; sents:     640; bsz:  206/ 245/32; 1206/1431 tok/s;    102 sec;\n",
      "[2024-03-11 10:44:06,723 INFO] Step 480/50000; acc: 41.6; ppl:  38.6; xent: 3.7; lr: 1.00000; sents:     640; bsz:  283/ 307/32; 1368/1484 tok/s;    106 sec;\n",
      "[2024-03-11 10:44:10,250 INFO] Step 500/50000; acc: 40.0; ppl:  38.6; xent: 3.7; lr: 1.00000; sents:     640; bsz:  277/ 309/32; 1570/1751 tok/s;    109 sec;\n",
      "[2024-03-11 10:44:16,468 INFO] valid stats calculation\n",
      "                           took: 6.217205762863159 s.\n",
      "[2024-03-11 10:44:16,474 INFO] Train perplexity: 88.3752\n",
      "[2024-03-11 10:44:16,474 INFO] Train accuracy: 32.1796\n",
      "[2024-03-11 10:44:16,474 INFO] Sentences processed: 16000\n",
      "[2024-03-11 10:44:16,474 INFO] Average bsz:  282/ 301/32\n",
      "[2024-03-11 10:44:16,474 INFO] Validation perplexity: 27.0869\n",
      "[2024-03-11 10:44:16,474 INFO] Validation accuracy: 46.268\n",
      "[2024-03-11 10:44:16,474 INFO] Model is improving ppl: inf --> 27.0869.\n",
      "[2024-03-11 10:44:16,474 INFO] Model is improving acc: -inf --> 46.268.\n",
      "[2024-03-11 10:44:19,749 INFO] Step 520/50000; acc: 42.9; ppl:  35.3; xent: 3.6; lr: 1.00000; sents:     640; bsz:  278/ 283/32; 586/596 tok/s;    119 sec;\n",
      "[2024-03-11 10:44:23,042 INFO] Step 540/50000; acc: 42.3; ppl:  36.2; xent: 3.6; lr: 1.00000; sents:     640; bsz:  254/ 285/32; 1545/1730 tok/s;    122 sec;\n",
      "[2024-03-11 10:44:26,454 INFO] Step 560/50000; acc: 42.1; ppl:  35.8; xent: 3.6; lr: 1.00000; sents:     640; bsz:  266/ 296/32; 1557/1738 tok/s;    125 sec;\n",
      "[2024-03-11 10:44:29,920 INFO] Step 580/50000; acc: 44.0; ppl:  31.3; xent: 3.4; lr: 1.00000; sents:     640; bsz:  258/ 290/32; 1487/1671 tok/s;    129 sec;\n",
      "[2024-03-11 10:44:33,805 INFO] Step 600/50000; acc: 43.5; ppl:  32.4; xent: 3.5; lr: 1.00000; sents:     640; bsz:  294/ 302/32; 1515/1557 tok/s;    133 sec;\n",
      "[2024-03-11 10:44:37,274 INFO] Step 620/50000; acc: 48.5; ppl:  24.3; xent: 3.2; lr: 1.00000; sents:     640; bsz:  242/ 261/32; 1393/1504 tok/s;    136 sec;\n",
      "[2024-03-11 10:44:41,250 INFO] Step 640/50000; acc: 46.5; ppl:  24.0; xent: 3.2; lr: 1.00000; sents:     640; bsz:  254/ 304/32; 1280/1529 tok/s;    140 sec;\n",
      "[2024-03-11 10:44:44,992 INFO] Step 660/50000; acc: 46.0; ppl:  28.2; xent: 3.3; lr: 1.00000; sents:     640; bsz:  283/ 290/32; 1514/1548 tok/s;    144 sec;\n",
      "[2024-03-11 10:44:48,872 INFO] Step 680/50000; acc: 44.4; ppl:  30.9; xent: 3.4; lr: 1.00000; sents:     640; bsz:  282/ 290/32; 1452/1493 tok/s;    148 sec;\n",
      "[2024-03-11 10:44:51,951 INFO] Step 700/50000; acc: 50.8; ppl:  20.5; xent: 3.0; lr: 1.00000; sents:     640; bsz:  235/ 247/32; 1528/1605 tok/s;    151 sec;\n",
      "[2024-03-11 10:44:55,514 INFO] Step 720/50000; acc: 43.4; ppl:  30.4; xent: 3.4; lr: 1.00000; sents:     640; bsz:  288/ 328/32; 1617/1838 tok/s;    154 sec;\n",
      "[2024-03-11 10:44:59,219 INFO] Step 740/50000; acc: 42.6; ppl:  31.4; xent: 3.4; lr: 1.00000; sents:     640; bsz:  317/ 322/32; 1710/1736 tok/s;    158 sec;\n",
      "[2024-03-11 10:45:02,233 INFO] Step 760/50000; acc: 48.3; ppl:  25.2; xent: 3.2; lr: 1.00000; sents:     640; bsz:  259/ 274/32; 1720/1816 tok/s;    161 sec;\n",
      "[2024-03-11 10:45:05,463 INFO] Step 780/50000; acc: 47.8; ppl:  23.0; xent: 3.1; lr: 1.00000; sents:     640; bsz:  256/ 284/32; 1585/1758 tok/s;    164 sec;\n",
      "[2024-03-11 10:45:08,809 INFO] Step 800/50000; acc: 47.3; ppl:  24.4; xent: 3.2; lr: 1.00000; sents:     640; bsz:  266/ 290/32; 1588/1731 tok/s;    168 sec;\n",
      "[2024-03-11 10:45:12,236 INFO] Step 820/50000; acc: 52.6; ppl:  17.9; xent: 2.9; lr: 1.00000; sents:     640; bsz:  230/ 256/32; 1345/1494 tok/s;    171 sec;\n",
      "[2024-03-11 10:45:15,286 INFO] Step 840/50000; acc: 47.3; ppl:  22.4; xent: 3.1; lr: 1.00000; sents:     640; bsz:  243/ 285/32; 1595/1868 tok/s;    174 sec;\n",
      "[2024-03-11 10:45:18,572 INFO] Step 860/50000; acc: 46.5; ppl:  25.3; xent: 3.2; lr: 1.00000; sents:     640; bsz:  282/ 301/32; 1714/1831 tok/s;    177 sec;\n",
      "[2024-03-11 10:45:22,823 INFO] Step 880/50000; acc: 43.8; ppl:  28.5; xent: 3.3; lr: 1.00000; sents:     640; bsz:  315/ 334/32; 1483/1573 tok/s;    182 sec;\n",
      "[2024-03-11 10:45:26,139 INFO] Step 900/50000; acc: 48.7; ppl:  21.5; xent: 3.1; lr: 1.00000; sents:     640; bsz:  280/ 290/32; 1689/1747 tok/s;    185 sec;\n",
      "[2024-03-11 10:45:29,982 INFO] Step 920/50000; acc: 43.9; ppl:  27.7; xent: 3.3; lr: 1.00000; sents:     640; bsz:  346/ 355/32; 1799/1849 tok/s;    189 sec;\n",
      "[2024-03-11 10:45:33,503 INFO] Step 940/50000; acc: 47.0; ppl:  24.2; xent: 3.2; lr: 1.00000; sents:     640; bsz:  286/ 298/32; 1627/1691 tok/s;    192 sec;\n",
      "[2024-03-11 10:45:37,045 INFO] Step 960/50000; acc: 45.5; ppl:  25.4; xent: 3.2; lr: 1.00000; sents:     640; bsz:  291/ 302/32; 1645/1706 tok/s;    196 sec;\n",
      "[2024-03-11 10:45:40,473 INFO] Step 980/50000; acc: 46.0; ppl:  24.1; xent: 3.2; lr: 1.00000; sents:     640; bsz:  296/ 317/32; 1727/1849 tok/s;    199 sec;\n",
      "[2024-03-11 10:45:43,520 INFO] Step 1000/50000; acc: 55.7; ppl:  13.4; xent: 2.6; lr: 1.00000; sents:     640; bsz:  222/ 256/32; 1460/1680 tok/s;    202 sec;\n",
      "[2024-03-11 10:45:49,941 INFO] valid stats calculation\n",
      "                           took: 6.419953346252441 s.\n",
      "[2024-03-11 10:45:49,941 INFO] Train perplexity: 48.445\n",
      "[2024-03-11 10:45:49,941 INFO] Train accuracy: 39.0598\n",
      "[2024-03-11 10:45:49,941 INFO] Sentences processed: 32000\n",
      "[2024-03-11 10:45:49,941 INFO] Average bsz:  278/ 297/32\n",
      "[2024-03-11 10:45:49,941 INFO] Validation perplexity: 16.5159\n",
      "[2024-03-11 10:45:49,941 INFO] Validation accuracy: 52.5035\n",
      "[2024-03-11 10:45:49,942 INFO] Model is improving ppl: 27.0869 --> 16.5159.\n",
      "[2024-03-11 10:45:49,942 INFO] Model is improving acc: 46.268 --> 52.5035.\n",
      "[2024-03-11 10:45:53,344 INFO] Step 1020/50000; acc: 50.5; ppl:  17.3; xent: 2.8; lr: 1.00000; sents:     640; bsz:  256/ 285/32; 521/580 tok/s;    212 sec;\n",
      "[2024-03-11 10:45:56,252 INFO] Step 1040/50000; acc: 53.6; ppl:  16.8; xent: 2.8; lr: 1.00000; sents:     640; bsz:  234/ 254/32; 1607/1750 tok/s;    215 sec;\n",
      "[2024-03-11 10:45:59,556 INFO] Step 1060/50000; acc: 46.6; ppl:  24.0; xent: 3.2; lr: 1.00000; sents:     640; bsz:  298/ 301/32; 1802/1821 tok/s;    218 sec;\n",
      "[2024-03-11 10:46:02,518 INFO] Step 1080/50000; acc: 50.1; ppl:  20.3; xent: 3.0; lr: 1.00000; sents:     640; bsz:  269/ 266/32; 1815/1794 tok/s;    221 sec;\n",
      "[2024-03-11 10:46:06,157 INFO] Step 1100/50000; acc: 48.7; ppl:  20.8; xent: 3.0; lr: 1.00000; sents:     640; bsz:  288/ 301/32; 1583/1654 tok/s;    225 sec;\n",
      "[2024-03-11 10:46:09,405 INFO] Step 1120/50000; acc: 52.3; ppl:  17.0; xent: 2.8; lr: 1.00000; sents:     640; bsz:  250/ 279/32; 1537/1719 tok/s;    228 sec;\n",
      "[2024-03-11 10:46:12,411 INFO] Step 1140/50000; acc: 52.1; ppl:  15.5; xent: 2.7; lr: 1.00000; sents:     640; bsz:  246/ 280/32; 1640/1863 tok/s;    231 sec;\n",
      "[2024-03-11 10:46:15,665 INFO] Step 1160/50000; acc: 50.0; ppl:  17.6; xent: 2.9; lr: 1.00000; sents:     640; bsz:  286/ 302/32; 1760/1854 tok/s;    235 sec;\n",
      "[2024-03-11 10:46:19,373 INFO] Step 1180/50000; acc: 48.9; ppl:  19.6; xent: 3.0; lr: 1.00000; sents:     640; bsz:  306/ 314/32; 1649/1692 tok/s;    238 sec;\n",
      "[2024-03-11 10:46:22,525 INFO] Step 1200/50000; acc: 51.8; ppl:  16.4; xent: 2.8; lr: 1.00000; sents:     640; bsz:  261/ 287/32; 1657/1820 tok/s;    241 sec;\n",
      "[2024-03-11 10:46:25,879 INFO] Step 1220/50000; acc: 53.2; ppl:  15.8; xent: 2.8; lr: 1.00000; sents:     640; bsz:  259/ 277/32; 1546/1654 tok/s;    245 sec;\n",
      "[2024-03-11 10:46:28,779 INFO] Step 1240/50000; acc: 52.0; ppl:  17.5; xent: 2.9; lr: 1.00000; sents:     640; bsz:  249/ 257/32; 1719/1775 tok/s;    248 sec;\n",
      "[2024-03-11 10:46:31,963 INFO] Step 1260/50000; acc: 52.2; ppl:  15.4; xent: 2.7; lr: 1.00000; sents:     640; bsz:  253/ 280/32; 1588/1759 tok/s;    251 sec;\n",
      "[2024-03-11 10:46:35,231 INFO] Step 1280/50000; acc: 49.3; ppl:  19.4; xent: 3.0; lr: 1.00000; sents:     640; bsz:  285/ 301/32; 1743/1841 tok/s;    254 sec;\n",
      "[2024-03-11 10:46:38,398 INFO] Step 1300/50000; acc: 51.9; ppl:  16.1; xent: 2.8; lr: 1.00000; sents:     640; bsz:  278/ 304/32; 1758/1920 tok/s;    257 sec;\n",
      "[2024-03-11 10:46:41,639 INFO] Step 1320/50000; acc: 52.1; ppl:  16.1; xent: 2.8; lr: 1.00000; sents:     640; bsz:  304/ 304/32; 1876/1876 tok/s;    261 sec;\n",
      "[2024-03-11 10:46:44,629 INFO] Step 1340/50000; acc: 52.4; ppl:  15.7; xent: 2.8; lr: 1.00000; sents:     640; bsz:  269/ 283/32; 1799/1895 tok/s;    264 sec;\n",
      "[2024-03-11 10:46:47,879 INFO] Step 1360/50000; acc: 51.9; ppl:  17.7; xent: 2.9; lr: 1.00000; sents:     640; bsz:  292/ 301/32; 1795/1854 tok/s;    267 sec;\n",
      "[2024-03-11 10:46:51,638 INFO] Step 1380/50000; acc: 50.9; ppl:  16.4; xent: 2.8; lr: 1.00000; sents:     640; bsz:  293/ 322/32; 1560/1713 tok/s;    271 sec;\n",
      "[2024-03-11 10:46:55,165 INFO] Step 1400/50000; acc: 54.1; ppl:  15.6; xent: 2.7; lr: 1.00000; sents:     640; bsz:  278/ 280/32; 1579/1588 tok/s;    274 sec;\n",
      "[2024-03-11 10:46:58,871 INFO] Step 1420/50000; acc: 52.1; ppl:  15.5; xent: 2.7; lr: 1.00000; sents:     640; bsz:  285/ 304/32; 1537/1640 tok/s;    278 sec;\n",
      "[2024-03-11 10:47:02,468 INFO] Step 1440/50000; acc: 52.6; ppl:  15.0; xent: 2.7; lr: 1.00000; sents:     640; bsz:  286/ 290/32; 1592/1610 tok/s;    281 sec;\n",
      "[2024-03-11 10:47:06,444 INFO] Step 1460/50000; acc: 52.0; ppl:  15.5; xent: 2.7; lr: 1.00000; sents:     640; bsz:  280/ 296/32; 1409/1488 tok/s;    285 sec;\n",
      "[2024-03-11 10:47:09,864 INFO] Step 1480/50000; acc: 51.2; ppl:  15.9; xent: 2.8; lr: 1.00000; sents:     640; bsz:  304/ 310/32; 1778/1815 tok/s;    289 sec;\n",
      "[2024-03-11 10:47:12,882 INFO] Step 1500/50000; acc: 55.7; ppl:  12.5; xent: 2.5; lr: 1.00000; sents:     640; bsz:  240/ 267/32; 1591/1771 tok/s;    292 sec;\n",
      "[2024-03-11 10:47:18,198 INFO] valid stats calculation\n",
      "                           took: 5.314872980117798 s.\n",
      "[2024-03-11 10:47:18,198 INFO] Train perplexity: 34.3061\n",
      "[2024-03-11 10:47:18,198 INFO] Train accuracy: 43.1291\n",
      "[2024-03-11 10:47:18,198 INFO] Sentences processed: 48000\n",
      "[2024-03-11 10:47:18,198 INFO] Average bsz:  276/ 295/32\n",
      "[2024-03-11 10:47:18,198 INFO] Validation perplexity: 12.6414\n",
      "[2024-03-11 10:47:18,198 INFO] Validation accuracy: 55.2851\n",
      "[2024-03-11 10:47:18,198 INFO] Model is improving ppl: 16.5159 --> 12.6414.\n",
      "[2024-03-11 10:47:18,198 INFO] Model is improving acc: 52.5035 --> 55.2851.\n",
      "[2024-03-11 10:47:21,701 INFO] Step 1520/50000; acc: 50.2; ppl:  17.9; xent: 2.9; lr: 1.00000; sents:     640; bsz:  312/ 330/32; 708/747 tok/s;    301 sec;\n",
      "[2024-03-11 10:47:25,253 INFO] Step 1540/50000; acc: 50.4; ppl:  16.7; xent: 2.8; lr: 1.00000; sents:     640; bsz:  299/ 325/32; 1685/1829 tok/s;    304 sec;\n",
      "[2024-03-11 10:47:28,644 INFO] Step 1560/50000; acc: 51.2; ppl:  16.0; xent: 2.8; lr: 1.00000; sents:     640; bsz:  320/ 317/32; 1887/1868 tok/s;    308 sec;\n",
      "[2024-03-11 10:47:31,859 INFO] Step 1580/50000; acc: 54.5; ppl:  12.3; xent: 2.5; lr: 1.00000; sents:     640; bsz:  286/ 295/32; 1782/1834 tok/s;    311 sec;\n",
      "[2024-03-11 10:47:35,209 INFO] Step 1600/50000; acc: 55.3; ppl:  12.8; xent: 2.6; lr: 1.00000; sents:     640; bsz:  269/ 279/32; 1608/1666 tok/s;    314 sec;\n",
      "[2024-03-11 10:47:38,667 INFO] Step 1620/50000; acc: 54.4; ppl:  13.0; xent: 2.6; lr: 1.00000; sents:     640; bsz:  302/ 305/32; 1749/1763 tok/s;    318 sec;\n",
      "[2024-03-11 10:47:41,651 INFO] Step 1640/50000; acc: 58.6; ppl:  10.2; xent: 2.3; lr: 1.00000; sents:     640; bsz:  264/ 280/32; 1769/1876 tok/s;    321 sec;\n",
      "[2024-03-11 10:47:45,368 INFO] Step 1660/50000; acc: 51.5; ppl:  15.2; xent: 2.7; lr: 1.00000; sents:     640; bsz:  302/ 330/32; 1627/1774 tok/s;    324 sec;\n",
      "[2024-03-11 10:47:48,637 INFO] Step 1680/50000; acc: 53.7; ppl:  13.7; xent: 2.6; lr: 1.00000; sents:     640; bsz:  286/ 317/32; 1752/1939 tok/s;    328 sec;\n",
      "[2024-03-11 10:47:52,184 INFO] Step 1700/50000; acc: 52.8; ppl:  13.9; xent: 2.6; lr: 1.00000; sents:     640; bsz:  306/ 326/32; 1723/1840 tok/s;    331 sec;\n",
      "[2024-03-11 10:47:55,050 INFO] Step 1720/50000; acc: 58.0; ppl:  11.0; xent: 2.4; lr: 1.00000; sents:     640; bsz:  274/ 261/32; 1910/1820 tok/s;    334 sec;\n",
      "[2024-03-11 10:47:58,135 INFO] Step 1740/50000; acc: 59.2; ppl:   9.5; xent: 2.3; lr: 1.00000; sents:     640; bsz:  245/ 274/32; 1587/1774 tok/s;    337 sec;\n",
      "[2024-03-11 10:48:02,192 INFO] Step 1760/50000; acc: 49.0; ppl:  18.6; xent: 2.9; lr: 1.00000; sents:     640; bsz:  338/ 347/32; 1665/1711 tok/s;    341 sec;\n",
      "[2024-03-11 10:48:05,651 INFO] Step 1780/50000; acc: 52.3; ppl:  14.9; xent: 2.7; lr: 1.00000; sents:     640; bsz:  292/ 334/32; 1689/1933 tok/s;    345 sec;\n",
      "[2024-03-11 10:48:08,596 INFO] Step 1800/50000; acc: 55.1; ppl:  12.8; xent: 2.5; lr: 1.00000; sents:     640; bsz:  261/ 274/32; 1771/1858 tok/s;    348 sec;\n",
      "[2024-03-11 10:48:11,859 INFO] Step 1820/50000; acc: 55.8; ppl:  12.0; xent: 2.5; lr: 1.00000; sents:     640; bsz:  312/ 312/32; 1913/1913 tok/s;    351 sec;\n",
      "[2024-03-11 10:48:15,190 INFO] Step 1840/50000; acc: 54.2; ppl:  11.7; xent: 2.5; lr: 1.00000; sents:     640; bsz:  299/ 321/32; 1796/1928 tok/s;    354 sec;\n",
      "[2024-03-11 10:48:18,824 INFO] Step 1860/50000; acc: 52.0; ppl:  13.9; xent: 2.6; lr: 1.00000; sents:     640; bsz:  330/ 357/32; 1814/1964 tok/s;    358 sec;\n",
      "[2024-03-11 10:48:22,447 INFO] Step 1880/50000; acc: 54.9; ppl:  11.5; xent: 2.4; lr: 1.00000; sents:     640; bsz:  304/ 325/32; 1678/1793 tok/s;    361 sec;\n",
      "[2024-03-11 10:48:25,809 INFO] Step 1900/50000; acc: 58.3; ppl:   9.3; xent: 2.2; lr: 1.00000; sents:     640; bsz:  261/ 286/32; 1552/1704 tok/s;    365 sec;\n",
      "[2024-03-11 10:48:28,729 INFO] Step 1920/50000; acc: 57.4; ppl:  10.8; xent: 2.4; lr: 1.00000; sents:     640; bsz:  235/ 271/32; 1611/1858 tok/s;    368 sec;\n",
      "[2024-03-11 10:48:31,734 INFO] Step 1940/50000; acc: 58.7; ppl:   9.9; xent: 2.3; lr: 1.00000; sents:     640; bsz:  237/ 266/32; 1576/1768 tok/s;    371 sec;\n",
      "[2024-03-11 10:48:34,876 INFO] Step 1960/50000; acc: 57.4; ppl:  10.3; xent: 2.3; lr: 1.00000; sents:     640; bsz:  270/ 280/32; 1721/1782 tok/s;    374 sec;\n",
      "[2024-03-11 10:48:38,626 INFO] Step 1980/50000; acc: 57.0; ppl:  10.9; xent: 2.4; lr: 1.00000; sents:     640; bsz:  282/ 312/32; 1502/1664 tok/s;    378 sec;\n",
      "[2024-03-11 10:48:41,936 INFO] Step 2000/50000; acc: 58.1; ppl:   9.9; xent: 2.3; lr: 1.00000; sents:     640; bsz:  250/ 289/32; 1508/1746 tok/s;    381 sec;\n",
      "[2024-03-11 10:48:47,573 INFO] valid stats calculation\n",
      "                           took: 5.635824918746948 s.\n",
      "[2024-03-11 10:48:47,573 INFO] Train perplexity: 26.5739\n",
      "[2024-03-11 10:48:47,573 INFO] Train accuracy: 46.0628\n",
      "[2024-03-11 10:48:47,573 INFO] Sentences processed: 64000\n",
      "[2024-03-11 10:48:47,573 INFO] Average bsz:  279/ 297/32\n",
      "[2024-03-11 10:48:47,573 INFO] Validation perplexity: 10.6249\n",
      "[2024-03-11 10:48:47,573 INFO] Validation accuracy: 58.4608\n",
      "[2024-03-11 10:48:47,574 INFO] Model is improving ppl: 12.6414 --> 10.6249.\n",
      "[2024-03-11 10:48:47,574 INFO] Model is improving acc: 55.2851 --> 58.4608.\n",
      "[2024-03-11 10:48:50,732 INFO] Step 2020/50000; acc: 59.6; ppl:   8.7; xent: 2.2; lr: 1.00000; sents:     640; bsz:  256/ 293/32; 582/666 tok/s;    390 sec;\n",
      "[2024-03-11 10:48:54,222 INFO] Step 2040/50000; acc: 57.8; ppl:   9.9; xent: 2.3; lr: 1.00000; sents:     640; bsz:  283/ 283/32; 1623/1623 tok/s;    393 sec;\n",
      "[2024-03-11 10:48:57,422 INFO] Step 2060/50000; acc: 57.0; ppl:  10.8; xent: 2.4; lr: 1.00000; sents:     640; bsz:  256/ 285/32; 1600/1780 tok/s;    396 sec;\n",
      "[2024-03-11 10:49:00,634 INFO] Step 2080/50000; acc: 57.2; ppl:  10.0; xent: 2.3; lr: 1.00000; sents:     640; bsz:  291/ 304/32; 1814/1896 tok/s;    400 sec;\n",
      "[2024-03-11 10:49:03,905 INFO] Step 2100/50000; acc: 58.9; ppl:   9.0; xent: 2.2; lr: 1.00000; sents:     640; bsz:  262/ 275/32; 1605/1683 tok/s;    403 sec;\n",
      "[2024-03-11 10:49:06,820 INFO] Step 2120/50000; acc: 62.0; ppl:   7.3; xent: 2.0; lr: 1.00000; sents:     640; bsz:  237/ 256/32; 1625/1757 tok/s;    406 sec;\n",
      "[2024-03-11 10:49:10,197 INFO] Step 2140/50000; acc: 59.4; ppl:   8.8; xent: 2.2; lr: 1.00000; sents:     640; bsz:  253/ 282/32; 1497/1668 tok/s;    409 sec;\n",
      "[2024-03-11 10:49:13,374 INFO] Step 2160/50000; acc: 59.5; ppl:   8.7; xent: 2.2; lr: 1.00000; sents:     640; bsz:  277/ 280/32; 1743/1763 tok/s;    412 sec;\n",
      "[2024-03-11 10:49:16,940 INFO] Step 2180/50000; acc: 57.6; ppl:   9.8; xent: 2.3; lr: 1.00000; sents:     640; bsz:  306/ 325/32; 1714/1822 tok/s;    416 sec;\n",
      "[2024-03-11 10:49:20,880 INFO] Step 2200/50000; acc: 63.0; ppl:   7.3; xent: 2.0; lr: 1.00000; sents:     640; bsz:  258/ 264/32; 1308/1340 tok/s;    420 sec;\n",
      "[2024-03-11 10:49:24,695 INFO] Step 2220/50000; acc: 60.8; ppl:   8.0; xent: 2.1; lr: 1.00000; sents:     640; bsz:  242/ 277/32; 1267/1451 tok/s;    424 sec;\n",
      "[2024-03-11 10:49:28,333 INFO] Step 2240/50000; acc: 61.5; ppl:   7.3; xent: 2.0; lr: 1.00000; sents:     640; bsz:  240/ 280/32; 1320/1540 tok/s;    427 sec;\n",
      "[2024-03-11 10:49:31,749 INFO] Step 2260/50000; acc: 63.4; ppl:   7.1; xent: 2.0; lr: 1.00000; sents:     640; bsz:  232/ 258/32; 1358/1508 tok/s;    431 sec;\n",
      "[2024-03-11 10:49:36,398 INFO] Step 2280/50000; acc: 56.3; ppl:  10.5; xent: 2.4; lr: 1.00000; sents:     640; bsz:  306/ 329/32; 1316/1414 tok/s;    435 sec;\n",
      "[2024-03-11 10:49:39,948 INFO] Step 2300/50000; acc: 57.6; ppl:   9.2; xent: 2.2; lr: 1.00000; sents:     640; bsz:  298/ 325/32; 1677/1830 tok/s;    439 sec;\n",
      "[2024-03-11 10:49:43,341 INFO] Step 2320/50000; acc: 55.0; ppl:  10.3; xent: 2.3; lr: 1.00000; sents:     640; bsz:  328/ 330/32; 1933/1943 tok/s;    442 sec;\n",
      "[2024-03-11 10:49:46,639 INFO] Step 2340/50000; acc: 54.5; ppl:  12.5; xent: 2.5; lr: 1.00000; sents:     640; bsz:  310/ 317/32; 1883/1922 tok/s;    446 sec;\n",
      "[2024-03-11 10:49:50,281 INFO] Step 2360/50000; acc: 54.1; ppl:  13.1; xent: 2.6; lr: 1.00000; sents:     640; bsz:  312/ 320/32; 1715/1755 tok/s;    449 sec;\n",
      "[2024-03-11 10:49:54,164 INFO] Step 2380/50000; acc: 57.7; ppl:   9.8; xent: 2.3; lr: 1.00000; sents:     640; bsz:  280/ 302/32; 1443/1557 tok/s;    453 sec;\n",
      "[2024-03-11 10:49:57,527 INFO] Step 2400/50000; acc: 59.4; ppl:   8.9; xent: 2.2; lr: 1.00000; sents:     640; bsz:  275/ 290/32; 1634/1723 tok/s;    456 sec;\n",
      "[2024-03-11 10:50:00,885 INFO] Step 2420/50000; acc: 62.7; ppl:   7.1; xent: 2.0; lr: 1.00000; sents:     640; bsz:  246/ 286/32; 1468/1704 tok/s;    460 sec;\n",
      "[2024-03-11 10:50:04,270 INFO] Step 2440/50000; acc: 62.4; ppl:   7.8; xent: 2.0; lr: 1.00000; sents:     640; bsz:  234/ 258/32; 1380/1522 tok/s;    463 sec;\n",
      "[2024-03-11 10:50:07,426 INFO] Step 2460/50000; acc: 62.6; ppl:   6.6; xent: 1.9; lr: 1.00000; sents:     640; bsz:  232/ 257/32; 1471/1628 tok/s;    466 sec;\n",
      "[2024-03-11 10:50:10,968 INFO] Step 2480/50000; acc: 57.9; ppl:  10.3; xent: 2.3; lr: 1.00000; sents:     640; bsz:  294/ 295/32; 1663/1664 tok/s;    470 sec;\n",
      "[2024-03-11 10:50:14,557 INFO] Step 2500/50000; acc: 59.2; ppl:   8.4; xent: 2.1; lr: 1.00000; sents:     640; bsz:  294/ 327/32; 1640/1820 tok/s;    473 sec;\n",
      "[2024-03-11 10:50:20,467 INFO] valid stats calculation\n",
      "                           took: 5.908779859542847 s.\n",
      "[2024-03-11 10:50:20,467 INFO] Train perplexity: 21.488\n",
      "[2024-03-11 10:50:20,467 INFO] Train accuracy: 48.5941\n",
      "[2024-03-11 10:50:20,467 INFO] Sentences processed: 80000\n",
      "[2024-03-11 10:50:20,467 INFO] Average bsz:  277/ 296/32\n",
      "[2024-03-11 10:50:20,467 INFO] Validation perplexity: 8.67498\n",
      "[2024-03-11 10:50:20,467 INFO] Validation accuracy: 61.1497\n",
      "[2024-03-11 10:50:20,467 INFO] Model is improving ppl: 10.6249 --> 8.67498.\n",
      "[2024-03-11 10:50:20,467 INFO] Model is improving acc: 58.4608 --> 61.1497.\n",
      "[2024-03-11 10:50:24,317 INFO] Step 2520/50000; acc: 59.9; ppl:   8.2; xent: 2.1; lr: 1.00000; sents:     640; bsz:  290/ 315/32; 593/646 tok/s;    483 sec;\n",
      "[2024-03-11 10:50:28,089 INFO] Step 2540/50000; acc: 60.5; ppl:   8.0; xent: 2.1; lr: 1.00000; sents:     640; bsz:  298/ 304/32; 1578/1612 tok/s;    487 sec;\n",
      "[2024-03-11 10:50:32,131 INFO] Step 2560/50000; acc: 58.3; ppl:   9.3; xent: 2.2; lr: 1.00000; sents:     640; bsz:  312/ 309/32; 1544/1528 tok/s;    491 sec;\n",
      "[2024-03-11 10:50:36,414 INFO] Step 2580/50000; acc: 56.2; ppl:  10.4; xent: 2.3; lr: 1.00000; sents:     640; bsz:  327/ 346/32; 1526/1617 tok/s;    495 sec;\n",
      "[2024-03-11 10:50:40,933 INFO] Step 2600/50000; acc: 55.1; ppl:  11.4; xent: 2.4; lr: 1.00000; sents:     640; bsz:  326/ 334/32; 1442/1480 tok/s;    500 sec;\n",
      "[2024-03-11 10:50:45,122 INFO] Step 2620/50000; acc: 58.3; ppl:   8.4; xent: 2.1; lr: 1.00000; sents:     640; bsz:  309/ 328/32; 1474/1566 tok/s;    504 sec;\n",
      "[2024-03-11 10:50:48,740 INFO] Step 2640/50000; acc: 61.7; ppl:   7.4; xent: 2.0; lr: 1.00000; sents:     640; bsz:  282/ 288/32; 1557/1592 tok/s;    508 sec;\n",
      "[2024-03-11 10:50:52,299 INFO] Step 2660/50000; acc: 63.0; ppl:   6.4; xent: 1.9; lr: 1.00000; sents:     640; bsz:  256/ 293/32; 1439/1646 tok/s;    511 sec;\n",
      "[2024-03-11 10:50:55,992 INFO] Step 2680/50000; acc: 63.4; ppl:   6.5; xent: 1.9; lr: 1.00000; sents:     640; bsz:  262/ 280/32; 1421/1517 tok/s;    515 sec;\n",
      "[2024-03-11 10:51:00,163 INFO] Step 2700/50000; acc: 62.1; ppl:   7.0; xent: 1.9; lr: 1.00000; sents:     640; bsz:  285/ 302/32; 1366/1450 tok/s;    519 sec;\n",
      "[2024-03-11 10:51:03,989 INFO] Step 2720/50000; acc: 62.3; ppl:   7.0; xent: 2.0; lr: 1.00000; sents:     640; bsz:  270/ 288/32; 1411/1508 tok/s;    523 sec;\n",
      "[2024-03-11 10:51:07,698 INFO] Step 2740/50000; acc: 62.5; ppl:   6.9; xent: 1.9; lr: 1.00000; sents:     640; bsz:  261/ 293/32; 1407/1579 tok/s;    527 sec;\n",
      "[2024-03-11 10:51:11,834 INFO] Step 2760/50000; acc: 60.4; ppl:   7.7; xent: 2.0; lr: 1.00000; sents:     640; bsz:  283/ 302/32; 1369/1462 tok/s;    531 sec;\n",
      "[2024-03-11 10:51:15,342 INFO] Step 2780/50000; acc: 60.5; ppl:   8.1; xent: 2.1; lr: 1.00000; sents:     640; bsz:  267/ 310/32; 1524/1770 tok/s;    534 sec;\n",
      "[2024-03-11 10:51:18,275 INFO] Step 2800/50000; acc: 63.3; ppl:   6.3; xent: 1.8; lr: 1.00000; sents:     640; bsz:  261/ 269/32; 1778/1833 tok/s;    537 sec;\n",
      "[2024-03-11 10:51:21,533 INFO] Step 2820/50000; acc: 63.1; ppl:   6.3; xent: 1.8; lr: 1.00000; sents:     640; bsz:  267/ 296/32; 1641/1818 tok/s;    540 sec;\n",
      "[2024-03-11 10:51:24,997 INFO] Step 2840/50000; acc: 59.3; ppl:   9.0; xent: 2.2; lr: 1.00000; sents:     640; bsz:  300/ 298/32; 1732/1718 tok/s;    544 sec;\n",
      "[2024-03-11 10:51:28,687 INFO] Step 2860/50000; acc: 57.8; ppl:  10.0; xent: 2.3; lr: 1.00000; sents:     640; bsz:  301/ 320/32; 1630/1735 tok/s;    548 sec;\n",
      "[2024-03-11 10:51:31,945 INFO] Step 2880/50000; acc: 62.5; ppl:   6.7; xent: 1.9; lr: 1.00000; sents:     640; bsz:  286/ 306/32; 1758/1881 tok/s;    551 sec;\n",
      "[2024-03-11 10:51:35,480 INFO] Step 2900/50000; acc: 62.5; ppl:   6.3; xent: 1.8; lr: 1.00000; sents:     640; bsz:  288/ 306/32; 1630/1729 tok/s;    554 sec;\n",
      "[2024-03-11 10:51:39,538 INFO] Step 2920/50000; acc: 61.5; ppl:   7.3; xent: 2.0; lr: 1.00000; sents:     640; bsz:  267/ 294/32; 1317/1451 tok/s;    558 sec;\n",
      "[2024-03-11 10:51:43,085 INFO] Step 2940/50000; acc: 63.1; ppl:   6.4; xent: 1.9; lr: 1.00000; sents:     640; bsz:  256/ 290/32; 1444/1633 tok/s;    562 sec;\n",
      "[2024-03-11 10:51:46,702 INFO] Step 2960/50000; acc: 62.6; ppl:   6.2; xent: 1.8; lr: 1.00000; sents:     640; bsz:  270/ 310/32; 1495/1712 tok/s;    566 sec;\n",
      "[2024-03-11 10:51:49,799 INFO] Step 2980/50000; acc: 66.7; ppl:   5.5; xent: 1.7; lr: 1.00000; sents:     640; bsz:  254/ 267/32; 1643/1726 tok/s;    569 sec;\n",
      "[2024-03-11 10:51:53,267 INFO] Step 3000/50000; acc: 60.3; ppl:   7.4; xent: 2.0; lr: 1.00000; sents:     640; bsz:  296/ 320/32; 1707/1846 tok/s;    572 sec;\n",
      "[2024-03-11 10:51:58,901 INFO] valid stats calculation\n",
      "                           took: 5.632826566696167 s.\n",
      "[2024-03-11 10:51:58,901 INFO] Train perplexity: 17.9898\n",
      "[2024-03-11 10:51:58,901 INFO] Train accuracy: 50.6937\n",
      "[2024-03-11 10:51:58,901 INFO] Sentences processed: 96000\n",
      "[2024-03-11 10:51:58,901 INFO] Average bsz:  278/ 297/32\n",
      "[2024-03-11 10:51:58,901 INFO] Validation perplexity: 8.03066\n",
      "[2024-03-11 10:51:58,901 INFO] Validation accuracy: 63.0737\n",
      "[2024-03-11 10:51:58,901 INFO] Model is improving ppl: 8.67498 --> 8.03066.\n",
      "[2024-03-11 10:51:58,901 INFO] Model is improving acc: 61.1497 --> 63.0737.\n",
      "[2024-03-11 10:52:02,247 INFO] Step 3020/50000; acc: 62.7; ppl:   6.6; xent: 1.9; lr: 1.00000; sents:     640; bsz:  286/ 315/32; 638/702 tok/s;    581 sec;\n",
      "[2024-03-11 10:52:05,821 INFO] Step 3040/50000; acc: 61.9; ppl:   6.5; xent: 1.9; lr: 1.00000; sents:     640; bsz:  294/ 306/32; 1647/1715 tok/s;    585 sec;\n",
      "[2024-03-11 10:52:09,366 INFO] Step 3060/50000; acc: 61.3; ppl:   7.6; xent: 2.0; lr: 1.00000; sents:     640; bsz:  288/ 317/32; 1625/1787 tok/s;    588 sec;\n",
      "[2024-03-11 10:52:12,815 INFO] Step 3080/50000; acc: 64.3; ppl:   6.1; xent: 1.8; lr: 1.00000; sents:     640; bsz:  275/ 278/32; 1596/1615 tok/s;    592 sec;\n",
      "[2024-03-11 10:52:16,629 INFO] Step 3100/50000; acc: 63.5; ppl:   6.3; xent: 1.8; lr: 1.00000; sents:     640; bsz:  275/ 293/32; 1443/1536 tok/s;    596 sec;\n",
      "[2024-03-11 10:52:20,350 INFO] Step 3120/50000; acc: 61.0; ppl:   7.6; xent: 2.0; lr: 1.00000; sents:     640; bsz:  274/ 297/32; 1471/1597 tok/s;    599 sec;\n",
      "[2024-03-11 10:52:24,717 INFO] Step 3140/50000; acc: 59.3; ppl:   8.1; xent: 2.1; lr: 1.00000; sents:     640; bsz:  318/ 312/32; 1458/1427 tok/s;    604 sec;\n",
      "[2024-03-11 10:52:28,348 INFO] Step 3160/50000; acc: 63.3; ppl:   6.2; xent: 1.8; lr: 1.00000; sents:     640; bsz:  290/ 294/32; 1595/1622 tok/s;    607 sec;\n",
      "[2024-03-11 10:52:31,896 INFO] Step 3180/50000; acc: 64.7; ppl:   5.5; xent: 1.7; lr: 1.00000; sents:     640; bsz:  309/ 301/32; 1741/1696 tok/s;    611 sec;\n",
      "[2024-03-11 10:52:35,159 INFO] Step 3200/50000; acc: 63.9; ppl:   6.3; xent: 1.8; lr: 1.00000; sents:     640; bsz:  291/ 302/32; 1785/1852 tok/s;    614 sec;\n",
      "[2024-03-11 10:52:38,664 INFO] Step 3220/50000; acc: 64.5; ppl:   5.8; xent: 1.8; lr: 1.00000; sents:     640; bsz:  278/ 307/32; 1589/1754 tok/s;    618 sec;\n",
      "[2024-03-11 10:52:42,223 INFO] Step 3240/50000; acc: 65.7; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  306/ 301/32; 1717/1690 tok/s;    621 sec;\n",
      "[2024-03-11 10:52:45,382 INFO] Step 3260/50000; acc: 65.3; ppl:   5.6; xent: 1.7; lr: 1.00000; sents:     640; bsz:  272/ 291/32; 1722/1844 tok/s;    624 sec;\n",
      "[2024-03-11 10:52:48,665 INFO] Step 3280/50000; acc: 63.6; ppl:   6.3; xent: 1.8; lr: 1.00000; sents:     640; bsz:  285/ 305/32; 1735/1857 tok/s;    628 sec;\n",
      "[2024-03-11 10:52:51,959 INFO] Step 3300/50000; acc: 64.0; ppl:   5.8; xent: 1.8; lr: 1.00000; sents:     640; bsz:  288/ 310/32; 1749/1885 tok/s;    631 sec;\n",
      "[2024-03-11 10:52:54,909 INFO] Step 3320/50000; acc: 64.9; ppl:   5.8; xent: 1.8; lr: 1.00000; sents:     640; bsz:  230/ 280/32; 1562/1899 tok/s;    634 sec;\n",
      "[2024-03-11 10:52:58,034 INFO] Step 3340/50000; acc: 65.1; ppl:   6.0; xent: 1.8; lr: 1.00000; sents:     640; bsz:  280/ 290/32; 1792/1854 tok/s;    637 sec;\n",
      "[2024-03-11 10:53:00,860 INFO] Step 3360/50000; acc: 65.6; ppl:   5.7; xent: 1.7; lr: 1.00000; sents:     640; bsz:  242/ 265/32; 1710/1872 tok/s;    640 sec;\n",
      "[2024-03-11 10:53:04,040 INFO] Step 3380/50000; acc: 65.3; ppl:   5.7; xent: 1.7; lr: 1.00000; sents:     640; bsz:  261/ 295/32; 1641/1853 tok/s;    643 sec;\n",
      "[2024-03-11 10:53:06,980 INFO] Step 3400/50000; acc: 67.9; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  267/ 261/32; 1818/1774 tok/s;    646 sec;\n",
      "[2024-03-11 10:53:10,296 INFO] Step 3420/50000; acc: 64.0; ppl:   6.1; xent: 1.8; lr: 1.00000; sents:     640; bsz:  304/ 317/32; 1834/1911 tok/s;    649 sec;\n",
      "[2024-03-11 10:53:13,756 INFO] Step 3440/50000; acc: 62.4; ppl:   6.8; xent: 1.9; lr: 1.00000; sents:     640; bsz:  308/ 320/32; 1782/1852 tok/s;    653 sec;\n",
      "[2024-03-11 10:53:16,965 INFO] Step 3460/50000; acc: 67.6; ppl:   4.8; xent: 1.6; lr: 1.00000; sents:     640; bsz:  299/ 309/32; 1864/1924 tok/s;    656 sec;\n",
      "[2024-03-11 10:53:20,485 INFO] Step 3480/50000; acc: 64.0; ppl:   5.7; xent: 1.7; lr: 1.00000; sents:     640; bsz:  314/ 341/32; 1782/1937 tok/s;    659 sec;\n",
      "[2024-03-11 10:53:24,531 INFO] Step 3500/50000; acc: 67.3; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  290/ 318/32; 1432/1573 tok/s;    663 sec;\n",
      "[2024-03-11 10:53:29,967 INFO] valid stats calculation\n",
      "                           took: 5.435238599777222 s.\n",
      "[2024-03-11 10:53:29,967 INFO] Train perplexity: 15.3677\n",
      "[2024-03-11 10:53:29,967 INFO] Train accuracy: 52.6274\n",
      "[2024-03-11 10:53:29,968 INFO] Sentences processed: 112000\n",
      "[2024-03-11 10:53:29,968 INFO] Average bsz:  279/ 298/32\n",
      "[2024-03-11 10:53:29,968 INFO] Validation perplexity: 7.66928\n",
      "[2024-03-11 10:53:29,968 INFO] Validation accuracy: 64.1632\n",
      "[2024-03-11 10:53:29,968 INFO] Model is improving ppl: 8.03066 --> 7.66928.\n",
      "[2024-03-11 10:53:29,968 INFO] Model is improving acc: 63.0737 --> 64.1632.\n",
      "[2024-03-11 10:53:33,304 INFO] Step 3520/50000; acc: 61.8; ppl:   7.1; xent: 2.0; lr: 1.00000; sents:     640; bsz:  314/ 320/32; 715/730 tok/s;    672 sec;\n",
      "[2024-03-11 10:53:36,525 INFO] Step 3540/50000; acc: 64.5; ppl:   5.8; xent: 1.8; lr: 1.00000; sents:     640; bsz:  288/ 314/32; 1789/1947 tok/s;    675 sec;\n",
      "[2024-03-11 10:53:39,778 INFO] Step 3560/50000; acc: 63.0; ppl:   6.7; xent: 1.9; lr: 1.00000; sents:     640; bsz:  296/ 307/32; 1820/1889 tok/s;    679 sec;\n",
      "[2024-03-11 10:53:42,994 INFO] Step 3580/50000; acc: 63.9; ppl:   5.9; xent: 1.8; lr: 1.00000; sents:     640; bsz:  283/ 307/32; 1761/1910 tok/s;    682 sec;\n",
      "[2024-03-11 10:53:46,175 INFO] Step 3600/50000; acc: 66.7; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  280/ 296/32; 1761/1861 tok/s;    685 sec;\n",
      "[2024-03-11 10:53:49,347 INFO] Step 3620/50000; acc: 64.5; ppl:   6.0; xent: 1.8; lr: 1.00000; sents:     640; bsz:  281/ 292/32; 1772/1840 tok/s;    688 sec;\n",
      "[2024-03-11 10:53:52,519 INFO] Step 3640/50000; acc: 66.9; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  296/ 296/32; 1867/1867 tok/s;    691 sec;\n",
      "[2024-03-11 10:53:55,650 INFO] Step 3660/50000; acc: 66.4; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  282/ 294/32; 1799/1881 tok/s;    695 sec;\n",
      "[2024-03-11 10:53:59,060 INFO] Step 3680/50000; acc: 63.3; ppl:   6.7; xent: 1.9; lr: 1.00000; sents:     618; bsz:  250/ 295/31; 1469/1732 tok/s;    698 sec;\n",
      "[2024-03-11 10:54:02,084 INFO] Step 3700/50000; acc: 65.9; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  264/ 293/32; 1746/1936 tok/s;    701 sec;\n",
      "[2024-03-11 10:54:05,058 INFO] Step 3720/50000; acc: 67.9; ppl:   4.6; xent: 1.5; lr: 1.00000; sents:     640; bsz:  269/ 272/32; 1808/1830 tok/s;    704 sec;\n",
      "[2024-03-11 10:54:08,164 INFO] Step 3740/50000; acc: 66.7; ppl:   4.8; xent: 1.6; lr: 1.00000; sents:     640; bsz:  272/ 296/32; 1752/1906 tok/s;    707 sec;\n",
      "[2024-03-11 10:54:11,507 INFO] Step 3760/50000; acc: 65.7; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  278/ 322/32; 1666/1924 tok/s;    710 sec;\n",
      "[2024-03-11 10:54:14,658 INFO] Step 3780/50000; acc: 64.3; ppl:   6.0; xent: 1.8; lr: 1.00000; sents:     640; bsz:  256/ 298/32; 1625/1889 tok/s;    714 sec;\n",
      "[2024-03-11 10:54:17,628 INFO] Step 3800/50000; acc: 68.1; ppl:   4.5; xent: 1.5; lr: 1.00000; sents:     640; bsz:  254/ 274/32; 1713/1848 tok/s;    717 sec;\n",
      "[2024-03-11 10:54:20,793 INFO] Step 3820/50000; acc: 64.8; ppl:   5.6; xent: 1.7; lr: 1.00000; sents:     640; bsz:  288/ 298/32; 1820/1880 tok/s;    720 sec;\n",
      "[2024-03-11 10:54:24,007 INFO] Step 3840/50000; acc: 65.2; ppl:   5.1; xent: 1.6; lr: 1.00000; sents:     640; bsz:  285/ 298/32; 1773/1852 tok/s;    723 sec;\n",
      "[2024-03-11 10:54:27,614 INFO] Step 3860/50000; acc: 60.6; ppl:   8.4; xent: 2.1; lr: 1.00000; sents:     640; bsz:  316/ 324/32; 1752/1796 tok/s;    727 sec;\n",
      "[2024-03-11 10:54:31,198 INFO] Step 3880/50000; acc: 61.0; ppl:   8.1; xent: 2.1; lr: 1.00000; sents:     640; bsz:  306/ 329/32; 1708/1834 tok/s;    730 sec;\n",
      "[2024-03-11 10:54:34,490 INFO] Step 3900/50000; acc: 64.7; ppl:   5.6; xent: 1.7; lr: 1.00000; sents:     640; bsz:  252/ 302/32; 1532/1833 tok/s;    733 sec;\n",
      "[2024-03-11 10:54:38,016 INFO] Step 3920/50000; acc: 64.6; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  310/ 337/32; 1761/1910 tok/s;    737 sec;\n",
      "[2024-03-11 10:54:41,835 INFO] Step 3940/50000; acc: 65.6; ppl:   5.2; xent: 1.7; lr: 1.00000; sents:     640; bsz:  282/ 304/32; 1475/1592 tok/s;    741 sec;\n",
      "[2024-03-11 10:54:45,236 INFO] Step 3960/50000; acc: 67.4; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  288/ 277/32; 1694/1632 tok/s;    744 sec;\n",
      "[2024-03-11 10:54:48,236 INFO] Step 3980/50000; acc: 71.1; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  250/ 261/32; 1664/1738 tok/s;    747 sec;\n",
      "[2024-03-11 10:54:51,660 INFO] Step 4000/50000; acc: 63.7; ppl:   5.8; xent: 1.8; lr: 1.00000; sents:     640; bsz:  283/ 301/32; 1654/1757 tok/s;    751 sec;\n",
      "[2024-03-11 10:54:57,231 INFO] valid stats calculation\n",
      "                           took: 5.57064151763916 s.\n",
      "[2024-03-11 10:54:57,232 INFO] Train perplexity: 13.5377\n",
      "[2024-03-11 10:54:57,232 INFO] Train accuracy: 54.1873\n",
      "[2024-03-11 10:54:57,232 INFO] Sentences processed: 127978\n",
      "[2024-03-11 10:54:57,232 INFO] Average bsz:  279/ 298/32\n",
      "[2024-03-11 10:54:57,232 INFO] Validation perplexity: 7.34606\n",
      "[2024-03-11 10:54:57,232 INFO] Validation accuracy: 65.1599\n",
      "[2024-03-11 10:54:57,232 INFO] Model is improving ppl: 7.66928 --> 7.34606.\n",
      "[2024-03-11 10:54:57,232 INFO] Model is improving acc: 64.1632 --> 65.1599.\n",
      "[2024-03-11 10:55:00,573 INFO] Step 4020/50000; acc: 67.8; ppl:   4.7; xent: 1.5; lr: 1.00000; sents:     640; bsz:  269/ 302/32; 603/679 tok/s;    759 sec;\n",
      "[2024-03-11 10:55:03,640 INFO] Step 4040/50000; acc: 67.9; ppl:   4.5; xent: 1.5; lr: 1.00000; sents:     640; bsz:  248/ 274/32; 1617/1784 tok/s;    763 sec;\n",
      "[2024-03-11 10:55:07,204 INFO] Step 4060/50000; acc: 67.2; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  266/ 299/32; 1491/1679 tok/s;    766 sec;\n",
      "[2024-03-11 10:55:10,836 INFO] Step 4080/50000; acc: 64.1; ppl:   6.4; xent: 1.9; lr: 1.00000; sents:     640; bsz:  294/ 316/32; 1618/1741 tok/s;    770 sec;\n",
      "[2024-03-11 10:55:14,466 INFO] Step 4100/50000; acc: 62.5; ppl:   6.7; xent: 1.9; lr: 1.00000; sents:     640; bsz:  294/ 316/32; 1621/1742 tok/s;    773 sec;\n",
      "[2024-03-11 10:55:18,041 INFO] Step 4120/50000; acc: 65.0; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  274/ 310/32; 1531/1737 tok/s;    777 sec;\n",
      "[2024-03-11 10:55:22,168 INFO] Step 4140/50000; acc: 64.6; ppl:   5.9; xent: 1.8; lr: 1.00000; sents:     640; bsz:  307/ 314/32; 1489/1524 tok/s;    781 sec;\n",
      "[2024-03-11 10:55:26,284 INFO] Step 4160/50000; acc: 62.6; ppl:   6.6; xent: 1.9; lr: 1.00000; sents:     640; bsz:  294/ 326/32; 1430/1585 tok/s;    785 sec;\n",
      "[2024-03-11 10:55:29,801 INFO] Step 4180/50000; acc: 65.3; ppl:   5.2; xent: 1.6; lr: 1.00000; sents:     640; bsz:  326/ 344/32; 1856/1957 tok/s;    789 sec;\n",
      "[2024-03-11 10:55:33,120 INFO] Step 4200/50000; acc: 66.5; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  286/ 310/32; 1726/1868 tok/s;    792 sec;\n",
      "[2024-03-11 10:55:36,425 INFO] Step 4220/50000; acc: 69.5; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  282/ 289/32; 1704/1749 tok/s;    795 sec;\n",
      "[2024-03-11 10:55:39,823 INFO] Step 4240/50000; acc: 68.8; ppl:   4.3; xent: 1.5; lr: 1.00000; sents:     640; bsz:  286/ 309/32; 1686/1818 tok/s;    799 sec;\n",
      "[2024-03-11 10:55:43,127 INFO] Step 4260/50000; acc: 69.2; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  270/ 283/32; 1637/1713 tok/s;    802 sec;\n",
      "[2024-03-11 10:55:46,438 INFO] Step 4280/50000; acc: 69.2; ppl:   4.4; xent: 1.5; lr: 1.00000; sents:     640; bsz:  269/ 286/32; 1624/1730 tok/s;    805 sec;\n",
      "[2024-03-11 10:55:49,767 INFO] Step 4300/50000; acc: 69.3; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  270/ 294/32; 1624/1768 tok/s;    809 sec;\n",
      "[2024-03-11 10:55:53,558 INFO] Step 4320/50000; acc: 65.5; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  301/ 328/32; 1587/1731 tok/s;    812 sec;\n",
      "[2024-03-11 10:55:56,840 INFO] Step 4340/50000; acc: 68.7; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  267/ 307/32; 1628/1872 tok/s;    816 sec;\n",
      "[2024-03-11 10:56:00,041 INFO] Step 4360/50000; acc: 69.1; ppl:   4.4; xent: 1.5; lr: 1.00000; sents:     640; bsz:  269/ 290/32; 1680/1810 tok/s;    819 sec;\n",
      "[2024-03-11 10:56:03,303 INFO] Step 4380/50000; acc: 66.7; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  274/ 280/32; 1677/1719 tok/s;    822 sec;\n",
      "[2024-03-11 10:56:06,651 INFO] Step 4400/50000; acc: 68.3; ppl:   4.5; xent: 1.5; lr: 1.00000; sents:     640; bsz:  259/ 274/32; 1549/1635 tok/s;    826 sec;\n",
      "[2024-03-11 10:56:09,902 INFO] Step 4420/50000; acc: 70.6; ppl:   3.9; xent: 1.3; lr: 1.00000; sents:     640; bsz:  261/ 283/32; 1605/1743 tok/s;    829 sec;\n",
      "[2024-03-11 10:56:13,168 INFO] Step 4440/50000; acc: 68.4; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  262/ 277/32; 1607/1695 tok/s;    832 sec;\n",
      "[2024-03-11 10:56:16,702 INFO] Step 4460/50000; acc: 64.6; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  274/ 312/32; 1548/1766 tok/s;    836 sec;\n",
      "[2024-03-11 10:56:19,810 INFO] Step 4480/50000; acc: 69.9; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  269/ 275/32; 1730/1771 tok/s;    839 sec;\n",
      "[2024-03-11 10:56:23,048 INFO] Step 4500/50000; acc: 68.0; ppl:   4.3; xent: 1.5; lr: 1.00000; sents:     640; bsz:  277/ 293/32; 1710/1809 tok/s;    842 sec;\n",
      "[2024-03-11 10:56:28,733 INFO] valid stats calculation\n",
      "                           took: 5.684645414352417 s.\n",
      "[2024-03-11 10:56:28,734 INFO] Train perplexity: 12.0539\n",
      "[2024-03-11 10:56:28,734 INFO] Train accuracy: 55.6256\n",
      "[2024-03-11 10:56:28,734 INFO] Sentences processed: 143978\n",
      "[2024-03-11 10:56:28,734 INFO] Average bsz:  279/ 298/32\n",
      "[2024-03-11 10:56:28,734 INFO] Validation perplexity: 7.24233\n",
      "[2024-03-11 10:56:28,734 INFO] Validation accuracy: 65.6236\n",
      "[2024-03-11 10:56:28,734 INFO] Model is improving ppl: 7.34606 --> 7.24233.\n",
      "[2024-03-11 10:56:28,734 INFO] Model is improving acc: 65.1599 --> 65.6236.\n",
      "[2024-03-11 10:56:32,198 INFO] Step 4520/50000; acc: 66.2; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  312/ 322/32; 682/703 tok/s;    851 sec;\n",
      "[2024-03-11 10:56:35,638 INFO] Step 4540/50000; acc: 66.3; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  296/ 320/32; 1721/1861 tok/s;    855 sec;\n",
      "[2024-03-11 10:56:39,351 INFO] Step 4560/50000; acc: 66.6; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  291/ 312/32; 1569/1681 tok/s;    858 sec;\n",
      "[2024-03-11 10:56:43,240 INFO] Step 4580/50000; acc: 66.4; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  301/ 312/32; 1547/1605 tok/s;    862 sec;\n",
      "[2024-03-11 10:56:47,197 INFO] Step 4600/50000; acc: 67.6; ppl:   4.6; xent: 1.5; lr: 1.00000; sents:     640; bsz:  278/ 299/32; 1407/1512 tok/s;    866 sec;\n",
      "[2024-03-11 10:56:50,963 INFO] Step 4620/50000; acc: 69.4; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  270/ 297/32; 1436/1576 tok/s;    870 sec;\n",
      "[2024-03-11 10:56:54,720 INFO] Step 4640/50000; acc: 71.3; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  267/ 299/32; 1423/1593 tok/s;    874 sec;\n",
      "[2024-03-11 10:56:58,663 INFO] Step 4660/50000; acc: 68.4; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  288/ 304/32; 1461/1542 tok/s;    878 sec;\n",
      "[2024-03-11 10:57:02,764 INFO] Step 4680/50000; acc: 71.2; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  270/ 299/32; 1317/1457 tok/s;    882 sec;\n",
      "[2024-03-11 10:57:06,491 INFO] Step 4700/50000; acc: 67.4; ppl:   4.7; xent: 1.6; lr: 1.00000; sents:     640; bsz:  274/ 316/32; 1469/1696 tok/s;    885 sec;\n",
      "[2024-03-11 10:57:10,105 INFO] Step 4720/50000; acc: 66.0; ppl:   5.5; xent: 1.7; lr: 1.00000; sents:     640; bsz:  280/ 297/32; 1549/1642 tok/s;    889 sec;\n",
      "[2024-03-11 10:57:14,161 INFO] Step 4740/50000; acc: 67.1; ppl:   4.8; xent: 1.6; lr: 1.00000; sents:     640; bsz:  285/ 322/32; 1405/1587 tok/s;    893 sec;\n",
      "[2024-03-11 10:57:18,007 INFO] Step 4760/50000; acc: 70.3; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  286/ 299/32; 1489/1556 tok/s;    897 sec;\n",
      "[2024-03-11 10:57:21,499 INFO] Step 4780/50000; acc: 72.7; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  256/ 288/32; 1467/1650 tok/s;    900 sec;\n",
      "[2024-03-11 10:57:24,699 INFO] Step 4800/50000; acc: 71.2; ppl:   3.5; xent: 1.2; lr: 1.00000; sents:     640; bsz:  251/ 282/32; 1570/1760 tok/s;    904 sec;\n",
      "[2024-03-11 10:57:28,008 INFO] Step 4820/50000; acc: 71.8; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  240/ 262/32; 1451/1586 tok/s;    907 sec;\n",
      "[2024-03-11 10:57:31,490 INFO] Step 4840/50000; acc: 68.5; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  272/ 290/32; 1562/1663 tok/s;    910 sec;\n",
      "[2024-03-11 10:57:34,859 INFO] Step 4860/50000; acc: 71.3; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  283/ 301/32; 1682/1786 tok/s;    914 sec;\n",
      "[2024-03-11 10:57:38,927 INFO] Step 4880/50000; acc: 69.5; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  280/ 306/32; 1377/1502 tok/s;    918 sec;\n",
      "[2024-03-11 10:57:43,197 INFO] Step 4900/50000; acc: 66.4; ppl:   5.2; xent: 1.6; lr: 1.00000; sents:     640; bsz:  325/ 335/32; 1522/1570 tok/s;    922 sec;\n",
      "[2024-03-11 10:57:46,712 INFO] Step 4920/50000; acc: 66.8; ppl:   4.5; xent: 1.5; lr: 1.00000; sents:     640; bsz:  288/ 302/32; 1639/1719 tok/s;    926 sec;\n",
      "[2024-03-11 10:57:50,005 INFO] Step 4940/50000; acc: 71.7; ppl:   3.5; xent: 1.2; lr: 1.00000; sents:     640; bsz:  282/ 293/32; 1711/1779 tok/s;    929 sec;\n",
      "[2024-03-11 10:57:53,419 INFO] Step 4960/50000; acc: 69.4; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  270/ 299/32; 1584/1753 tok/s;    932 sec;\n",
      "[2024-03-11 10:57:57,498 INFO] Step 4980/50000; acc: 65.4; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  312/ 325/32; 1530/1593 tok/s;    936 sec;\n",
      "[2024-03-11 10:58:01,199 INFO] Step 5000/50000; acc: 66.1; ppl:   5.1; xent: 1.6; lr: 1.00000; sents:     640; bsz:  288/ 320/32; 1554/1729 tok/s;    940 sec;\n",
      "[2024-03-11 10:58:07,371 INFO] valid stats calculation\n",
      "                           took: 6.17126989364624 s.\n",
      "[2024-03-11 10:58:07,376 INFO] Train perplexity: 10.861\n",
      "[2024-03-11 10:58:07,376 INFO] Train accuracy: 56.9373\n",
      "[2024-03-11 10:58:07,376 INFO] Sentences processed: 159978\n",
      "[2024-03-11 10:58:07,376 INFO] Average bsz:  280/ 299/32\n",
      "[2024-03-11 10:58:07,376 INFO] Validation perplexity: 7.00052\n",
      "[2024-03-11 10:58:07,376 INFO] Validation accuracy: 66.6435\n",
      "[2024-03-11 10:58:07,376 INFO] Model is improving ppl: 7.24233 --> 7.00052.\n",
      "[2024-03-11 10:58:07,376 INFO] Model is improving acc: 65.6236 --> 66.6435.\n",
      "[2024-03-11 10:58:07,378 INFO] Saving checkpoint ./models/base/model_step_5000.pt\n",
      "[2024-03-11 10:58:11,227 INFO] Step 5020/50000; acc: 66.2; ppl:   5.2; xent: 1.6; lr: 1.00000; sents:     640; bsz:  322/ 307/32; 641/611 tok/s;    950 sec;\n",
      "[2024-03-11 10:58:14,764 INFO] Step 5040/50000; acc: 66.5; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  293/ 314/32; 1656/1778 tok/s;    954 sec;\n",
      "[2024-03-11 10:58:18,074 INFO] Step 5060/50000; acc: 72.5; ppl:   3.5; xent: 1.3; lr: 1.00000; sents:     640; bsz:  272/ 278/32; 1644/1680 tok/s;    957 sec;\n",
      "[2024-03-11 10:58:22,133 INFO] Step 5080/50000; acc: 69.1; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  286/ 314/32; 1411/1546 tok/s;    961 sec;\n",
      "[2024-03-11 10:58:25,926 INFO] Step 5100/50000; acc: 70.0; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  296/ 312/32; 1561/1645 tok/s;    965 sec;\n",
      "[2024-03-11 10:58:29,553 INFO] Step 5120/50000; acc: 69.5; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  309/ 321/32; 1703/1769 tok/s;    968 sec;\n",
      "[2024-03-11 10:58:33,125 INFO] Step 5140/50000; acc: 69.5; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  312/ 317/32; 1747/1774 tok/s;    972 sec;\n",
      "[2024-03-11 10:58:37,249 INFO] Step 5160/50000; acc: 69.6; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  296/ 325/32; 1436/1575 tok/s;    976 sec;\n",
      "[2024-03-11 10:58:41,039 INFO] Step 5180/50000; acc: 68.9; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  301/ 305/32; 1588/1608 tok/s;    980 sec;\n",
      "[2024-03-11 10:58:44,741 INFO] Step 5200/50000; acc: 71.3; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  262/ 283/32; 1418/1530 tok/s;    984 sec;\n",
      "[2024-03-11 10:58:48,614 INFO] Step 5220/50000; acc: 69.6; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  307/ 331/32; 1587/1708 tok/s;    988 sec;\n",
      "[2024-03-11 10:58:52,100 INFO] Step 5240/50000; acc: 75.6; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  242/ 270/32; 1386/1552 tok/s;    991 sec;\n",
      "[2024-03-11 10:58:55,562 INFO] Step 5260/50000; acc: 74.5; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  266/ 279/32; 1534/1609 tok/s;    994 sec;\n",
      "[2024-03-11 10:58:59,052 INFO] Step 5280/50000; acc: 74.8; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  250/ 270/32; 1431/1550 tok/s;    998 sec;\n",
      "[2024-03-11 10:59:02,253 INFO] Step 5300/50000; acc: 73.1; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  256/ 282/32; 1599/1759 tok/s;   1001 sec;\n",
      "[2024-03-11 10:59:05,458 INFO] Step 5320/50000; acc: 74.4; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  248/ 259/32; 1548/1618 tok/s;   1004 sec;\n",
      "[2024-03-11 10:59:09,135 INFO] Step 5340/50000; acc: 69.5; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  274/ 304/32; 1489/1654 tok/s;   1008 sec;\n",
      "[2024-03-11 10:59:12,734 INFO] Step 5360/50000; acc: 69.0; ppl:   4.8; xent: 1.6; lr: 1.00000; sents:     640; bsz:  298/ 299/32; 1654/1664 tok/s;   1012 sec;\n",
      "[2024-03-11 10:59:16,282 INFO] Step 5380/50000; acc: 70.3; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  266/ 299/32; 1497/1687 tok/s;   1015 sec;\n",
      "[2024-03-11 10:59:20,007 INFO] Step 5400/50000; acc: 69.2; ppl:   4.3; xent: 1.4; lr: 1.00000; sents:     640; bsz:  285/ 301/32; 1529/1616 tok/s;   1019 sec;\n",
      "[2024-03-11 10:59:24,043 INFO] Step 5420/50000; acc: 68.4; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  309/ 320/32; 1530/1586 tok/s;   1023 sec;\n",
      "[2024-03-11 10:59:27,659 INFO] Step 5440/50000; acc: 69.5; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  282/ 317/32; 1558/1755 tok/s;   1027 sec;\n",
      "[2024-03-11 10:59:31,359 INFO] Step 5460/50000; acc: 70.0; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  277/ 309/32; 1496/1669 tok/s;   1030 sec;\n",
      "[2024-03-11 10:59:35,124 INFO] Step 5480/50000; acc: 70.4; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  278/ 298/32; 1479/1581 tok/s;   1034 sec;\n",
      "[2024-03-11 10:59:39,046 INFO] Step 5500/50000; acc: 69.0; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  285/ 328/32; 1452/1672 tok/s;   1038 sec;\n",
      "[2024-03-11 10:59:45,423 INFO] valid stats calculation\n",
      "                           took: 6.375597953796387 s.\n",
      "[2024-03-11 10:59:45,423 INFO] Train perplexity: 9.88082\n",
      "[2024-03-11 10:59:45,423 INFO] Train accuracy: 58.1613\n",
      "[2024-03-11 10:59:45,423 INFO] Sentences processed: 175978\n",
      "[2024-03-11 10:59:45,423 INFO] Average bsz:  280/ 299/32\n",
      "[2024-03-11 10:59:45,423 INFO] Validation perplexity: 7.07974\n",
      "[2024-03-11 10:59:45,423 INFO] Validation accuracy: 66.2494\n",
      "[2024-03-11 10:59:45,423 INFO] Decreasing patience: 1/2\n",
      "[2024-03-11 10:59:49,132 INFO] Step 5520/50000; acc: 71.7; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  270/ 307/32; 536/609 tok/s;   1048 sec;\n",
      "[2024-03-11 10:59:52,709 INFO] Step 5540/50000; acc: 73.1; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  264/ 291/32; 1476/1628 tok/s;   1052 sec;\n",
      "[2024-03-11 10:59:56,638 INFO] Step 5560/50000; acc: 68.0; ppl:   4.8; xent: 1.6; lr: 1.00000; sents:     640; bsz:  278/ 311/32; 1417/1583 tok/s;   1056 sec;\n",
      "[2024-03-11 11:00:00,589 INFO] Step 5580/50000; acc: 69.8; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  288/ 307/32; 1458/1555 tok/s;   1060 sec;\n",
      "[2024-03-11 11:00:04,308 INFO] Step 5600/50000; acc: 72.2; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  269/ 294/32; 1446/1583 tok/s;   1063 sec;\n",
      "[2024-03-11 11:00:07,879 INFO] Step 5620/50000; acc: 75.2; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  264/ 286/32; 1479/1604 tok/s;   1067 sec;\n",
      "[2024-03-11 11:00:11,697 INFO] Step 5640/50000; acc: 69.0; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  283/ 306/32; 1484/1605 tok/s;   1071 sec;\n",
      "[2024-03-11 11:00:15,521 INFO] Step 5660/50000; acc: 73.8; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  250/ 286/32; 1305/1494 tok/s;   1074 sec;\n",
      "[2024-03-11 11:00:19,301 INFO] Step 5680/50000; acc: 73.5; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  278/ 286/32; 1473/1515 tok/s;   1078 sec;\n",
      "[2024-03-11 11:00:22,970 INFO] Step 5700/50000; acc: 71.4; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  267/ 293/32; 1456/1597 tok/s;   1082 sec;\n",
      "[2024-03-11 11:00:26,770 INFO] Step 5720/50000; acc: 70.4; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  291/ 312/32; 1533/1643 tok/s;   1086 sec;\n",
      "[2024-03-11 11:00:30,486 INFO] Step 5740/50000; acc: 71.7; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  272/ 291/32; 1464/1567 tok/s;   1089 sec;\n",
      "[2024-03-11 11:00:34,436 INFO] Step 5760/50000; acc: 73.6; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  301/ 301/32; 1523/1523 tok/s;   1093 sec;\n",
      "[2024-03-11 11:00:38,659 INFO] Step 5780/50000; acc: 68.7; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  288/ 307/32; 1364/1454 tok/s;   1098 sec;\n",
      "[2024-03-11 11:00:42,790 INFO] Step 5800/50000; acc: 67.7; ppl:   4.4; xent: 1.5; lr: 1.00000; sents:     640; bsz:  301/ 309/32; 1460/1496 tok/s;   1102 sec;\n",
      "[2024-03-11 11:00:46,650 INFO] Step 5820/50000; acc: 65.8; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  320/ 325/32; 1658/1683 tok/s;   1106 sec;\n",
      "[2024-03-11 11:00:50,226 INFO] Step 5840/50000; acc: 73.7; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  269/ 294/32; 1503/1646 tok/s;   1109 sec;\n",
      "[2024-03-11 11:00:53,935 INFO] Step 5860/50000; acc: 71.4; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  285/ 302/32; 1536/1631 tok/s;   1113 sec;\n",
      "[2024-03-11 11:00:57,428 INFO] Step 5880/50000; acc: 72.3; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  278/ 280/32; 1594/1605 tok/s;   1116 sec;\n",
      "[2024-03-11 11:01:00,986 INFO] Step 5900/50000; acc: 73.4; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  262/ 290/32; 1475/1628 tok/s;   1120 sec;\n",
      "[2024-03-11 11:01:04,452 INFO] Step 5920/50000; acc: 72.8; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  266/ 294/32; 1533/1699 tok/s;   1123 sec;\n",
      "[2024-03-11 11:01:08,109 INFO] Step 5940/50000; acc: 75.7; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  274/ 274/32; 1496/1496 tok/s;   1127 sec;\n",
      "[2024-03-11 11:01:12,383 INFO] Step 5960/50000; acc: 73.7; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  275/ 290/32; 1288/1356 tok/s;   1131 sec;\n",
      "[2024-03-11 11:01:16,553 INFO] Step 5980/50000; acc: 71.7; ppl:   3.5; xent: 1.2; lr: 1.00000; sents:     640; bsz:  301/ 326/32; 1443/1564 tok/s;   1135 sec;\n",
      "[2024-03-11 11:01:20,345 INFO] Step 6000/50000; acc: 70.5; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  298/ 300/32; 1570/1584 tok/s;   1139 sec;\n",
      "[2024-03-11 11:01:26,347 INFO] valid stats calculation\n",
      "                           took: 6.000931739807129 s.\n",
      "[2024-03-11 11:01:26,347 INFO] Train perplexity: 9.07728\n",
      "[2024-03-11 11:01:26,347 INFO] Train accuracy: 59.2761\n",
      "[2024-03-11 11:01:26,347 INFO] Sentences processed: 191978\n",
      "[2024-03-11 11:01:26,347 INFO] Average bsz:  280/ 299/32\n",
      "[2024-03-11 11:01:26,347 INFO] Validation perplexity: 7.20232\n",
      "[2024-03-11 11:01:26,347 INFO] Validation accuracy: 66.6203\n",
      "[2024-03-11 11:01:26,347 INFO] Decreasing patience: 0/2\n",
      "[2024-03-11 11:01:26,347 INFO] Training finished after not improving. Early Stop!\n",
      "[2024-03-11 11:01:26,347 INFO] Best model found at step 5000\n",
      "[2024-03-11 11:01:26,347 INFO] earlystopper has_stopped!\n",
      "[2024-03-11 11:01:27,938 INFO] Saving checkpoint ./models/base/model_step_6000.pt\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config ./configs/config-early-stopping.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 11:07:41,898 INFO] Loading checkpoint from ./models/base/model_step_5000.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:07:42,227 INFO] Loading data into the model\n",
      "[2024-03-11 11:07:44,538 INFO] PRED SCORE: -0.4034, PRED PPL: 1.50 NB SENTENCES: 469\n",
      "Time w/o python interpreter load/terminate:  2.649181842803955\n",
      "BLEU = 30.31, 59.5/35.3/24.7/16.3 (BP=1.000, ratio=1.000, hyp_len=3574, ref_len=3574)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!onmt_translate -model ./models/base/model_step_5000.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_5000.txt\n",
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_5000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11**: Augmenter le nombre de steps permet d'obtenir un meilleur score jusqu'à ce que le modèle overfit. On peut donc utiliser l'option early-stopping pour arrêter l'entrainement du modèle lorsqu'il ne s'améliore pas pendant un certain nombre de validations d'affilé. Notre modèle s'améliore jusqu'à 5000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 11:14:57,137 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2024-03-11 11:14:57,138 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2024-03-11 11:14:57,138 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2024-03-11 11:14:57,138 INFO] Parsed 2 corpora from -data.\n",
      "[2024-03-11 11:14:57,138 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2024-03-11 11:14:57,161 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '.', '?', 'de', ',', 'vous', 'Je']\n",
      "[2024-03-11 11:14:57,161 INFO] The decoder start token is: <s>\n",
      "[2024-03-11 11:14:57,161 INFO] Building model...\n",
      "[2024-03-11 11:14:57,673 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2024-03-11 11:14:57,673 INFO] Non quantized layer compute is fp32\n",
      "[2024-03-11 11:14:57,675 INFO] NMTModel(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(9984, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (rnn): LSTM(500, 250, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): InputFeedRNNDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(8200, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(1000, 500)\n",
      "        (1): LSTMCell(500, 500)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=500, out_features=8200, bias=True)\n",
      ")\n",
      "[2024-03-11 11:14:57,675 INFO] encoder: 8000000\n",
      "[2024-03-11 11:14:57,675 INFO] decoder: 13216200\n",
      "[2024-03-11 11:14:57,675 INFO] * number of parameters: 21216200\n",
      "[2024-03-11 11:14:57,675 INFO] Trainable parameters = {'torch.float32': 21216200, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 11:14:57,675 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 11:14:57,675 INFO]  * src vocab size = 9984\n",
      "[2024-03-11 11:14:57,675 INFO]  * tgt vocab size = 8200\n",
      "[2024-03-11 11:14:58,028 INFO] Starting training on CPU, could be very slow\n",
      "[2024-03-11 11:14:58,028 INFO] Start training loop and validate every 500 steps...\n",
      "[2024-03-11 11:14:58,029 INFO] Scoring with: TransformPipe()\n",
      "[2024-03-11 11:14:59,932 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 11:15:01,772 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 11:15:01,872 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 11:15:01,900 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 11:15:02,122 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 11:15:02,133 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 11:15:02,388 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 11:15:02,397 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 11:15:02,520 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 11:15:02,532 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 11:15:02,830 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 11:15:02,837 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 11:15:02,950 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 11:15:02,955 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 11:15:03,303 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 11:15:03,307 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 11:15:03,434 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 11:15:03,439 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 11:15:03,552 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 11:15:03,559 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 11:15:04,055 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 11:15:04,072 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 11:15:04,204 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 11:15:04,214 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 11:15:04,327 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 11:15:04,342 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 11:15:04,861 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 11:15:04,875 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 11:15:04,983 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 11:15:04,999 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 11:15:05,103 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 11:15:05,121 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 11:15:05,228 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 11:15:05,260 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 11:15:05,819 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 11:15:05,848 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 11:15:05,945 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 11:15:05,972 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 11:15:06,063 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 11:15:06,092 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 11:15:06,203 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 11:15:06,229 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 11:15:06,346 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 11:15:06,361 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 11:15:07,058 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 11:15:07,062 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 11:15:07,225 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 11:15:07,227 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 11:15:07,346 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 11:15:07,347 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 11:15:07,466 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 11:15:07,466 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 11:15:07,588 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 11:15:07,588 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 11:15:20,948 INFO] Step 20/ 2001; acc: 9.7; ppl: 5917.8; xent: 8.7; lr: 1.00000; sents:     640; bsz:  283/ 294/32; 247/257 tok/s;     23 sec;\n",
      "[2024-03-11 11:15:25,582 INFO] Step 40/ 2001; acc: 10.6; ppl: 949.3; xent: 6.9; lr: 1.00000; sents:     640; bsz:  277/ 293/32; 1195/1264 tok/s;     28 sec;\n",
      "[2024-03-11 11:15:30,726 INFO] Step 60/ 2001; acc: 8.8; ppl: 527.6; xent: 6.3; lr: 1.00000; sents:     640; bsz:  310/ 338/32; 1207/1315 tok/s;     33 sec;\n",
      "[2024-03-11 11:15:37,112 INFO] Step 80/ 2001; acc: 10.9; ppl: 362.3; xent: 5.9; lr: 1.00000; sents:     640; bsz:  285/ 310/32; 892/972 tok/s;     39 sec;\n",
      "[2024-03-11 11:15:42,254 INFO] Step 100/ 2001; acc: 16.4; ppl: 242.3; xent: 5.5; lr: 1.00000; sents:     640; bsz:  278/ 302/32; 1083/1176 tok/s;     44 sec;\n",
      "[2024-03-11 11:15:48,500 INFO] Step 120/ 2001; acc: 17.5; ppl: 214.3; xent: 5.4; lr: 1.00000; sents:     640; bsz:  315/ 357/32; 1009/1143 tok/s;     50 sec;\n",
      "[2024-03-11 11:15:54,004 INFO] Step 140/ 2001; acc: 22.1; ppl: 166.0; xent: 5.1; lr: 1.00000; sents:     640; bsz:  274/ 282/32; 994/1023 tok/s;     56 sec;\n",
      "[2024-03-11 11:15:59,676 INFO] Step 160/ 2001; acc: 24.9; ppl: 129.2; xent: 4.9; lr: 1.00000; sents:     640; bsz:  259/ 291/32; 914/1027 tok/s;     62 sec;\n",
      "[2024-03-11 11:16:04,880 INFO] Step 180/ 2001; acc: 30.6; ppl:  92.4; xent: 4.5; lr: 1.00000; sents:     640; bsz:  229/ 256/32; 880/985 tok/s;     67 sec;\n",
      "[2024-03-11 11:16:11,746 INFO] Step 200/ 2001; acc: 25.1; ppl: 143.8; xent: 5.0; lr: 1.00000; sents:     640; bsz:  302/ 326/32; 881/951 tok/s;     74 sec;\n",
      "[2024-03-11 11:16:16,279 INFO] Step 220/ 2001; acc: 30.6; ppl:  88.4; xent: 4.5; lr: 1.00000; sents:     640; bsz:  246/ 261/32; 1089/1152 tok/s;     78 sec;\n",
      "[2024-03-11 11:16:21,091 INFO] Step 240/ 2001; acc: 33.1; ppl:  75.0; xent: 4.3; lr: 1.00000; sents:     640; bsz:  219/ 262/32; 911/1091 tok/s;     83 sec;\n",
      "[2024-03-11 11:16:26,464 INFO] Step 260/ 2001; acc: 31.0; ppl:  86.8; xent: 4.5; lr: 1.00000; sents:     640; bsz:  270/ 291/32; 1007/1084 tok/s;     88 sec;\n",
      "[2024-03-11 11:16:32,129 INFO] Step 280/ 2001; acc: 31.2; ppl:  80.6; xent: 4.4; lr: 1.00000; sents:     640; bsz:  275/ 280/32; 972/989 tok/s;     94 sec;\n",
      "[2024-03-11 11:16:38,082 INFO] Step 300/ 2001; acc: 28.8; ppl:  98.6; xent: 4.6; lr: 1.00000; sents:     640; bsz:  325/ 317/32; 1091/1064 tok/s;    100 sec;\n",
      "[2024-03-11 11:16:44,649 INFO] Step 320/ 2001; acc: 35.1; ppl:  73.2; xent: 4.3; lr: 1.00000; sents:     640; bsz:  278/ 274/32; 849/836 tok/s;    107 sec;\n",
      "[2024-03-11 11:16:49,946 INFO] Step 340/ 2001; acc: 36.0; ppl:  54.5; xent: 4.0; lr: 1.00000; sents:     640; bsz:  246/ 282/32; 931/1064 tok/s;    112 sec;\n",
      "[2024-03-11 11:16:55,383 INFO] Step 360/ 2001; acc: 35.3; ppl:  66.7; xent: 4.2; lr: 1.00000; sents:     640; bsz:  278/ 290/32; 1024/1065 tok/s;    117 sec;\n",
      "[2024-03-11 11:17:00,551 INFO] Step 380/ 2001; acc: 34.2; ppl:  74.3; xent: 4.3; lr: 1.00000; sents:     640; bsz:  294/ 298/32; 1139/1152 tok/s;    123 sec;\n",
      "[2024-03-11 11:17:05,364 INFO] Step 400/ 2001; acc: 34.1; ppl:  61.1; xent: 4.1; lr: 1.00000; sents:     640; bsz:  280/ 318/32; 1164/1323 tok/s;    127 sec;\n",
      "[2024-03-11 11:17:10,271 INFO] Step 420/ 2001; acc: 33.1; ppl:  65.3; xent: 4.2; lr: 1.00000; sents:     640; bsz:  286/ 325/32; 1167/1324 tok/s;    132 sec;\n",
      "[2024-03-11 11:17:14,789 INFO] Step 440/ 2001; acc: 39.2; ppl:  54.7; xent: 4.0; lr: 1.00000; sents:     640; bsz:  253/ 261/32; 1119/1157 tok/s;    137 sec;\n",
      "[2024-03-11 11:17:20,992 INFO] Step 460/ 2001; acc: 36.0; ppl:  57.6; xent: 4.1; lr: 1.00000; sents:     640; bsz:  278/ 299/32; 898/965 tok/s;    143 sec;\n",
      "[2024-03-11 11:17:25,994 INFO] Step 480/ 2001; acc: 42.8; ppl:  34.3; xent: 3.5; lr: 1.00000; sents:     640; bsz:  206/ 259/32; 825/1036 tok/s;    148 sec;\n",
      "[2024-03-11 11:17:32,778 INFO] Step 500/ 2001; acc: 32.0; ppl:  71.8; xent: 4.3; lr: 1.00000; sents:     640; bsz:  362/ 380/32; 1066/1120 tok/s;    155 sec;\n",
      "[2024-03-11 11:19:36,386 INFO] valid stats calculation\n",
      "                           took: 123.60110664367676 s.\n",
      "[2024-03-11 11:19:36,393 INFO] Train perplexity: 130.475\n",
      "[2024-03-11 11:19:36,394 INFO] Train accuracy: 27.2044\n",
      "[2024-03-11 11:19:36,394 INFO] Sentences processed: 16000\n",
      "[2024-03-11 11:19:36,394 INFO] Average bsz:  276/ 298/32\n",
      "[2024-03-11 11:19:36,394 INFO] Validation perplexity: 51.7899\n",
      "[2024-03-11 11:19:36,394 INFO] Validation accuracy: 36.4859\n",
      "[2024-03-11 11:19:42,414 INFO] Step 520/ 2001; acc: 36.9; ppl:  50.6; xent: 3.9; lr: 1.00000; sents:     640; bsz:  269/ 302/32;  41/ 47 tok/s;    284 sec;\n",
      "[2024-03-11 11:19:48,653 INFO] Step 540/ 2001; acc: 34.8; ppl:  61.3; xent: 4.1; lr: 1.00000; sents:     640; bsz:  307/ 329/32; 983/1055 tok/s;    291 sec;\n",
      "[2024-03-11 11:19:53,792 INFO] Step 560/ 2001; acc: 39.0; ppl:  47.9; xent: 3.9; lr: 1.00000; sents:     640; bsz:  309/ 310/32; 1202/1209 tok/s;    296 sec;\n",
      "[2024-03-11 11:19:59,427 INFO] Step 580/ 2001; acc: 36.6; ppl:  53.2; xent: 4.0; lr: 1.00000; sents:     640; bsz:  341/ 339/32; 1209/1204 tok/s;    301 sec;\n",
      "[2024-03-11 11:20:04,059 INFO] Step 600/ 2001; acc: 41.7; ppl:  38.3; xent: 3.6; lr: 1.00000; sents:     640; bsz:  256/ 278/32; 1106/1202 tok/s;    306 sec;\n",
      "[2024-03-11 11:20:09,310 INFO] Step 620/ 2001; acc: 37.8; ppl:  45.3; xent: 3.8; lr: 1.00000; sents:     640; bsz:  304/ 325/32; 1158/1237 tok/s;    311 sec;\n",
      "[2024-03-11 11:20:15,775 INFO] Step 640/ 2001; acc: 36.8; ppl:  45.0; xent: 3.8; lr: 1.00000; sents:     640; bsz:  309/ 348/32; 955/1076 tok/s;    318 sec;\n",
      "[2024-03-11 11:20:21,223 INFO] Step 660/ 2001; acc: 39.7; ppl:  40.2; xent: 3.7; lr: 1.00000; sents:     640; bsz:  304/ 315/32; 1116/1157 tok/s;    323 sec;\n",
      "[2024-03-11 11:20:25,892 INFO] Step 680/ 2001; acc: 41.5; ppl:  37.0; xent: 3.6; lr: 1.00000; sents:     640; bsz:  250/ 282/32; 1069/1206 tok/s;    328 sec;\n",
      "[2024-03-11 11:20:30,957 INFO] Step 700/ 2001; acc: 41.5; ppl:  35.8; xent: 3.6; lr: 1.00000; sents:     640; bsz:  294/ 306/32; 1163/1207 tok/s;    333 sec;\n",
      "[2024-03-11 11:20:35,488 INFO] Step 720/ 2001; acc: 46.0; ppl:  27.5; xent: 3.3; lr: 1.00000; sents:     640; bsz:  243/ 272/32; 1073/1201 tok/s;    337 sec;\n",
      "[2024-03-11 11:20:40,883 INFO] Step 740/ 2001; acc: 40.4; ppl:  39.5; xent: 3.7; lr: 1.00000; sents:     640; bsz:  291/ 302/32; 1080/1121 tok/s;    343 sec;\n",
      "[2024-03-11 11:20:46,622 INFO] Step 760/ 2001; acc: 44.5; ppl:  29.7; xent: 3.4; lr: 1.00000; sents:     640; bsz:  270/ 290/32; 943/1010 tok/s;    349 sec;\n",
      "[2024-03-11 11:20:52,567 INFO] Step 780/ 2001; acc: 43.8; ppl:  33.6; xent: 3.5; lr: 1.00000; sents:     640; bsz:  250/ 269/32; 840/905 tok/s;    355 sec;\n",
      "[2024-03-11 11:20:58,788 INFO] Step 800/ 2001; acc: 42.4; ppl:  33.6; xent: 3.5; lr: 1.00000; sents:     640; bsz:  282/ 302/32; 905/972 tok/s;    361 sec;\n",
      "[2024-03-11 11:21:03,831 INFO] Step 820/ 2001; acc: 44.3; ppl:  32.0; xent: 3.5; lr: 1.00000; sents:     640; bsz:  280/ 288/32; 1110/1142 tok/s;    366 sec;\n",
      "[2024-03-11 11:21:09,253 INFO] Step 840/ 2001; acc: 41.8; ppl:  33.5; xent: 3.5; lr: 1.00000; sents:     640; bsz:  312/ 314/32; 1151/1157 tok/s;    371 sec;\n",
      "[2024-03-11 11:21:16,217 INFO] Step 860/ 2001; acc: 41.3; ppl:  33.4; xent: 3.5; lr: 1.00000; sents:     640; bsz:  322/ 349/32; 924/1001 tok/s;    378 sec;\n",
      "[2024-03-11 11:21:21,578 INFO] Step 880/ 2001; acc: 43.5; ppl:  31.7; xent: 3.5; lr: 1.00000; sents:     640; bsz:  283/ 286/32; 1058/1069 tok/s;    384 sec;\n",
      "[2024-03-11 11:21:26,968 INFO] Step 900/ 2001; acc: 43.6; ppl:  30.9; xent: 3.4; lr: 1.00000; sents:     640; bsz:  298/ 306/32; 1104/1134 tok/s;    389 sec;\n",
      "[2024-03-11 11:21:31,938 INFO] Step 920/ 2001; acc: 44.5; ppl:  28.3; xent: 3.3; lr: 1.00000; sents:     640; bsz:  264/ 287/32; 1062/1155 tok/s;    394 sec;\n",
      "[2024-03-11 11:21:37,301 INFO] Step 940/ 2001; acc: 45.2; ppl:  24.9; xent: 3.2; lr: 1.00000; sents:     640; bsz:  269/ 307/32; 1003/1144 tok/s;    399 sec;\n",
      "[2024-03-11 11:21:42,503 INFO] Step 960/ 2001; acc: 45.4; ppl:  28.2; xent: 3.3; lr: 1.00000; sents:     640; bsz:  291/ 286/32; 1119/1098 tok/s;    404 sec;\n",
      "[2024-03-11 11:21:48,454 INFO] Step 980/ 2001; acc: 45.0; ppl:  27.3; xent: 3.3; lr: 1.00000; sents:     640; bsz:  264/ 303/32; 887/1020 tok/s;    410 sec;\n",
      "[2024-03-11 11:21:53,675 INFO] Step 1000/ 2001; acc: 46.2; ppl:  24.5; xent: 3.2; lr: 1.00000; sents:     640; bsz:  266/ 290/32; 1019/1111 tok/s;    416 sec;\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config ./configs/config-multiple-layers.yaml\n",
    "!onmt_translate -model ./models/base/model_step_2001.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_2001.txt\n",
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_2001.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12**: Cela permet d'obtenir de meilleurs résultats car on augmente la profondeur du réseau de neuronnes donc il est plus apte à comprendre des données plus complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 11:32:59,539 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2024-03-11 11:32:59,539 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2024-03-11 11:32:59,539 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2024-03-11 11:32:59,540 INFO] Parsed 2 corpora from -data.\n",
      "[2024-03-11 11:32:59,540 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2024-03-11 11:32:59,563 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '.', '?', 'de', ',', 'vous', 'Je']\n",
      "[2024-03-11 11:32:59,563 INFO] The decoder start token is: <s>\n",
      "[2024-03-11 11:32:59,563 INFO] Building model...\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:33:00,032 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2024-03-11 11:33:00,032 INFO] Non quantized layer compute is fp32\n",
      "[2024-03-11 11:33:00,034 INFO] NMTModel(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(9984, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (rnn): LSTM(500, 250, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): InputFeedRNNDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(8200, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(1000, 500)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=500, out_features=8200, bias=True)\n",
      ")\n",
      "[2024-03-11 11:33:00,034 INFO] encoder: 6496000\n",
      "[2024-03-11 11:33:00,034 INFO] decoder: 11212200\n",
      "[2024-03-11 11:33:00,034 INFO] * number of parameters: 17708200\n",
      "[2024-03-11 11:33:00,034 INFO] Trainable parameters = {'torch.float32': 17708200, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 11:33:00,034 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 11:33:00,034 INFO]  * src vocab size = 9984\n",
      "[2024-03-11 11:33:00,034 INFO]  * tgt vocab size = 8200\n",
      "[2024-03-11 11:33:00,494 INFO] Starting training on CPU, could be very slow\n",
      "[2024-03-11 11:33:00,494 INFO] Start training loop and validate every 501 steps...\n",
      "[2024-03-11 11:33:00,494 INFO] Scoring with: TransformPipe()\n",
      "[2024-03-11 11:33:02,455 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 11:33:04,337 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 11:33:04,444 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 11:33:04,469 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 11:33:04,695 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 11:33:04,718 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 11:33:04,952 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 11:33:04,979 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 11:33:05,105 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 11:33:05,115 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 11:33:05,422 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 11:33:05,425 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 11:33:05,586 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 11:33:05,593 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 11:33:05,971 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 11:33:05,974 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 11:33:06,133 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 11:33:06,143 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 11:33:06,304 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 11:33:06,313 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 11:33:06,736 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 11:33:06,742 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 11:33:06,903 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 11:33:06,914 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 11:33:07,079 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 11:33:07,089 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 11:33:07,580 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 11:33:07,586 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 11:33:07,745 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 11:33:07,754 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 11:33:07,929 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 11:33:07,931 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 11:33:08,110 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 11:33:08,154 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 11:33:08,695 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 11:33:08,736 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 11:33:08,860 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 11:33:08,932 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 11:33:09,044 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 11:33:09,111 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 11:33:09,228 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 11:33:09,296 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 11:33:09,415 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 11:33:09,474 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 11:33:10,167 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 11:33:10,207 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 11:33:10,328 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 11:33:10,370 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 11:33:10,557 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 11:33:10,643 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 11:33:10,817 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 11:33:10,864 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 11:33:11,023 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 11:33:11,062 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 11:33:23,796 INFO] Step 20/ 2002; acc: 8.4; ppl: 7412.1; xent: 8.9; lr: 1.00000; sents:     640; bsz:  248/ 272/32; 213/233 tok/s;     23 sec;\n",
      "[2024-03-11 11:33:28,273 INFO] Step 40/ 2002; acc: 17.6; ppl: 415.2; xent: 6.0; lr: 1.00000; sents:     640; bsz:  290/ 287/32; 1294/1283 tok/s;     28 sec;\n",
      "[2024-03-11 11:33:33,070 INFO] Step 60/ 2002; acc: 20.7; ppl: 238.9; xent: 5.5; lr: 1.00000; sents:     640; bsz:  294/ 304/32; 1228/1268 tok/s;     33 sec;\n",
      "[2024-03-11 11:33:37,556 INFO] Step 80/ 2002; acc: 22.1; ppl: 198.4; xent: 5.3; lr: 1.00000; sents:     640; bsz:  283/ 298/32; 1263/1327 tok/s;     37 sec;\n",
      "[2024-03-11 11:33:42,274 INFO] Step 100/ 2002; acc: 24.2; ppl: 152.1; xent: 5.0; lr: 1.00000; sents:     640; bsz:  302/ 310/32; 1282/1316 tok/s;     42 sec;\n",
      "[2024-03-11 11:33:47,111 INFO] Step 120/ 2002; acc: 24.0; ppl: 135.2; xent: 4.9; lr: 1.00000; sents:     640; bsz:  317/ 336/32; 1310/1389 tok/s;     47 sec;\n",
      "[2024-03-11 11:33:50,955 INFO] Step 140/ 2002; acc: 34.7; ppl:  76.3; xent: 4.3; lr: 1.00000; sents:     640; bsz:  240/ 254/32; 1249/1322 tok/s;     50 sec;\n",
      "[2024-03-11 11:33:55,679 INFO] Step 160/ 2002; acc: 31.2; ppl:  90.7; xent: 4.5; lr: 1.00000; sents:     640; bsz:  266/ 285/32; 1125/1206 tok/s;     55 sec;\n",
      "[2024-03-11 11:34:00,149 INFO] Step 180/ 2002; acc: 33.7; ppl:  79.2; xent: 4.4; lr: 1.00000; sents:     640; bsz:  254/ 279/32; 1138/1248 tok/s;     60 sec;\n",
      "[2024-03-11 11:34:05,225 INFO] Step 200/ 2002; acc: 31.7; ppl:  75.5; xent: 4.3; lr: 1.00000; sents:     640; bsz:  285/ 318/32; 1123/1255 tok/s;     65 sec;\n",
      "[2024-03-11 11:34:10,084 INFO] Step 220/ 2002; acc: 34.2; ppl:  80.2; xent: 4.4; lr: 1.00000; sents:     640; bsz:  291/ 299/32; 1200/1233 tok/s;     70 sec;\n",
      "[2024-03-11 11:34:15,639 INFO] Step 240/ 2002; acc: 30.4; ppl:  79.3; xent: 4.4; lr: 1.00000; sents:     640; bsz:  346/ 368/32; 1244/1325 tok/s;     75 sec;\n",
      "[2024-03-11 11:34:20,435 INFO] Step 260/ 2002; acc: 34.8; ppl:  64.4; xent: 4.2; lr: 1.00000; sents:     640; bsz:  294/ 310/32; 1228/1295 tok/s;     80 sec;\n",
      "[2024-03-11 11:34:25,092 INFO] Step 280/ 2002; acc: 34.5; ppl:  71.2; xent: 4.3; lr: 1.00000; sents:     640; bsz:  283/ 295/32; 1216/1266 tok/s;     85 sec;\n",
      "[2024-03-11 11:34:28,514 INFO] Step 300/ 2002; acc: 40.1; ppl:  40.9; xent: 3.7; lr: 1.00000; sents:     640; bsz:  238/ 290/32; 1393/1692 tok/s;     88 sec;\n",
      "[2024-03-11 11:34:32,160 INFO] Step 320/ 2002; acc: 40.3; ppl:  46.9; xent: 3.8; lr: 1.00000; sents:     640; bsz:  221/ 243/32; 1211/1334 tok/s;     92 sec;\n",
      "[2024-03-11 11:34:35,664 INFO] Step 340/ 2002; acc: 37.9; ppl:  49.9; xent: 3.9; lr: 1.00000; sents:     640; bsz:  288/ 307/32; 1644/1753 tok/s;     95 sec;\n",
      "[2024-03-11 11:34:38,834 INFO] Step 360/ 2002; acc: 40.3; ppl:  46.4; xent: 3.8; lr: 1.00000; sents:     640; bsz:  272/ 279/32; 1716/1759 tok/s;     98 sec;\n",
      "[2024-03-11 11:34:42,167 INFO] Step 380/ 2002; acc: 39.0; ppl:  46.4; xent: 3.8; lr: 1.00000; sents:     640; bsz:  291/ 298/32; 1747/1786 tok/s;    102 sec;\n",
      "[2024-03-11 11:34:45,310 INFO] Step 400/ 2002; acc: 40.4; ppl:  45.3; xent: 3.8; lr: 1.00000; sents:     640; bsz:  251/ 278/32; 1599/1772 tok/s;    105 sec;\n",
      "[2024-03-11 11:34:48,884 INFO] Step 420/ 2002; acc: 37.2; ppl:  49.0; xent: 3.9; lr: 1.00000; sents:     640; bsz:  299/ 333/32; 1675/1863 tok/s;    108 sec;\n",
      "[2024-03-11 11:34:51,934 INFO] Step 440/ 2002; acc: 42.7; ppl:  37.4; xent: 3.6; lr: 1.00000; sents:     640; bsz:  266/ 277/32; 1742/1819 tok/s;    111 sec;\n",
      "[2024-03-11 11:34:55,248 INFO] Step 460/ 2002; acc: 37.4; ppl:  52.1; xent: 4.0; lr: 1.00000; sents:     640; bsz:  307/ 302/32; 1854/1823 tok/s;    115 sec;\n",
      "[2024-03-11 11:34:58,176 INFO] Step 480/ 2002; acc: 47.0; ppl:  27.8; xent: 3.3; lr: 1.00000; sents:     640; bsz:  232/ 261/32; 1585/1783 tok/s;    118 sec;\n",
      "[2024-03-11 11:35:01,260 INFO] Step 500/ 2002; acc: 43.5; ppl:  32.9; xent: 3.5; lr: 1.00000; sents:     640; bsz:  256/ 280/32; 1660/1815 tok/s;    121 sec;\n",
      "[2024-03-11 11:35:08,432 INFO] valid stats calculation\n",
      "                           took: 7.0218164920806885 s.\n",
      "[2024-03-11 11:35:08,433 INFO] Train perplexity: 86.7864\n",
      "[2024-03-11 11:35:08,433 INFO] Train accuracy: 32.9508\n",
      "[2024-03-11 11:35:08,433 INFO] Sentences processed: 16032\n",
      "[2024-03-11 11:35:08,433 INFO] Average bsz:  277/ 294/32\n",
      "[2024-03-11 11:35:08,433 INFO] Validation perplexity: 28.8202\n",
      "[2024-03-11 11:35:08,433 INFO] Validation accuracy: 45.4567\n",
      "[2024-03-11 11:35:11,306 INFO] Step 520/ 2002; acc: 43.0; ppl:  34.4; xent: 3.5; lr: 1.00000; sents:     640; bsz:  253/ 278/32; 503/554 tok/s;    131 sec;\n",
      "[2024-03-11 11:35:14,887 INFO] Step 540/ 2002; acc: 39.9; ppl:  40.8; xent: 3.7; lr: 1.00000; sents:     640; bsz:  322/ 337/32; 1796/1882 tok/s;    134 sec;\n",
      "[2024-03-11 11:35:18,131 INFO] Step 560/ 2002; acc: 39.8; ppl:  40.9; xent: 3.7; lr: 1.00000; sents:     640; bsz:  283/ 306/32; 1746/1885 tok/s;    138 sec;\n",
      "[2024-03-11 11:35:21,111 INFO] Step 580/ 2002; acc: 46.2; ppl:  29.6; xent: 3.4; lr: 1.00000; sents:     640; bsz:  254/ 272/32; 1708/1826 tok/s;    141 sec;\n",
      "[2024-03-11 11:35:23,953 INFO] Step 600/ 2002; acc: 44.9; ppl:  32.3; xent: 3.5; lr: 1.00000; sents:     640; bsz:  248/ 258/32; 1745/1813 tok/s;    143 sec;\n",
      "[2024-03-11 11:35:26,889 INFO] Step 620/ 2002; acc: 47.3; ppl:  25.5; xent: 3.2; lr: 1.00000; sents:     640; bsz:  243/ 270/32; 1657/1842 tok/s;    146 sec;\n",
      "[2024-03-11 11:35:30,180 INFO] Step 640/ 2002; acc: 43.6; ppl:  32.4; xent: 3.5; lr: 1.00000; sents:     640; bsz:  280/ 299/32; 1703/1819 tok/s;    150 sec;\n",
      "[2024-03-11 11:35:33,460 INFO] Step 660/ 2002; acc: 46.0; ppl:  25.6; xent: 3.2; lr: 1.00000; sents:     640; bsz:  256/ 296/32; 1561/1805 tok/s;    153 sec;\n",
      "[2024-03-11 11:35:37,865 INFO] Step 680/ 2002; acc: 40.0; ppl:  48.4; xent: 3.9; lr: 1.00000; sents:     604; bsz:  325/ 328/30; 1476/1489 tok/s;    157 sec;\n",
      "[2024-03-11 11:35:40,962 INFO] Step 700/ 2002; acc: 45.8; ppl:  27.6; xent: 3.3; lr: 1.00000; sents:     640; bsz:  254/ 272/32; 1643/1757 tok/s;    160 sec;\n",
      "[2024-03-11 11:35:44,014 INFO] Step 720/ 2002; acc: 44.9; ppl:  28.1; xent: 3.3; lr: 1.00000; sents:     640; bsz:  248/ 282/32; 1625/1846 tok/s;    164 sec;\n",
      "[2024-03-11 11:35:47,103 INFO] Step 740/ 2002; acc: 44.8; ppl:  29.0; xent: 3.4; lr: 1.00000; sents:     640; bsz:  270/ 307/32; 1751/1989 tok/s;    167 sec;\n",
      "[2024-03-11 11:35:50,090 INFO] Step 760/ 2002; acc: 46.0; ppl:  25.0; xent: 3.2; lr: 1.00000; sents:     640; bsz:  288/ 296/32; 1928/1982 tok/s;    170 sec;\n",
      "[2024-03-11 11:35:53,095 INFO] Step 780/ 2002; acc: 49.0; ppl:  21.5; xent: 3.1; lr: 1.00000; sents:     640; bsz:  256/ 288/32; 1704/1917 tok/s;    173 sec;\n",
      "[2024-03-11 11:35:56,636 INFO] Step 800/ 2002; acc: 41.7; ppl:  30.6; xent: 3.4; lr: 1.00000; sents:     640; bsz:  328/ 346/32; 1854/1957 tok/s;    176 sec;\n",
      "[2024-03-11 11:36:00,208 INFO] Step 820/ 2002; acc: 47.0; ppl:  24.3; xent: 3.2; lr: 1.00000; sents:     640; bsz:  254/ 283/32; 1424/1586 tok/s;    180 sec;\n",
      "[2024-03-11 11:36:04,746 INFO] Step 840/ 2002; acc: 48.8; ppl:  20.8; xent: 3.0; lr: 1.00000; sents:     640; bsz:  259/ 291/32; 1143/1284 tok/s;    184 sec;\n",
      "[2024-03-11 11:36:08,668 INFO] Step 860/ 2002; acc: 45.9; ppl:  27.0; xent: 3.3; lr: 1.00000; sents:     640; bsz:  280/ 306/32; 1428/1563 tok/s;    188 sec;\n",
      "[2024-03-11 11:36:12,295 INFO] Step 880/ 2002; acc: 49.1; ppl:  22.4; xent: 3.1; lr: 1.00000; sents:     640; bsz:  262/ 267/32; 1447/1473 tok/s;    192 sec;\n",
      "[2024-03-11 11:36:15,655 INFO] Step 900/ 2002; acc: 48.7; ppl:  23.8; xent: 3.2; lr: 1.00000; sents:     640; bsz:  288/ 272/32; 1715/1620 tok/s;    195 sec;\n",
      "[2024-03-11 11:36:19,296 INFO] Step 920/ 2002; acc: 47.1; ppl:  23.6; xent: 3.2; lr: 1.00000; sents:     640; bsz:  286/ 299/32; 1573/1644 tok/s;    199 sec;\n",
      "[2024-03-11 11:36:22,549 INFO] Step 940/ 2002; acc: 51.1; ppl:  18.9; xent: 2.9; lr: 1.00000; sents:     640; bsz:  251/ 266/32; 1545/1633 tok/s;    202 sec;\n",
      "[2024-03-11 11:36:25,963 INFO] Step 960/ 2002; acc: 46.6; ppl:  25.7; xent: 3.2; lr: 1.00000; sents:     640; bsz:  315/ 306/32; 1847/1790 tok/s;    205 sec;\n",
      "[2024-03-11 11:36:29,648 INFO] Step 980/ 2002; acc: 48.1; ppl:  22.4; xent: 3.1; lr: 1.00000; sents:     640; bsz:  282/ 298/32; 1528/1615 tok/s;    209 sec;\n",
      "[2024-03-11 11:36:34,106 INFO] Step 1000/ 2002; acc: 45.3; ppl:  24.0; xent: 3.2; lr: 1.00000; sents:     640; bsz:  314/ 339/32; 1407/1522 tok/s;    214 sec;\n",
      "[2024-03-11 11:36:41,271 INFO] valid stats calculation\n",
      "                           took: 6.866647958755493 s.\n",
      "[2024-03-11 11:36:41,272 INFO] Train perplexity: 48.9273\n",
      "[2024-03-11 11:36:41,272 INFO] Train accuracy: 39.2323\n",
      "[2024-03-11 11:36:41,272 INFO] Sentences processed: 32028\n",
      "[2024-03-11 11:36:41,272 INFO] Average bsz:  276/ 294/32\n",
      "[2024-03-11 11:36:41,272 INFO] Validation perplexity: 16.3887\n",
      "[2024-03-11 11:36:41,272 INFO] Validation accuracy: 52.4803\n",
      "[2024-03-11 11:36:45,003 INFO] Step 1020/ 2002; acc: 47.5; ppl:  21.5; xent: 3.1; lr: 1.00000; sents:     640; bsz:  296/ 311/32; 543/571 tok/s;    225 sec;\n",
      "[2024-03-11 11:36:48,283 INFO] Step 1040/ 2002; acc: 48.7; ppl:  20.9; xent: 3.0; lr: 1.00000; sents:     640; bsz:  290/ 295/32; 1766/1797 tok/s;    228 sec;\n",
      "[2024-03-11 11:36:51,646 INFO] Step 1060/ 2002; acc: 49.0; ppl:  19.1; xent: 2.9; lr: 1.00000; sents:     640; bsz:  280/ 310/32; 1666/1847 tok/s;    231 sec;\n",
      "[2024-03-11 11:36:54,696 INFO] Step 1080/ 2002; acc: 51.5; ppl:  18.8; xent: 2.9; lr: 1.00000; sents:     640; bsz:  283/ 274/32; 1857/1794 tok/s;    234 sec;\n",
      "[2024-03-11 11:36:58,394 INFO] Step 1100/ 2002; acc: 52.5; ppl:  15.1; xent: 2.7; lr: 1.00000; sents:     640; bsz:  253/ 285/32; 1367/1540 tok/s;    238 sec;\n",
      "[2024-03-11 11:37:01,793 INFO] Step 1120/ 2002; acc: 52.0; ppl:  17.8; xent: 2.9; lr: 1.00000; sents:     640; bsz:  306/ 290/32; 1798/1704 tok/s;    241 sec;\n",
      "[2024-03-11 11:37:05,467 INFO] Step 1140/ 2002; acc: 48.2; ppl:  20.8; xent: 3.0; lr: 1.00000; sents:     640; bsz:  318/ 322/32; 1733/1751 tok/s;    245 sec;\n",
      "[2024-03-11 11:37:08,662 INFO] Step 1160/ 2002; acc: 52.3; ppl:  17.8; xent: 2.9; lr: 1.00000; sents:     640; bsz:  254/ 272/32; 1592/1702 tok/s;    248 sec;\n",
      "[2024-03-11 11:37:11,765 INFO] Step 1180/ 2002; acc: 53.2; ppl:  15.1; xent: 2.7; lr: 1.00000; sents:     640; bsz:  254/ 288/32; 1640/1857 tok/s;    251 sec;\n",
      "[2024-03-11 11:37:15,327 INFO] Step 1200/ 2002; acc: 50.2; ppl:  18.3; xent: 2.9; lr: 1.00000; sents:     640; bsz:  283/ 299/32; 1590/1680 tok/s;    255 sec;\n",
      "[2024-03-11 11:37:18,474 INFO] Step 1220/ 2002; acc: 53.3; ppl:  15.1; xent: 2.7; lr: 1.00000; sents:     640; bsz:  262/ 258/32; 1664/1640 tok/s;    258 sec;\n",
      "[2024-03-11 11:37:22,325 INFO] Step 1240/ 2002; acc: 45.4; ppl:  25.4; xent: 3.2; lr: 1.00000; sents:     640; bsz:  321/ 342/32; 1666/1775 tok/s;    262 sec;\n",
      "[2024-03-11 11:37:25,759 INFO] Step 1260/ 2002; acc: 52.5; ppl:  15.6; xent: 2.7; lr: 1.00000; sents:     640; bsz:  259/ 293/32; 1510/1705 tok/s;    265 sec;\n",
      "[2024-03-11 11:37:29,466 INFO] Step 1280/ 2002; acc: 55.5; ppl:  13.2; xent: 2.6; lr: 1.00000; sents:     640; bsz:  250/ 285/32; 1347/1537 tok/s;    269 sec;\n",
      "[2024-03-11 11:37:33,657 INFO] Step 1300/ 2002; acc: 49.4; ppl:  19.2; xent: 3.0; lr: 1.00000; sents:     640; bsz:  312/ 336/32; 1489/1604 tok/s;    273 sec;\n",
      "[2024-03-11 11:37:37,620 INFO] Step 1320/ 2002; acc: 50.6; ppl:  16.1; xent: 2.8; lr: 1.00000; sents:     640; bsz:  277/ 314/32; 1397/1586 tok/s;    277 sec;\n",
      "[2024-03-11 11:37:41,747 INFO] Step 1340/ 2002; acc: 51.0; ppl:  16.5; xent: 2.8; lr: 1.00000; sents:     640; bsz:  272/ 309/32; 1318/1497 tok/s;    281 sec;\n",
      "[2024-03-11 11:37:45,501 INFO] Step 1360/ 2002; acc: 54.3; ppl:  13.6; xent: 2.6; lr: 1.00000; sents:     640; bsz:  261/ 296/32; 1390/1577 tok/s;    285 sec;\n",
      "[2024-03-11 11:37:49,353 INFO] Step 1380/ 2002; acc: 54.1; ppl:  13.1; xent: 2.6; lr: 1.00000; sents:     640; bsz:  261/ 304/32; 1354/1579 tok/s;    289 sec;\n",
      "[2024-03-11 11:37:52,936 INFO] Step 1400/ 2002; acc: 52.9; ppl:  15.8; xent: 2.8; lr: 1.00000; sents:     640; bsz:  264/ 277/32; 1474/1545 tok/s;    292 sec;\n",
      "[2024-03-11 11:37:56,914 INFO] Step 1420/ 2002; acc: 52.6; ppl:  14.6; xent: 2.7; lr: 1.00000; sents:     640; bsz:  286/ 307/32; 1440/1544 tok/s;    296 sec;\n",
      "[2024-03-11 11:38:00,619 INFO] Step 1440/ 2002; acc: 53.5; ppl:  15.3; xent: 2.7; lr: 1.00000; sents:     640; bsz:  259/ 266/32; 1399/1436 tok/s;    300 sec;\n",
      "[2024-03-11 11:38:04,036 INFO] Step 1460/ 2002; acc: 56.1; ppl:  12.4; xent: 2.5; lr: 1.00000; sents:     640; bsz:  250/ 273/32; 1461/1596 tok/s;    304 sec;\n",
      "[2024-03-11 11:38:07,687 INFO] Step 1480/ 2002; acc: 56.4; ppl:  11.4; xent: 2.4; lr: 1.00000; sents:     640; bsz:  254/ 294/32; 1394/1613 tok/s;    307 sec;\n",
      "[2024-03-11 11:38:11,688 INFO] Step 1500/ 2002; acc: 53.7; ppl:  15.0; xent: 2.7; lr: 1.00000; sents:     640; bsz:  275/ 275/32; 1376/1376 tok/s;    311 sec;\n",
      "[2024-03-11 11:38:18,532 INFO] valid stats calculation\n",
      "                           took: 6.313272953033447 s.\n",
      "[2024-03-11 11:38:18,532 INFO] Train perplexity: 34.0746\n",
      "[2024-03-11 11:38:18,532 INFO] Train accuracy: 43.3879\n",
      "[2024-03-11 11:38:18,532 INFO] Sentences processed: 48060\n",
      "[2024-03-11 11:38:18,533 INFO] Average bsz:  276/ 295/32\n",
      "[2024-03-11 11:38:18,533 INFO] Validation perplexity: 12.3483\n",
      "[2024-03-11 11:38:18,533 INFO] Validation accuracy: 56.1196\n",
      "[2024-03-11 11:38:21,190 INFO] Step 1520/ 2002; acc: 53.7; ppl:  13.5; xent: 2.6; lr: 1.00000; sents:     640; bsz:  251/ 274/32; 529/576 tok/s;    321 sec;\n",
      "[2024-03-11 11:38:24,730 INFO] Step 1540/ 2002; acc: 53.3; ppl:  14.6; xent: 2.7; lr: 1.00000; sents:     640; bsz:  294/ 307/32; 1663/1736 tok/s;    324 sec;\n",
      "[2024-03-11 11:38:28,825 INFO] Step 1560/ 2002; acc: 50.9; ppl:  16.9; xent: 2.8; lr: 1.00000; sents:     640; bsz:  302/ 327/32; 1473/1599 tok/s;    328 sec;\n",
      "[2024-03-11 11:38:32,439 INFO] Step 1580/ 2002; acc: 56.4; ppl:  11.6; xent: 2.4; lr: 1.00000; sents:     640; bsz:  258/ 277/32; 1426/1532 tok/s;    332 sec;\n",
      "[2024-03-11 11:38:35,936 INFO] Step 1600/ 2002; acc: 53.6; ppl:  14.0; xent: 2.6; lr: 1.00000; sents:     640; bsz:  301/ 318/32; 1720/1821 tok/s;    335 sec;\n",
      "[2024-03-11 11:38:39,336 INFO] Step 1620/ 2002; acc: 54.8; ppl:  12.6; xent: 2.5; lr: 1.00000; sents:     640; bsz:  237/ 283/32; 1393/1666 tok/s;    339 sec;\n",
      "[2024-03-11 11:38:42,786 INFO] Step 1640/ 2002; acc: 57.1; ppl:  10.9; xent: 2.4; lr: 1.00000; sents:     640; bsz:  243/ 274/32; 1410/1586 tok/s;    342 sec;\n",
      "[2024-03-11 11:38:46,218 INFO] Step 1660/ 2002; acc: 53.5; ppl:  14.0; xent: 2.6; lr: 1.00000; sents:     640; bsz:  278/ 282/32; 1623/1641 tok/s;    346 sec;\n",
      "[2024-03-11 11:38:49,450 INFO] Step 1680/ 2002; acc: 58.0; ppl:  11.5; xent: 2.4; lr: 1.00000; sents:     640; bsz:  251/ 267/32; 1555/1654 tok/s;    349 sec;\n",
      "[2024-03-11 11:38:52,669 INFO] Step 1700/ 2002; acc: 57.8; ppl:  10.4; xent: 2.3; lr: 1.00000; sents:     640; bsz:  267/ 282/32; 1660/1750 tok/s;    352 sec;\n",
      "[2024-03-11 11:38:55,906 INFO] Step 1720/ 2002; acc: 56.7; ppl:  10.9; xent: 2.4; lr: 1.00000; sents:     640; bsz:  259/ 281/32; 1601/1737 tok/s;    355 sec;\n",
      "[2024-03-11 11:38:59,216 INFO] Step 1740/ 2002; acc: 56.0; ppl:  11.4; xent: 2.4; lr: 1.00000; sents:     640; bsz:  269/ 285/32; 1624/1723 tok/s;    359 sec;\n",
      "[2024-03-11 11:39:02,764 INFO] Step 1760/ 2002; acc: 53.6; ppl:  13.4; xent: 2.6; lr: 1.00000; sents:     640; bsz:  317/ 318/32; 1786/1795 tok/s;    362 sec;\n",
      "[2024-03-11 11:39:06,441 INFO] Step 1780/ 2002; acc: 54.1; ppl:  13.4; xent: 2.6; lr: 1.00000; sents:     640; bsz:  312/ 325/32; 1697/1767 tok/s;    366 sec;\n",
      "[2024-03-11 11:39:09,603 INFO] Step 1800/ 2002; acc: 55.3; ppl:  12.8; xent: 2.5; lr: 1.00000; sents:     640; bsz:  261/ 282/32; 1649/1781 tok/s;    369 sec;\n",
      "[2024-03-11 11:39:13,713 INFO] Step 1820/ 2002; acc: 52.7; ppl:  13.7; xent: 2.6; lr: 1.00000; sents:     640; bsz:  330/ 329/32; 1604/1600 tok/s;    373 sec;\n",
      "[2024-03-11 11:39:17,392 INFO] Step 1840/ 2002; acc: 53.5; ppl:  13.6; xent: 2.6; lr: 1.00000; sents:     640; bsz:  299/ 316/32; 1627/1717 tok/s;    377 sec;\n",
      "[2024-03-11 11:39:20,323 INFO] Step 1860/ 2002; acc: 58.6; ppl:   9.9; xent: 2.3; lr: 1.00000; sents:     640; bsz:  237/ 256/32; 1616/1747 tok/s;    380 sec;\n",
      "[2024-03-11 11:39:23,649 INFO] Step 1880/ 2002; acc: 56.6; ppl:  11.8; xent: 2.5; lr: 1.00000; sents:     640; bsz:  283/ 299/32; 1703/1799 tok/s;    383 sec;\n",
      "[2024-03-11 11:39:26,995 INFO] Step 1900/ 2002; acc: 57.4; ppl:   9.7; xent: 2.3; lr: 1.00000; sents:     640; bsz:  270/ 318/32; 1616/1903 tok/s;    387 sec;\n",
      "[2024-03-11 11:39:30,130 INFO] Step 1920/ 2002; acc: 57.9; ppl:  10.3; xent: 2.3; lr: 1.00000; sents:     640; bsz:  269/ 290/32; 1715/1848 tok/s;    390 sec;\n",
      "[2024-03-11 11:39:34,129 INFO] Step 1940/ 2002; acc: 58.5; ppl:   9.7; xent: 2.3; lr: 1.00000; sents:     640; bsz:  294/ 309/32; 1472/1544 tok/s;    394 sec;\n",
      "[2024-03-11 11:39:38,037 INFO] Step 1960/ 2002; acc: 55.5; ppl:  11.0; xent: 2.4; lr: 1.00000; sents:     640; bsz:  308/ 328/32; 1578/1681 tok/s;    398 sec;\n",
      "[2024-03-11 11:39:41,436 INFO] Step 1980/ 2002; acc: 57.1; ppl:  10.2; xent: 2.3; lr: 1.00000; sents:     640; bsz:  282/ 302/32; 1657/1780 tok/s;    401 sec;\n",
      "[2024-03-11 11:39:44,848 INFO] Step 2000/ 2002; acc: 59.9; ppl:   8.5; xent: 2.1; lr: 1.00000; sents:     640; bsz:  258/ 286/32; 1510/1679 tok/s;    404 sec;\n",
      "[2024-03-11 11:39:45,217 INFO] Saving checkpoint ./models/base/model_step_2002.pt\n",
      "[2024-03-11 11:39:50,544 INFO] Loading checkpoint from ./models/base/model_step_2002.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:39:50,850 INFO] Loading data into the model\n",
      "[2024-03-11 11:39:53,717 INFO] PRED SCORE: -0.6057, PRED PPL: 1.83 NB SENTENCES: 469\n",
      "Time w/o python interpreter load/terminate:  3.1851677894592285\n",
      "BLEU = 20.30, 53.6/25.7/16.4/9.1 (BP=0.954, ratio=0.955, hyp_len=3414, ref_len=3574)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config ./configs/config-more-neurons.yaml\n",
    "!onmt_translate -model ./models/base/model_step_2002.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_2002.txt\n",
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_2002.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 13**: Cela permet d'obtenir de meilleurs résultats car on augmente la profondeur du réseau de neuronnes donc il est plus apte à comprendre des données plus complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 11:42:06,846 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2024-03-11 11:42:06,846 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2024-03-11 11:42:06,846 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2024-03-11 11:42:06,846 INFO] Parsed 2 corpora from -data.\n",
      "[2024-03-11 11:42:06,846 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2024-03-11 11:42:06,873 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '.', '?', 'de', ',', 'vous', 'Je']\n",
      "[2024-03-11 11:42:06,873 INFO] The decoder start token is: <s>\n",
      "[2024-03-11 11:42:06,873 INFO] Building model...\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:42:07,243 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2024-03-11 11:42:07,244 INFO] Non quantized layer compute is fp32\n",
      "[2024-03-11 11:42:07,244 INFO] NMTModel(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(9984, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (rnn): LSTM(500, 250, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): InputFeedRNNDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(8200, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(1000, 500)\n",
      "      )\n",
      "    )\n",
      "    (attn): GlobalAttention(\n",
      "      (linear_context): Linear(in_features=500, out_features=500, bias=False)\n",
      "      (linear_query): Linear(in_features=500, out_features=500, bias=True)\n",
      "      (v): Linear(in_features=500, out_features=1, bias=False)\n",
      "      (linear_out): Linear(in_features=1000, out_features=500, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=500, out_features=8200, bias=True)\n",
      ")\n",
      "[2024-03-11 11:42:07,245 INFO] encoder: 6496000\n",
      "[2024-03-11 11:42:07,245 INFO] decoder: 12213700\n",
      "[2024-03-11 11:42:07,245 INFO] * number of parameters: 18709700\n",
      "[2024-03-11 11:42:07,245 INFO] Trainable parameters = {'torch.float32': 18709700, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 11:42:07,245 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-11 11:42:07,246 INFO]  * src vocab size = 9984\n",
      "[2024-03-11 11:42:07,246 INFO]  * tgt vocab size = 8200\n",
      "[2024-03-11 11:42:07,609 INFO] Starting training on CPU, could be very slow\n",
      "[2024-03-11 11:42:07,609 INFO] Start training loop and validate every 501 steps...\n",
      "[2024-03-11 11:42:07,609 INFO] Scoring with: TransformPipe()\n",
      "[2024-03-11 11:42:09,433 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 11:42:11,161 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-11 11:42:11,285 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 11:42:11,299 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-11 11:42:11,511 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 11:42:11,515 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-11 11:42:11,756 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 11:42:11,770 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-11 11:42:11,881 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 11:42:11,916 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-11 11:42:12,176 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 11:42:12,206 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-11 11:42:12,300 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 11:42:12,338 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-11 11:42:12,640 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 11:42:12,674 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-11 11:42:12,761 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 11:42:12,814 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-11 11:42:12,872 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 11:42:12,933 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-11 11:42:13,278 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 11:42:13,322 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-11 11:42:13,388 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 11:42:13,436 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-11 11:42:13,500 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 11:42:13,555 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-11 11:42:13,981 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 11:42:14,029 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-11 11:42:14,103 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 11:42:14,149 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-11 11:42:14,219 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 11:42:14,265 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-11 11:42:14,335 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 11:42:14,400 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-11 11:42:14,946 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 11:42:14,965 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-11 11:42:15,160 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 11:42:15,253 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-11 11:42:15,379 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 11:42:15,424 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-11 11:42:15,553 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 11:42:15,573 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-11 11:42:15,726 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 11:42:15,733 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-11 11:42:16,561 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 11:42:16,562 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-11 11:42:16,690 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 11:42:16,699 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-11 11:42:16,821 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 11:42:16,828 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-11 11:42:16,953 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 11:42:16,956 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-11 11:42:17,095 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 11:42:17,107 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-11 11:42:29,693 INFO] Step 20/ 2003; acc: 7.1; ppl: 169407.0; xent: 12.0; lr: 1.00000; sents:     640; bsz:  254/ 274/32; 230/248 tok/s;     22 sec;\n",
      "[2024-03-11 11:42:35,282 INFO] Step 40/ 2003; acc: 7.8; ppl: 56076.7; xent: 10.9; lr: 1.00000; sents:     640; bsz:  291/ 317/32; 1043/1135 tok/s;     28 sec;\n",
      "[2024-03-11 11:42:40,056 INFO] Step 60/ 2003; acc: 11.6; ppl: 3401.9; xent: 8.1; lr: 1.00000; sents:     640; bsz:  264/ 301/32; 1106/1260 tok/s;     32 sec;\n",
      "[2024-03-11 11:42:44,534 INFO] Step 80/ 2003; acc: 13.7; ppl: 1654.8; xent: 7.4; lr: 1.00000; sents:     640; bsz:  294/ 291/32; 1315/1300 tok/s;     37 sec;\n",
      "[2024-03-11 11:42:48,607 INFO] Step 100/ 2003; acc: 15.9; ppl: 1449.3; xent: 7.3; lr: 1.00000; sents:     640; bsz:  240/ 289/32; 1179/1420 tok/s;     41 sec;\n",
      "[2024-03-11 11:42:53,318 INFO] Step 120/ 2003; acc: 14.7; ppl: 4260.1; xent: 8.4; lr: 1.00000; sents:     640; bsz:  277/ 299/32; 1175/1270 tok/s;     46 sec;\n",
      "[2024-03-11 11:42:57,818 INFO] Step 140/ 2003; acc: 17.6; ppl: 918.0; xent: 6.8; lr: 1.00000; sents:     640; bsz:  293/ 333/32; 1301/1479 tok/s;     50 sec;\n",
      "[2024-03-11 11:43:03,462 INFO] Step 160/ 2003; acc: 14.9; ppl: 708.0; xent: 6.6; lr: 1.00000; sents:     640; bsz:  336/ 346/32; 1191/1228 tok/s;     56 sec;\n",
      "[2024-03-11 11:43:07,410 INFO] Step 180/ 2003; acc: 20.6; ppl: 432.8; xent: 6.1; lr: 1.00000; sents:     640; bsz:  262/ 286/32; 1329/1451 tok/s;     60 sec;\n",
      "[2024-03-11 11:43:11,513 INFO] Step 200/ 2003; acc: 19.6; ppl: 478.6; xent: 6.2; lr: 1.00000; sents:     640; bsz:  262/ 301/32; 1279/1467 tok/s;     64 sec;\n",
      "[2024-03-11 11:43:15,459 INFO] Step 220/ 2003; acc: 22.7; ppl: 315.2; xent: 5.8; lr: 1.00000; sents:     640; bsz:  258/ 296/32; 1306/1500 tok/s;     68 sec;\n",
      "[2024-03-11 11:43:19,840 INFO] Step 240/ 2003; acc: 21.5; ppl: 500.9; xent: 6.2; lr: 1.00000; sents:     640; bsz:  274/ 290/32; 1249/1322 tok/s;     72 sec;\n",
      "[2024-03-11 11:43:24,452 INFO] Step 260/ 2003; acc: 23.7; ppl: 246.1; xent: 5.5; lr: 1.00000; sents:     640; bsz:  270/ 291/32; 1173/1264 tok/s;     77 sec;\n",
      "[2024-03-11 11:43:29,136 INFO] Step 280/ 2003; acc: 22.9; ppl: 345.7; xent: 5.8; lr: 1.00000; sents:     640; bsz:  291/ 294/32; 1243/1257 tok/s;     82 sec;\n",
      "[2024-03-11 11:43:34,713 INFO] Step 300/ 2003; acc: 22.0; ppl: 229.4; xent: 5.4; lr: 1.00000; sents:     640; bsz:  320/ 355/32; 1148/1274 tok/s;     87 sec;\n",
      "[2024-03-11 11:43:38,679 INFO] Step 320/ 2003; acc: 26.1; ppl: 163.9; xent: 5.1; lr: 1.00000; sents:     640; bsz:  250/ 274/32; 1259/1380 tok/s;     91 sec;\n",
      "[2024-03-11 11:43:43,675 INFO] Step 340/ 2003; acc: 27.9; ppl: 129.1; xent: 4.9; lr: 1.00000; sents:     640; bsz:  250/ 293/32; 999/1172 tok/s;     96 sec;\n",
      "[2024-03-11 11:43:47,815 INFO] Step 360/ 2003; acc: 28.7; ppl: 127.4; xent: 4.8; lr: 1.00000; sents:     640; bsz:  275/ 286/32; 1330/1384 tok/s;    100 sec;\n",
      "[2024-03-11 11:43:51,988 INFO] Step 380/ 2003; acc: 29.8; ppl: 127.9; xent: 4.9; lr: 1.00000; sents:     640; bsz:  242/ 246/32; 1158/1181 tok/s;    104 sec;\n",
      "[2024-03-11 11:43:56,579 INFO] Step 400/ 2003; acc: 27.3; ppl: 123.5; xent: 4.8; lr: 1.00000; sents:     640; bsz:  253/ 302/32; 1101/1317 tok/s;    109 sec;\n",
      "[2024-03-11 11:44:00,654 INFO] Step 420/ 2003; acc: 28.7; ppl: 139.5; xent: 4.9; lr: 1.00000; sents:     640; bsz:  242/ 275/32; 1186/1351 tok/s;    113 sec;\n",
      "[2024-03-11 11:44:04,413 INFO] Step 440/ 2003; acc: 32.9; ppl: 102.8; xent: 4.6; lr: 1.00000; sents:     640; bsz:  242/ 245/32; 1286/1303 tok/s;    117 sec;\n",
      "[2024-03-11 11:44:09,167 INFO] Step 460/ 2003; acc: 28.9; ppl: 102.3; xent: 4.6; lr: 1.00000; sents:     640; bsz:  282/ 325/32; 1185/1367 tok/s;    122 sec;\n",
      "[2024-03-11 11:44:13,846 INFO] Step 480/ 2003; acc: 31.7; ppl: 113.3; xent: 4.7; lr: 1.00000; sents:     640; bsz:  280/ 290/32; 1197/1238 tok/s;    126 sec;\n",
      "[2024-03-11 11:44:19,466 INFO] Step 500/ 2003; acc: 30.2; ppl: 111.7; xent: 4.7; lr: 1.00000; sents:     640; bsz:  304/ 302/32; 1082/1073 tok/s;    132 sec;\n",
      "[2024-03-11 11:44:27,931 INFO] valid stats calculation\n",
      "                           took: 8.274935483932495 s.\n",
      "[2024-03-11 11:44:27,932 INFO] Train perplexity: 534.84\n",
      "[2024-03-11 11:44:27,932 INFO] Train accuracy: 21.7512\n",
      "[2024-03-11 11:44:27,932 INFO] Sentences processed: 16032\n",
      "[2024-03-11 11:44:27,933 INFO] Average bsz:  272/ 296/32\n",
      "[2024-03-11 11:44:27,933 INFO] Validation perplexity: 67.1147\n",
      "[2024-03-11 11:44:27,933 INFO] Validation accuracy: 32.0584\n",
      "[2024-03-11 11:44:32,546 INFO] Step 520/ 2003; acc: 31.1; ppl:  90.1; xent: 4.5; lr: 1.00000; sents:     640; bsz:  291/ 299/32; 445/458 tok/s;    145 sec;\n",
      "[2024-03-11 11:44:37,594 INFO] Step 540/ 2003; acc: 29.6; ppl: 107.1; xent: 4.7; lr: 1.00000; sents:     640; bsz:  317/ 322/32; 1255/1274 tok/s;    150 sec;\n",
      "[2024-03-11 11:44:42,306 INFO] Step 560/ 2003; acc: 31.9; ppl:  91.5; xent: 4.5; lr: 1.00000; sents:     640; bsz:  290/ 309/32; 1229/1311 tok/s;    155 sec;\n",
      "[2024-03-11 11:44:47,298 INFO] Step 580/ 2003; acc: 34.3; ppl:  61.7; xent: 4.1; lr: 1.00000; sents:     640; bsz:  243/ 304/32; 974/1218 tok/s;    160 sec;\n",
      "[2024-03-11 11:44:52,094 INFO] Step 600/ 2003; acc: 36.3; ppl:  60.2; xent: 4.1; lr: 1.00000; sents:     640; bsz:  270/ 294/32; 1128/1228 tok/s;    164 sec;\n",
      "[2024-03-11 11:44:57,632 INFO] Step 620/ 2003; acc: 32.9; ppl:  71.7; xent: 4.3; lr: 1.00000; sents:     640; bsz:  293/ 331/32; 1058/1196 tok/s;    170 sec;\n",
      "[2024-03-11 11:45:03,042 INFO] Step 640/ 2003; acc: 33.6; ppl:  63.5; xent: 4.2; lr: 1.00000; sents:     640; bsz:  298/ 317/32; 1100/1173 tok/s;    175 sec;\n",
      "[2024-03-11 11:45:06,799 INFO] Step 660/ 2003; acc: 40.2; ppl:  51.5; xent: 3.9; lr: 1.00000; sents:     640; bsz:  232/ 237/32; 1235/1261 tok/s;    179 sec;\n",
      "[2024-03-11 11:45:11,913 INFO] Step 680/ 2003; acc: 35.9; ppl:  67.6; xent: 4.2; lr: 1.00000; sents:     640; bsz:  269/ 290/32; 1051/1132 tok/s;    184 sec;\n",
      "[2024-03-11 11:45:17,336 INFO] Step 700/ 2003; acc: 37.8; ppl:  56.2; xent: 4.0; lr: 1.00000; sents:     640; bsz:  275/ 294/32; 1015/1086 tok/s;    190 sec;\n",
      "[2024-03-11 11:45:22,852 INFO] Step 720/ 2003; acc: 37.1; ppl:  59.5; xent: 4.1; lr: 1.00000; sents:     640; bsz:  259/ 290/32; 940/1050 tok/s;    195 sec;\n",
      "[2024-03-11 11:45:28,749 INFO] Step 740/ 2003; acc: 35.0; ppl:  67.9; xent: 4.2; lr: 1.00000; sents:     640; bsz:  301/ 310/32; 1020/1053 tok/s;    201 sec;\n",
      "[2024-03-11 11:45:34,092 INFO] Step 760/ 2003; acc: 35.7; ppl:  56.4; xent: 4.0; lr: 1.00000; sents:     640; bsz:  293/ 314/32; 1096/1174 tok/s;    206 sec;\n",
      "[2024-03-11 11:45:39,013 INFO] Step 780/ 2003; acc: 40.7; ppl:  39.5; xent: 3.7; lr: 1.00000; sents:     640; bsz:  245/ 268/32; 995/1088 tok/s;    211 sec;\n",
      "[2024-03-11 11:45:43,248 INFO] Step 800/ 2003; acc: 42.5; ppl:  35.7; xent: 3.6; lr: 1.00000; sents:     640; bsz:  226/ 248/32; 1065/1171 tok/s;    216 sec;\n",
      "[2024-03-11 11:45:47,673 INFO] Step 820/ 2003; acc: 41.1; ppl:  36.3; xent: 3.6; lr: 1.00000; sents:     640; bsz:  238/ 266/32; 1078/1202 tok/s;    220 sec;\n",
      "[2024-03-11 11:45:52,617 INFO] Step 840/ 2003; acc: 38.5; ppl:  47.1; xent: 3.9; lr: 1.00000; sents:     640; bsz:  270/ 301/32; 1094/1217 tok/s;    225 sec;\n",
      "[2024-03-11 11:45:57,993 INFO] Step 860/ 2003; acc: 40.1; ppl:  42.4; xent: 3.7; lr: 1.00000; sents:     640; bsz:  283/ 310/32; 1054/1155 tok/s;    230 sec;\n",
      "[2024-03-11 11:46:02,514 INFO] Step 880/ 2003; acc: 43.1; ppl:  36.7; xent: 3.6; lr: 1.00000; sents:     640; bsz:  243/ 267/32; 1076/1182 tok/s;    235 sec;\n",
      "[2024-03-11 11:46:06,693 INFO] Step 900/ 2003; acc: 43.4; ppl:  36.5; xent: 3.6; lr: 1.00000; sents:     640; bsz:  270/ 266/32; 1294/1274 tok/s;    239 sec;\n",
      "[2024-03-11 11:46:11,388 INFO] Step 920/ 2003; acc: 42.5; ppl:  38.0; xent: 3.6; lr: 1.00000; sents:     640; bsz:  262/ 277/32; 1118/1180 tok/s;    244 sec;\n",
      "[2024-03-11 11:46:16,499 INFO] Step 940/ 2003; acc: 38.8; ppl:  44.5; xent: 3.8; lr: 1.00000; sents:     640; bsz:  291/ 302/32; 1140/1182 tok/s;    249 sec;\n",
      "[2024-03-11 11:46:21,126 INFO] Step 960/ 2003; acc: 40.7; ppl:  41.6; xent: 3.7; lr: 1.00000; sents:     640; bsz:  282/ 289/32; 1217/1248 tok/s;    254 sec;\n",
      "[2024-03-11 11:46:25,643 INFO] Step 980/ 2003; acc: 43.9; ppl:  31.3; xent: 3.4; lr: 1.00000; sents:     640; bsz:  251/ 275/32; 1112/1218 tok/s;    258 sec;\n",
      "[2024-03-11 11:46:31,649 INFO] Step 1000/ 2003; acc: 39.9; ppl:  40.8; xent: 3.7; lr: 1.00000; sents:     640; bsz:  320/ 320/32; 1064/1066 tok/s;    264 sec;\n",
      "[2024-03-11 11:46:39,088 INFO] valid stats calculation\n",
      "                           took: 7.0156567096710205 s.\n",
      "[2024-03-11 11:46:39,089 INFO] Train perplexity: 169.101\n",
      "[2024-03-11 11:46:39,089 INFO] Train accuracy: 29.658\n",
      "[2024-03-11 11:46:39,089 INFO] Sentences processed: 32064\n",
      "[2024-03-11 11:46:39,089 INFO] Average bsz:  272/ 294/32\n",
      "[2024-03-11 11:46:39,089 INFO] Validation perplexity: 23.8143\n",
      "[2024-03-11 11:46:39,089 INFO] Validation accuracy: 45.8507\n",
      "[2024-03-11 11:46:43,121 INFO] Step 1020/ 2003; acc: 41.5; ppl:  34.1; xent: 3.5; lr: 1.00000; sents:     640; bsz:  277/ 309/32; 483/538 tok/s;    276 sec;\n",
      "[2024-03-11 11:46:47,334 INFO] Step 1040/ 2003; acc: 46.4; ppl:  25.0; xent: 3.2; lr: 1.00000; sents:     640; bsz:  248/ 288/32; 1177/1367 tok/s;    280 sec;\n",
      "[2024-03-11 11:46:51,279 INFO] Step 1060/ 2003; acc: 47.4; ppl:  25.5; xent: 3.2; lr: 1.00000; sents:     640; bsz:  248/ 261/32; 1258/1322 tok/s;    284 sec;\n",
      "[2024-03-11 11:46:56,267 INFO] Step 1080/ 2003; acc: 39.5; ppl:  39.7; xent: 3.7; lr: 1.00000; sents:     640; bsz:  312/ 322/32; 1251/1290 tok/s;    289 sec;\n",
      "[2024-03-11 11:47:01,308 INFO] Step 1100/ 2003; acc: 44.6; ppl:  26.6; xent: 3.3; lr: 1.00000; sents:     640; bsz:  270/ 296/32; 1073/1174 tok/s;    294 sec;\n",
      "[2024-03-11 11:47:06,407 INFO] Step 1120/ 2003; acc: 42.0; ppl:  30.9; xent: 3.4; lr: 1.00000; sents:     640; bsz:  291/ 328/32; 1142/1287 tok/s;    299 sec;\n",
      "[2024-03-11 11:47:10,735 INFO] Step 1140/ 2003; acc: 43.2; ppl:  32.1; xent: 3.5; lr: 1.00000; sents:     640; bsz:  264/ 277/32; 1220/1279 tok/s;    303 sec;\n",
      "[2024-03-11 11:47:15,236 INFO] Step 1160/ 2003; acc: 44.5; ppl:  28.4; xent: 3.3; lr: 1.00000; sents:     640; bsz:  266/ 300/32; 1180/1333 tok/s;    308 sec;\n",
      "[2024-03-11 11:47:20,298 INFO] Step 1180/ 2003; acc: 42.5; ppl:  31.0; xent: 3.4; lr: 1.00000; sents:     640; bsz:  328/ 332/32; 1296/1313 tok/s;    313 sec;\n",
      "[2024-03-11 11:47:24,435 INFO] Step 1200/ 2003; acc: 46.8; ppl:  26.5; xent: 3.3; lr: 1.00000; sents:     640; bsz:  267/ 270/32; 1292/1307 tok/s;    317 sec;\n",
      "[2024-03-11 11:47:28,998 INFO] Step 1220/ 2003; acc: 43.9; ppl:  28.6; xent: 3.4; lr: 1.00000; sents:     640; bsz:  278/ 299/32; 1220/1311 tok/s;    321 sec;\n",
      "[2024-03-11 11:47:35,262 INFO] Step 1240/ 2003; acc: 41.4; ppl:  31.9; xent: 3.5; lr: 1.00000; sents:     640; bsz:  325/ 336/32; 1037/1073 tok/s;    328 sec;\n",
      "[2024-03-11 11:47:40,592 INFO] Step 1260/ 2003; acc: 50.6; ppl:  17.4; xent: 2.9; lr: 1.00000; sents:     640; bsz:  248/ 287/32; 931/1076 tok/s;    333 sec;\n",
      "[2024-03-11 11:47:45,494 INFO] Step 1280/ 2003; acc: 47.6; ppl:  22.1; xent: 3.1; lr: 1.00000; sents:     640; bsz:  275/ 296/32; 1123/1208 tok/s;    338 sec;\n",
      "[2024-03-11 11:47:49,954 INFO] Step 1300/ 2003; acc: 48.3; ppl:  19.8; xent: 3.0; lr: 1.00000; sents:     640; bsz:  277/ 299/32; 1241/1342 tok/s;    342 sec;\n",
      "[2024-03-11 11:47:54,787 INFO] Step 1320/ 2003; acc: 46.9; ppl:  23.8; xent: 3.2; lr: 1.00000; sents:     640; bsz:  275/ 296/32; 1139/1225 tok/s;    347 sec;\n",
      "[2024-03-11 11:47:58,968 INFO] Step 1340/ 2003; acc: 51.2; ppl:  18.8; xent: 2.9; lr: 1.00000; sents:     640; bsz:  251/ 273/32; 1202/1306 tok/s;    351 sec;\n",
      "[2024-03-11 11:48:03,378 INFO] Step 1360/ 2003; acc: 51.0; ppl:  18.0; xent: 2.9; lr: 1.00000; sents:     640; bsz:  256/ 283/32; 1161/1285 tok/s;    356 sec;\n",
      "[2024-03-11 11:48:09,190 INFO] Step 1380/ 2003; acc: 46.1; ppl:  24.2; xent: 3.2; lr: 1.00000; sents:     640; bsz:  296/ 318/32; 1019/1096 tok/s;    362 sec;\n",
      "[2024-03-11 11:48:13,841 INFO] Step 1400/ 2003; acc: 52.0; ppl:  16.3; xent: 2.8; lr: 1.00000; sents:     640; bsz:  253/ 282/32; 1087/1211 tok/s;    366 sec;\n",
      "[2024-03-11 11:48:18,101 INFO] Step 1420/ 2003; acc: 52.9; ppl:  16.7; xent: 2.8; lr: 1.00000; sents:     640; bsz:  256/ 266/32; 1202/1247 tok/s;    370 sec;\n",
      "[2024-03-11 11:48:23,163 INFO] Step 1440/ 2003; acc: 47.7; ppl:  21.4; xent: 3.1; lr: 1.00000; sents:     640; bsz:  298/ 322/32; 1176/1274 tok/s;    376 sec;\n",
      "[2024-03-11 11:48:27,561 INFO] Step 1460/ 2003; acc: 50.2; ppl:  19.0; xent: 2.9; lr: 1.00000; sents:     640; bsz:  235/ 254/32; 1070/1157 tok/s;    380 sec;\n",
      "[2024-03-11 11:48:32,288 INFO] Step 1480/ 2003; acc: 47.2; ppl:  23.1; xent: 3.1; lr: 1.00000; sents:     640; bsz:  270/ 275/32; 1144/1164 tok/s;    385 sec;\n",
      "[2024-03-11 11:48:37,474 INFO] Step 1500/ 2003; acc: 46.8; ppl:  23.5; xent: 3.2; lr: 1.00000; sents:     640; bsz:  291/ 296/32; 1123/1143 tok/s;    390 sec;\n",
      "[2024-03-11 11:48:46,314 INFO] valid stats calculation\n",
      "                           took: 8.067441701889038 s.\n",
      "[2024-03-11 11:48:46,315 INFO] Train perplexity: 88.7394\n",
      "[2024-03-11 11:48:46,315 INFO] Train accuracy: 35.2249\n",
      "[2024-03-11 11:48:46,315 INFO] Sentences processed: 48096\n",
      "[2024-03-11 11:48:46,315 INFO] Average bsz:  273/ 294/32\n",
      "[2024-03-11 11:48:46,315 INFO] Validation perplexity: 16.6739\n",
      "[2024-03-11 11:48:46,315 INFO] Validation accuracy: 51.4604\n",
      "[2024-03-11 11:48:50,744 INFO] Step 1520/ 2003; acc: 48.0; ppl:  22.3; xent: 3.1; lr: 1.00000; sents:     640; bsz:  315/ 307/32; 475/463 tok/s;    403 sec;\n",
      "[2024-03-11 11:48:55,937 INFO] Step 1540/ 2003; acc: 48.9; ppl:  19.1; xent: 2.9; lr: 1.00000; sents:     640; bsz:  285/ 318/32; 1097/1226 tok/s;    408 sec;\n",
      "[2024-03-11 11:49:00,535 INFO] Step 1560/ 2003; acc: 52.3; ppl:  16.6; xent: 2.8; lr: 1.00000; sents:     640; bsz:  272/ 280/32; 1183/1218 tok/s;    413 sec;\n",
      "[2024-03-11 11:49:05,119 INFO] Step 1580/ 2003; acc: 50.0; ppl:  17.5; xent: 2.9; lr: 1.00000; sents:     640; bsz:  280/ 309/32; 1222/1347 tok/s;    418 sec;\n",
      "[2024-03-11 11:49:09,719 INFO] Step 1600/ 2003; acc: 51.0; ppl:  16.1; xent: 2.8; lr: 1.00000; sents:     640; bsz:  274/ 311/32; 1190/1353 tok/s;    422 sec;\n",
      "[2024-03-11 11:49:14,325 INFO] Step 1620/ 2003; acc: 51.5; ppl:  16.3; xent: 2.8; lr: 1.00000; sents:     640; bsz:  248/ 277/32; 1077/1202 tok/s;    427 sec;\n",
      "[2024-03-11 11:49:20,551 INFO] Step 1640/ 2003; acc: 44.6; ppl:  30.0; xent: 3.4; lr: 1.00000; sents:     640; bsz:  314/ 331/32; 1009/1063 tok/s;    433 sec;\n",
      "[2024-03-11 11:49:26,810 INFO] Step 1660/ 2003; acc: 44.3; ppl:  28.8; xent: 3.4; lr: 1.00000; sents:     640; bsz:  339/ 338/32; 1084/1080 tok/s;    439 sec;\n",
      "[2024-03-11 11:49:32,842 INFO] Step 1680/ 2003; acc: 46.2; ppl:  24.8; xent: 3.2; lr: 1.00000; sents:     640; bsz:  335/ 319/32; 1110/1058 tok/s;    445 sec;\n",
      "[2024-03-11 11:49:36,947 INFO] Step 1700/ 2003; acc: 51.5; ppl:  17.3; xent: 2.9; lr: 1.00000; sents:     640; bsz:  280/ 293/32; 1364/1427 tok/s;    449 sec;\n",
      "[2024-03-11 11:49:41,342 INFO] Step 1720/ 2003; acc: 48.8; ppl:  19.5; xent: 3.0; lr: 1.00000; sents:     640; bsz:  296/ 309/32; 1347/1405 tok/s;    454 sec;\n",
      "[2024-03-11 11:49:45,392 INFO] Step 1740/ 2003; acc: 53.9; ppl:  13.3; xent: 2.6; lr: 1.00000; sents:     640; bsz:  266/ 290/32; 1312/1430 tok/s;    458 sec;\n",
      "[2024-03-11 11:49:51,303 INFO] Step 1760/ 2003; acc: 51.6; ppl:  14.3; xent: 2.7; lr: 1.00000; sents:     640; bsz:  299/ 326/32; 1012/1104 tok/s;    464 sec;\n",
      "[2024-03-11 11:49:56,591 INFO] Step 1780/ 2003; acc: 48.8; ppl:  19.1; xent: 3.0; lr: 1.00000; sents:     640; bsz:  312/ 306/32; 1180/1156 tok/s;    469 sec;\n",
      "[2024-03-11 11:50:01,161 INFO] Step 1800/ 2003; acc: 52.7; ppl:  16.3; xent: 2.8; lr: 1.00000; sents:     640; bsz:  274/ 290/32; 1197/1268 tok/s;    474 sec;\n",
      "[2024-03-11 11:50:05,930 INFO] Step 1820/ 2003; acc: 49.8; ppl:  17.3; xent: 2.9; lr: 1.00000; sents:     640; bsz:  293/ 314/32; 1229/1315 tok/s;    478 sec;\n",
      "[2024-03-11 11:50:10,837 INFO] Step 1840/ 2003; acc: 50.5; ppl:  16.5; xent: 2.8; lr: 1.00000; sents:     640; bsz:  306/ 323/32; 1245/1317 tok/s;    483 sec;\n",
      "[2024-03-11 11:50:15,808 INFO] Step 1860/ 2003; acc: 52.4; ppl:  14.2; xent: 2.7; lr: 1.00000; sents:     640; bsz:  285/ 290/32; 1146/1165 tok/s;    488 sec;\n",
      "[2024-03-11 11:50:21,287 INFO] Step 1880/ 2003; acc: 49.6; ppl:  17.1; xent: 2.8; lr: 1.00000; sents:     640; bsz:  297/ 310/32; 1083/1132 tok/s;    494 sec;\n",
      "[2024-03-11 11:50:26,163 INFO] Step 1900/ 2003; acc: 55.1; ppl:  12.3; xent: 2.5; lr: 1.00000; sents:     640; bsz:  251/ 288/32; 1030/1180 tok/s;    499 sec;\n",
      "[2024-03-11 11:50:30,537 INFO] Step 1920/ 2003; acc: 56.7; ppl:  11.1; xent: 2.4; lr: 1.00000; sents:     640; bsz:  258/ 296/32; 1178/1354 tok/s;    503 sec;\n",
      "[2024-03-11 11:50:35,302 INFO] Step 1940/ 2003; acc: 55.1; ppl:  12.1; xent: 2.5; lr: 1.00000; sents:     640; bsz:  280/ 314/32; 1175/1316 tok/s;    508 sec;\n",
      "[2024-03-11 11:50:39,297 INFO] Step 1960/ 2003; acc: 60.0; ppl:   9.2; xent: 2.2; lr: 1.00000; sents:     640; bsz:  226/ 270/32; 1130/1354 tok/s;    512 sec;\n",
      "[2024-03-11 11:50:43,772 INFO] Step 1980/ 2003; acc: 55.1; ppl:  12.3; xent: 2.5; lr: 1.00000; sents:     640; bsz:  242/ 290/32; 1080/1294 tok/s;    516 sec;\n",
      "[2024-03-11 11:50:48,698 INFO] Step 2000/ 2003; acc: 53.7; ppl:  14.2; xent: 2.7; lr: 1.00000; sents:     640; bsz:  264/ 286/32; 1072/1163 tok/s;    521 sec;\n",
      "[2024-03-11 11:50:49,267 INFO] Saving checkpoint ./models/base/model_step_2003.pt\n",
      "[2024-03-11 11:50:54,556 INFO] Loading checkpoint from ./models/base/model_step_2003.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:50:55,016 INFO] Loading data into the model\n",
      "[2024-03-11 11:50:59,287 INFO] PRED SCORE: -0.6828, PRED PPL: 1.98 NB SENTENCES: 469\n",
      "Time w/o python interpreter load/terminate:  4.7461464405059814\n",
      "BLEU = 21.69, 55.6/29.6/18.4/9.9 (BP=0.926, ratio=0.929, hyp_len=3319, ref_len=3574)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config ./configs/config-mlp-attention.yaml\n",
    "!onmt_translate -model ./models/base/model_step_2003.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_2003.txt\n",
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_2003.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 14**: On observe un gain de performance (score bleu 20 -> 21). Le mécanisme permet au modèle de se concentrer sur des parties spécifiques de la séquence d'entrée lors de la génération de la séquence de sortie. L'attention MLP est une approche plus flexible et plus expressive pour calculer les poids d'attention par rapport à d'autres méthodes d'attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 15**: Le beam search est un algorithme qui au lieu d'explorer toutes les possibilités, n'en explore que quelques unes en faisant un choix grâce à un modèle probabilitste. La taille par défaut du beam est 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time w/o python interpreter load/terminate:  1.3783504962921143\n",
      "Time w/o python interpreter load/terminate:  1.8698782920837402\n",
      "Time w/o python interpreter load/terminate:  3.0410964488983154\n",
      "Time w/o python interpreter load/terminate:  4.2600226402282715\n",
      "BLEU = 18.57, 49.9/22.7/14.2/7.4 (BP=1.000, ratio=1.045, hyp_len=3734, ref_len=3574)\n",
      "BLEU = 20.43, 53.0/25.4/16.0/8.6 (BP=0.986, ratio=0.986, hyp_len=3524, ref_len=3574)\n",
      "BLEU = 20.84, 54.2/26.4/17.1/9.4 (BP=0.951, ratio=0.952, hyp_len=3403, ref_len=3574)\n",
      "BLEU = 21.14, 54.8/26.9/17.5/9.7 (BP=0.945, ratio=0.947, hyp_len=3384, ref_len=3574)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-11 11:52:50,377 INFO] Loading checkpoint from ./models/base/model_step_2000.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:52:50,771 INFO] Loading data into the model\n",
      "[2024-03-11 11:52:51,749 INFO] PRED SCORE: -0.7095, PRED PPL: 2.03 NB SENTENCES: 469\n",
      "[2024-03-11 11:52:53,962 INFO] Loading checkpoint from ./models/base/model_step_2000.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:52:54,294 INFO] Loading data into the model\n",
      "[2024-03-11 11:52:55,825 INFO] PRED SCORE: -0.6250, PRED PPL: 1.87 NB SENTENCES: 469\n",
      "[2024-03-11 11:52:58,057 INFO] Loading checkpoint from ./models/base/model_step_2000.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:52:58,389 INFO] Loading data into the model\n",
      "[2024-03-11 11:53:01,090 INFO] PRED SCORE: -0.6103, PRED PPL: 1.84 NB SENTENCES: 469\n",
      "[2024-03-11 11:53:03,259 INFO] Loading checkpoint from ./models/base/model_step_2000.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:53:03,589 INFO] Loading data into the model\n",
      "[2024-03-11 11:53:07,513 INFO] PRED SCORE: -0.6061, PRED PPL: 1.83 NB SENTENCES: 469\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "onmt_translate -model ./models/base/model_step_2000.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_beam_1.txt -beam_size 1\n",
    "onmt_translate -model ./models/base/model_step_2000.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_beam_3.txt -beam_size 3\n",
    "onmt_translate -model ./models/base/model_step_2000.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_beam_7.txt -beam_size 7\n",
    "onmt_translate -model ./models/base/model_step_2000.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_beam_10.txt -beam_size 10\n",
    "perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_beam_1.txt\n",
    "perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_beam_3.txt\n",
    "perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_beam_7.txt\n",
    "perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_beam_10.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 16**: Plus la taille du beam est élevée, meilleurs sont les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 11:53:28,433 INFO] Loading checkpoint from ./models/base/model_step_6000.pt\n",
      "/home/puguix/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[2024-03-11 11:53:28,780 INFO] Loading data into the model\n",
      "[2024-03-11 11:53:30,897 INFO] PRED SCORE: -0.3571, PRED PPL: 1.43 NB SENTENCES: 469\n",
      "Time w/o python interpreter load/terminate:  2.47044038772583\n",
      "BLEU = 30.59, 63.0/37.8/26.2/16.6 (BP=0.959, ratio=0.960, hyp_len=3431, ref_len=3574)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!onmt_translate -model ./models/base/model_step_6000.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_6000.txt\n",
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_6000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-14 12:37:40,087 INFO] Missing transforms field for train data, set to default: [].\n",
      "[2024-03-14 12:37:40,087 WARNING] Corpus train's weight should be given. We default it to 1 for you.\n",
      "[2024-03-14 12:37:40,087 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2024-03-14 12:37:40,087 INFO] Parsed 2 corpora from -data.\n",
      "[2024-03-14 12:37:40,087 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2024-03-14 12:37:40,110 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '.', '?', 'de', ',', 'vous', 'Je']\n",
      "[2024-03-14 12:37:40,111 INFO] The decoder start token is: <s>\n",
      "[2024-03-14 12:37:40,111 INFO] Building model...\n",
      "[2024-03-14 12:37:40,651 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2024-03-14 12:37:40,651 INFO] Non quantized layer compute is fp32\n",
      "[2024-03-14 12:37:40,658 INFO] NMTModel(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(9984, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (rnn): LSTM(500, 250, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  )\n",
      "  (decoder): InputFeedRNNDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(8200, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(1000, 500)\n",
      "        (1): LSTMCell(500, 500)\n",
      "      )\n",
      "    )\n",
      "    (attn): GlobalAttention(\n",
      "      (linear_context): Linear(in_features=500, out_features=500, bias=False)\n",
      "      (linear_query): Linear(in_features=500, out_features=500, bias=True)\n",
      "      (v): Linear(in_features=500, out_features=1, bias=False)\n",
      "      (linear_out): Linear(in_features=1000, out_features=500, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=500, out_features=8200, bias=True)\n",
      ")\n",
      "[2024-03-14 12:37:40,659 INFO] encoder: 8000000\n",
      "[2024-03-14 12:37:40,659 INFO] decoder: 14217700\n",
      "[2024-03-14 12:37:40,659 INFO] * number of parameters: 22217700\n",
      "[2024-03-14 12:37:40,659 INFO] Trainable parameters = {'torch.float32': 22217700, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-14 12:37:40,659 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-14 12:37:40,659 INFO]  * src vocab size = 9984\n",
      "[2024-03-14 12:37:40,659 INFO]  * tgt vocab size = 8200\n",
      "[2024-03-14 12:37:41,039 INFO] Starting training on CPU, could be very slow\n",
      "[2024-03-14 12:37:41,039 INFO] Start training loop and validate every 1000 steps...\n",
      "[2024-03-14 12:37:41,039 INFO] Scoring with: TransformPipe()\n",
      "[2024-03-14 12:37:43,212 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-14 12:37:45,058 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 1\n",
      "[2024-03-14 12:37:45,182 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-14 12:37:45,205 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 2\n",
      "[2024-03-14 12:37:45,432 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-14 12:37:45,452 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 3\n",
      "[2024-03-14 12:37:45,723 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-14 12:37:45,734 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 4\n",
      "[2024-03-14 12:37:45,948 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-14 12:37:45,984 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 5\n",
      "[2024-03-14 12:37:46,398 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-14 12:37:46,426 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 6\n",
      "[2024-03-14 12:37:46,564 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-14 12:37:46,639 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 7\n",
      "[2024-03-14 12:37:47,019 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-14 12:37:47,103 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 8\n",
      "[2024-03-14 12:37:47,197 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-14 12:37:47,290 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 9\n",
      "[2024-03-14 12:37:47,373 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-14 12:37:47,482 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 10\n",
      "[2024-03-14 12:37:47,856 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-14 12:37:47,947 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 11\n",
      "[2024-03-14 12:37:48,043 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-14 12:37:48,145 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 12\n",
      "[2024-03-14 12:37:48,242 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-14 12:37:48,358 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 13\n",
      "[2024-03-14 12:37:48,808 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-14 12:37:48,865 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 14\n",
      "[2024-03-14 12:37:48,957 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-14 12:37:49,011 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 15\n",
      "[2024-03-14 12:37:49,105 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-14 12:37:49,166 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 16\n",
      "[2024-03-14 12:37:49,258 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-14 12:37:49,316 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 17\n",
      "[2024-03-14 12:37:49,865 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-14 12:37:49,912 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 18\n",
      "[2024-03-14 12:37:50,013 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-14 12:37:50,054 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 19\n",
      "[2024-03-14 12:37:50,175 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-14 12:37:50,215 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 20\n",
      "[2024-03-14 12:37:50,331 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-14 12:37:50,373 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 21\n",
      "[2024-03-14 12:37:50,499 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-14 12:37:50,535 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 22\n",
      "[2024-03-14 12:37:51,229 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-14 12:37:51,262 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 23\n",
      "[2024-03-14 12:37:51,376 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-14 12:37:51,417 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 24\n",
      "[2024-03-14 12:37:51,534 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-14 12:37:51,574 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 25\n",
      "[2024-03-14 12:37:51,695 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-14 12:37:51,737 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 26\n",
      "[2024-03-14 12:37:51,853 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-14 12:37:51,906 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* train: 27\n",
      "[2024-03-14 12:38:07,433 INFO] Step 20/11000; acc: 6.3; ppl: 41871.6; xent: 10.6; lr: 1.00000; sents:     640; bsz:  290/ 313/32; 220/237 tok/s;     26 sec;\n",
      "[2024-03-14 12:38:13,171 INFO] Step 40/11000; acc: 6.8; ppl: 44011.9; xent: 10.7; lr: 1.00000; sents:     640; bsz:  238/ 279/32; 831/972 tok/s;     32 sec;\n",
      "[2024-03-14 12:38:19,575 INFO] Step 60/11000; acc: 8.0; ppl: 25727.6; xent: 10.2; lr: 1.00000; sents:     640; bsz:  254/ 306/32; 795/954 tok/s;     39 sec;\n",
      "[2024-03-14 12:38:27,160 INFO] Step 80/11000; acc: 7.7; ppl: 3640.2; xent: 8.2; lr: 1.00000; sents:     640; bsz:  328/ 330/32; 865/869 tok/s;     46 sec;\n",
      "[2024-03-14 12:38:33,565 INFO] Step 100/11000; acc: 9.2; ppl: 2042.5; xent: 7.6; lr: 1.00000; sents:     640; bsz:  264/ 310/32; 824/969 tok/s;     53 sec;\n",
      "[2024-03-14 12:38:40,282 INFO] Step 120/11000; acc: 8.5; ppl: 2115.4; xent: 7.7; lr: 1.00000; sents:     640; bsz:  293/ 323/32; 872/962 tok/s;     59 sec;\n",
      "[2024-03-14 12:38:46,352 INFO] Step 140/11000; acc: 13.0; ppl: 1238.0; xent: 7.1; lr: 1.00000; sents:     640; bsz:  280/ 291/32; 923/960 tok/s;     65 sec;\n",
      "[2024-03-14 12:38:52,403 INFO] Step 160/11000; acc: 12.3; ppl: 825.6; xent: 6.7; lr: 1.00000; sents:     640; bsz:  256/ 275/32; 846/909 tok/s;     71 sec;\n",
      "[2024-03-14 12:38:58,979 INFO] Step 180/11000; acc: 13.3; ppl: 570.6; xent: 6.3; lr: 1.00000; sents:     640; bsz:  254/ 283/32; 774/861 tok/s;     78 sec;\n",
      "[2024-03-14 12:39:04,925 INFO] Step 200/11000; acc: 13.2; ppl: 504.3; xent: 6.2; lr: 1.00000; sents:     640; bsz:  248/ 277/32; 834/931 tok/s;     84 sec;\n",
      "[2024-03-14 12:39:11,090 INFO] Step 220/11000; acc: 13.8; ppl: 454.3; xent: 6.1; lr: 1.00000; sents:     640; bsz:  282/ 293/32; 914/950 tok/s;     90 sec;\n",
      "[2024-03-14 12:39:17,458 INFO] Step 240/11000; acc: 19.8; ppl: 286.9; xent: 5.7; lr: 1.00000; sents:     640; bsz:  285/ 296/32; 895/930 tok/s;     96 sec;\n",
      "[2024-03-14 12:39:22,818 INFO] Step 260/11000; acc: 22.0; ppl: 219.5; xent: 5.4; lr: 1.00000; sents:     640; bsz:  240/ 256/32; 896/955 tok/s;    102 sec;\n",
      "[2024-03-14 12:39:29,584 INFO] Step 280/11000; acc: 21.1; ppl: 239.5; xent: 5.5; lr: 1.00000; sents:     640; bsz:  262/ 278/32; 776/823 tok/s;    109 sec;\n",
      "[2024-03-14 12:39:35,614 INFO] Step 300/11000; acc: 24.4; ppl: 188.1; xent: 5.2; lr: 1.00000; sents:     640; bsz:  250/ 282/32; 828/934 tok/s;    115 sec;\n",
      "[2024-03-14 12:39:42,785 INFO] Step 320/11000; acc: 20.2; ppl: 245.7; xent: 5.5; lr: 1.00000; sents:     640; bsz:  296/ 334/32; 826/933 tok/s;    122 sec;\n",
      "[2024-03-14 12:39:49,551 INFO] Step 340/11000; acc: 20.4; ppl: 252.2; xent: 5.5; lr: 1.00000; sents:     640; bsz:  294/ 314/32; 870/927 tok/s;    129 sec;\n",
      "[2024-03-14 12:39:56,388 INFO] Step 360/11000; acc: 23.4; ppl: 194.3; xent: 5.3; lr: 1.00000; sents:     640; bsz:  312/ 309/32; 913/903 tok/s;    135 sec;\n",
      "[2024-03-14 12:40:03,581 INFO] Step 380/11000; acc: 25.0; ppl: 171.3; xent: 5.1; lr: 1.00000; sents:     640; bsz:  278/ 288/32; 774/801 tok/s;    143 sec;\n",
      "[2024-03-14 12:40:10,566 INFO] Step 400/11000; acc: 23.5; ppl: 159.5; xent: 5.1; lr: 1.00000; sents:     640; bsz:  290/ 306/32; 829/875 tok/s;    150 sec;\n",
      "[2024-03-14 12:40:16,597 INFO] Step 420/11000; acc: 25.4; ppl: 149.9; xent: 5.0; lr: 1.00000; sents:     640; bsz:  269/ 278/32; 891/923 tok/s;    156 sec;\n",
      "[2024-03-14 12:40:22,890 INFO] Step 440/11000; acc: 26.1; ppl: 132.9; xent: 4.9; lr: 1.00000; sents:     640; bsz:  270/ 297/32; 860/943 tok/s;    162 sec;\n",
      "[2024-03-14 12:40:28,798 INFO] Step 460/11000; acc: 26.8; ppl: 113.6; xent: 4.7; lr: 1.00000; sents:     640; bsz:  250/ 285/32; 845/964 tok/s;    168 sec;\n",
      "[2024-03-14 12:40:34,648 INFO] Step 480/11000; acc: 29.1; ppl: 107.0; xent: 4.7; lr: 1.00000; sents:     640; bsz:  248/ 270/32; 848/925 tok/s;    174 sec;\n",
      "[2024-03-14 12:40:41,846 INFO] Step 500/11000; acc: 24.7; ppl: 129.9; xent: 4.9; lr: 1.00000; sents:     640; bsz:  277/ 322/32; 769/894 tok/s;    181 sec;\n",
      "[2024-03-14 12:40:48,680 INFO] Step 520/11000; acc: 27.0; ppl: 120.6; xent: 4.8; lr: 1.00000; sents:     640; bsz:  293/ 317/32; 857/927 tok/s;    188 sec;\n",
      "[2024-03-14 12:40:54,839 INFO] Step 540/11000; acc: 29.9; ppl:  99.1; xent: 4.6; lr: 1.00000; sents:     640; bsz:  270/ 294/32; 878/954 tok/s;    194 sec;\n",
      "[2024-03-14 12:41:02,243 INFO] Step 560/11000; acc: 26.7; ppl: 110.7; xent: 4.7; lr: 1.00000; sents:     640; bsz:  330/ 338/32; 890/914 tok/s;    201 sec;\n",
      "[2024-03-14 12:41:07,761 INFO] Step 580/11000; acc: 32.0; ppl:  74.1; xent: 4.3; lr: 1.00000; sents:     640; bsz:  234/ 262/32; 847/951 tok/s;    207 sec;\n",
      "[2024-03-14 12:41:14,811 INFO] Step 600/11000; acc: 32.7; ppl:  74.2; xent: 4.3; lr: 1.00000; sents:     640; bsz:  254/ 290/32; 722/823 tok/s;    214 sec;\n",
      "[2024-03-14 12:41:21,837 INFO] Step 620/11000; acc: 28.6; ppl: 100.6; xent: 4.6; lr: 1.00000; sents:     640; bsz:  323/ 321/32; 920/913 tok/s;    221 sec;\n",
      "[2024-03-14 12:41:28,196 INFO] Step 640/11000; acc: 32.6; ppl:  78.6; xent: 4.4; lr: 1.00000; sents:     640; bsz:  283/ 301/32; 891/946 tok/s;    227 sec;\n",
      "[2024-03-14 12:41:34,556 INFO] Step 660/11000; acc: 32.6; ppl:  69.3; xent: 4.2; lr: 1.00000; sents:     640; bsz:  294/ 299/32; 926/942 tok/s;    234 sec;\n",
      "[2024-03-14 12:41:42,688 INFO] Step 680/11000; acc: 28.1; ppl:  96.5; xent: 4.6; lr: 1.00000; sents:     640; bsz:  352/ 370/32; 866/909 tok/s;    242 sec;\n",
      "[2024-03-14 12:41:50,905 INFO] Step 700/11000; acc: 29.6; ppl:  87.6; xent: 4.5; lr: 1.00000; sents:     640; bsz:  344/ 354/32; 837/861 tok/s;    250 sec;\n",
      "[2024-03-14 12:41:57,281 INFO] Step 720/11000; acc: 33.7; ppl:  62.0; xent: 4.1; lr: 1.00000; sents:     640; bsz:  275/ 304/32; 863/954 tok/s;    256 sec;\n",
      "[2024-03-14 12:42:03,750 INFO] Step 740/11000; acc: 34.1; ppl:  62.3; xent: 4.1; lr: 1.00000; sents:     640; bsz:  293/ 306/32; 905/945 tok/s;    263 sec;\n",
      "[2024-03-14 12:42:10,392 INFO] Step 760/11000; acc: 35.4; ppl:  54.8; xent: 4.0; lr: 1.00000; sents:     640; bsz:  301/ 316/32; 906/953 tok/s;    269 sec;\n",
      "[2024-03-14 12:42:17,555 INFO] Step 780/11000; acc: 33.8; ppl:  60.4; xent: 4.1; lr: 1.00000; sents:     640; bsz:  285/ 320/32; 795/894 tok/s;    277 sec;\n",
      "[2024-03-14 12:42:24,217 INFO] Step 800/11000; acc: 36.0; ppl:  49.4; xent: 3.9; lr: 1.00000; sents:     640; bsz:  240/ 293/32; 721/879 tok/s;    283 sec;\n",
      "[2024-03-14 12:42:31,038 INFO] Step 820/11000; acc: 34.6; ppl:  66.7; xent: 4.2; lr: 1.00000; sents:     640; bsz:  318/ 315/32; 934/924 tok/s;    290 sec;\n",
      "[2024-03-14 12:42:36,577 INFO] Step 840/11000; acc: 37.1; ppl:  54.2; xent: 4.0; lr: 1.00000; sents:     640; bsz:  248/ 266/32; 896/962 tok/s;    296 sec;\n",
      "[2024-03-14 12:42:42,054 INFO] Step 860/11000; acc: 38.2; ppl:  52.8; xent: 4.0; lr: 1.00000; sents:     640; bsz:  245/ 250/32; 894/913 tok/s;    301 sec;\n",
      "[2024-03-14 12:42:47,906 INFO] Step 880/11000; acc: 39.4; ppl:  43.3; xent: 3.8; lr: 1.00000; sents:     640; bsz:  245/ 274/32; 837/935 tok/s;    307 sec;\n",
      "[2024-03-14 12:42:56,043 INFO] Step 900/11000; acc: 32.1; ppl:  66.9; xent: 4.2; lr: 1.00000; sents:     640; bsz:  330/ 341/32; 810/838 tok/s;    315 sec;\n",
      "[2024-03-14 12:43:01,873 INFO] Step 920/11000; acc: 39.5; ppl:  44.7; xent: 3.8; lr: 1.00000; sents:     640; bsz:  251/ 270/32; 862/928 tok/s;    321 sec;\n",
      "[2024-03-14 12:43:07,958 INFO] Step 940/11000; acc: 38.8; ppl:  43.0; xent: 3.8; lr: 1.00000; sents:     640; bsz:  270/ 288/32; 889/947 tok/s;    327 sec;\n",
      "[2024-03-14 12:43:14,373 INFO] Step 960/11000; acc: 38.0; ppl:  45.7; xent: 3.8; lr: 1.00000; sents:     640; bsz:  275/ 309/32; 858/963 tok/s;    333 sec;\n",
      "[2024-03-14 12:43:21,532 INFO] Step 980/11000; acc: 34.3; ppl:  53.5; xent: 4.0; lr: 1.00000; sents:     640; bsz:  301/ 344/32; 840/961 tok/s;    340 sec;\n",
      "[2024-03-14 12:43:28,927 INFO] Step 1000/11000; acc: 36.7; ppl:  48.2; xent: 3.9; lr: 1.00000; sents:     640; bsz:  298/ 303/32; 805/819 tok/s;    348 sec;\n",
      "[2024-03-14 12:43:36,646 INFO] valid stats calculation\n",
      "                           took: 7.717654466629028 s.\n",
      "[2024-03-14 12:43:36,647 INFO] Train perplexity: 198.795\n",
      "[2024-03-14 12:43:36,647 INFO] Train accuracy: 25.664\n",
      "[2024-03-14 12:43:36,647 INFO] Sentences processed: 32000\n",
      "[2024-03-14 12:43:36,647 INFO] Average bsz:  279/ 301/32\n",
      "[2024-03-14 12:43:36,647 INFO] Validation perplexity: 32.137\n",
      "[2024-03-14 12:43:36,647 INFO] Validation accuracy: 41.1451\n",
      "[2024-03-14 12:43:43,123 INFO] Step 1020/11000; acc: 36.5; ppl:  50.6; xent: 3.9; lr: 1.00000; sents:     640; bsz:  290/ 301/32; 408/424 tok/s;    362 sec;\n",
      "[2024-03-14 12:43:49,244 INFO] Step 1040/11000; acc: 38.6; ppl:  41.5; xent: 3.7; lr: 1.00000; sents:     640; bsz:  246/ 290/32; 805/946 tok/s;    368 sec;\n",
      "[2024-03-14 12:43:55,186 INFO] Step 1060/11000; acc: 41.2; ppl:  38.0; xent: 3.6; lr: 1.00000; sents:     640; bsz:  261/ 268/32; 878/901 tok/s;    374 sec;\n",
      "[2024-03-14 12:44:02,669 INFO] Step 1080/11000; acc: 39.1; ppl:  41.2; xent: 3.7; lr: 1.00000; sents:     640; bsz:  296/ 307/32; 791/821 tok/s;    382 sec;\n",
      "[2024-03-14 12:44:08,857 INFO] Step 1100/11000; acc: 42.2; ppl:  35.3; xent: 3.6; lr: 1.00000; sents:     640; bsz:  258/ 282/32; 833/911 tok/s;    388 sec;\n",
      "[2024-03-14 12:44:15,518 INFO] Step 1120/11000; acc: 38.0; ppl:  44.7; xent: 3.8; lr: 1.00000; sents:     640; bsz:  280/ 310/32; 841/932 tok/s;    394 sec;\n",
      "[2024-03-14 12:44:21,541 INFO] Step 1140/11000; acc: 41.9; ppl:  34.6; xent: 3.5; lr: 1.00000; sents:     640; bsz:  246/ 283/32; 818/940 tok/s;    401 sec;\n",
      "[2024-03-14 12:44:28,601 INFO] Step 1160/11000; acc: 38.0; ppl:  46.2; xent: 3.8; lr: 1.00000; sents:     640; bsz:  315/ 312/32; 893/884 tok/s;    408 sec;\n",
      "[2024-03-14 12:44:35,114 INFO] Step 1180/11000; acc: 41.8; ppl:  30.4; xent: 3.4; lr: 1.00000; sents:     640; bsz:  246/ 286/32; 757/880 tok/s;    414 sec;\n",
      "[2024-03-14 12:44:42,663 INFO] Step 1200/11000; acc: 37.6; ppl:  44.3; xent: 3.8; lr: 1.00000; sents:     640; bsz:  302/ 318/32; 801/844 tok/s;    422 sec;\n",
      "[2024-03-14 12:44:50,095 INFO] Step 1220/11000; acc: 37.8; ppl:  46.3; xent: 3.8; lr: 1.00000; sents:     640; bsz:  323/ 338/32; 870/910 tok/s;    429 sec;\n",
      "[2024-03-14 12:44:58,308 INFO] Step 1240/11000; acc: 37.2; ppl:  44.9; xent: 3.8; lr: 1.00000; sents:     640; bsz:  316/ 354/32; 769/863 tok/s;    437 sec;\n",
      "[2024-03-14 12:45:05,561 INFO] Step 1260/11000; acc: 38.6; ppl:  38.2; xent: 3.6; lr: 1.00000; sents:     640; bsz:  307/ 321/32; 847/884 tok/s;    445 sec;\n",
      "[2024-03-14 12:45:12,810 INFO] Step 1280/11000; acc: 41.5; ppl:  33.6; xent: 3.5; lr: 1.00000; sents:     640; bsz:  253/ 283/32; 698/781 tok/s;    452 sec;\n",
      "[2024-03-14 12:45:19,710 INFO] Step 1300/11000; acc: 42.1; ppl:  31.7; xent: 3.5; lr: 1.00000; sents:     640; bsz:  259/ 291/32; 751/844 tok/s;    459 sec;\n",
      "[2024-03-14 12:45:25,958 INFO] Step 1320/11000; acc: 42.6; ppl:  32.0; xent: 3.5; lr: 1.00000; sents:     640; bsz:  264/ 290/32; 845/927 tok/s;    465 sec;\n",
      "[2024-03-14 12:45:32,062 INFO] Step 1340/11000; acc: 43.7; ppl:  29.2; xent: 3.4; lr: 1.00000; sents:     640; bsz:  250/ 283/32; 818/928 tok/s;    471 sec;\n",
      "[2024-03-14 12:45:38,099 INFO] Step 1360/11000; acc: 43.6; ppl:  30.3; xent: 3.4; lr: 1.00000; sents:     640; bsz:  258/ 274/32; 853/908 tok/s;    477 sec;\n",
      "[2024-03-14 12:45:45,218 INFO] Step 1380/11000; acc: 44.6; ppl:  26.4; xent: 3.3; lr: 1.00000; sents:     640; bsz:  261/ 285/32; 733/800 tok/s;    484 sec;\n",
      "[2024-03-14 12:45:51,919 INFO] Step 1400/11000; acc: 43.8; ppl:  28.8; xent: 3.4; lr: 1.00000; sents:     640; bsz:  285/ 299/32; 850/893 tok/s;    491 sec;\n",
      "[2024-03-14 12:45:58,748 INFO] Step 1420/11000; acc: 43.8; ppl:  28.7; xent: 3.4; lr: 1.00000; sents:     640; bsz:  283/ 303/32; 829/888 tok/s;    498 sec;\n",
      "[2024-03-14 12:46:06,073 INFO] Step 1440/11000; acc: 42.1; ppl:  35.4; xent: 3.6; lr: 1.00000; sents:     640; bsz:  296/ 312/32; 808/852 tok/s;    505 sec;\n",
      "[2024-03-14 12:46:13,017 INFO] Step 1460/11000; acc: 42.9; ppl:  30.1; xent: 3.4; lr: 1.00000; sents:     640; bsz:  302/ 310/32; 871/894 tok/s;    512 sec;\n",
      "[2024-03-14 12:46:21,220 INFO] Step 1480/11000; acc: 42.7; ppl:  29.3; xent: 3.4; lr: 1.00000; sents:     640; bsz:  288/ 320/32; 702/780 tok/s;    520 sec;\n",
      "[2024-03-14 12:46:27,893 INFO] Step 1500/11000; acc: 44.3; ppl:  25.5; xent: 3.2; lr: 1.00000; sents:     640; bsz:  280/ 293/32; 839/878 tok/s;    527 sec;\n",
      "[2024-03-14 12:46:34,469 INFO] Step 1520/11000; acc: 44.8; ppl:  28.5; xent: 3.4; lr: 1.00000; sents:     640; bsz:  269/ 304/32; 818/925 tok/s;    533 sec;\n",
      "[2024-03-14 12:46:42,193 INFO] Step 1540/11000; acc: 42.1; ppl:  32.4; xent: 3.5; lr: 1.00000; sents:     640; bsz:  292/ 324/32; 756/839 tok/s;    541 sec;\n",
      "[2024-03-14 12:46:48,636 INFO] Step 1560/11000; acc: 45.7; ppl:  25.7; xent: 3.2; lr: 1.00000; sents:     640; bsz:  261/ 299/32; 810/929 tok/s;    548 sec;\n",
      "[2024-03-14 12:46:56,479 INFO] Step 1580/11000; acc: 42.2; ppl:  31.2; xent: 3.4; lr: 1.00000; sents:     640; bsz:  296/ 318/32; 755/812 tok/s;    555 sec;\n",
      "[2024-03-14 12:47:03,859 INFO] Step 1600/11000; acc: 43.9; ppl:  27.4; xent: 3.3; lr: 1.00000; sents:     640; bsz:  302/ 315/32; 820/854 tok/s;    563 sec;\n",
      "[2024-03-14 12:47:10,028 INFO] Step 1620/11000; acc: 47.5; ppl:  20.5; xent: 3.0; lr: 1.00000; sents:     640; bsz:  251/ 283/32; 814/919 tok/s;    569 sec;\n",
      "[2024-03-14 12:47:16,698 INFO] Step 1640/11000; acc: 45.8; ppl:  23.8; xent: 3.2; lr: 1.00000; sents:     640; bsz:  299/ 297/32; 897/891 tok/s;    576 sec;\n",
      "[2024-03-14 12:47:23,628 INFO] Step 1660/11000; acc: 45.6; ppl:  24.6; xent: 3.2; lr: 1.00000; sents:     640; bsz:  290/ 298/32; 836/861 tok/s;    583 sec;\n",
      "[2024-03-14 12:47:32,193 INFO] Step 1680/11000; acc: 42.7; ppl:  37.7; xent: 3.6; lr: 1.00000; sents:     640; bsz:  303/ 304/32; 707/709 tok/s;    591 sec;\n",
      "[2024-03-14 12:47:40,318 INFO] Step 1700/11000; acc: 41.4; ppl:  38.6; xent: 3.7; lr: 1.00000; sents:     640; bsz:  327/ 330/32; 806/813 tok/s;    599 sec;\n",
      "[2024-03-14 12:47:47,262 INFO] Step 1720/11000; acc: 45.2; ppl:  24.0; xent: 3.2; lr: 1.00000; sents:     640; bsz:  291/ 310/32; 839/894 tok/s;    606 sec;\n",
      "[2024-03-14 12:47:54,593 INFO] Step 1740/11000; acc: 44.8; ppl:  24.5; xent: 3.2; lr: 1.00000; sents:     640; bsz:  306/ 330/32; 834/899 tok/s;    614 sec;\n",
      "[2024-03-14 12:48:02,816 INFO] Step 1760/11000; acc: 45.8; ppl:  23.5; xent: 3.2; lr: 1.00000; sents:     640; bsz:  271/ 313/32; 660/762 tok/s;    622 sec;\n",
      "[2024-03-14 12:48:11,091 INFO] Step 1780/11000; acc: 42.1; ppl:  28.5; xent: 3.3; lr: 1.00000; sents:     640; bsz:  330/ 368/32; 797/891 tok/s;    630 sec;\n",
      "[2024-03-14 12:48:17,794 INFO] Step 1800/11000; acc: 45.8; ppl:  25.4; xent: 3.2; lr: 1.00000; sents:     640; bsz:  296/ 296/32; 883/883 tok/s;    637 sec;\n",
      "[2024-03-14 12:48:23,979 INFO] Step 1820/11000; acc: 49.7; ppl:  17.9; xent: 2.9; lr: 1.00000; sents:     640; bsz:  253/ 285/32; 818/921 tok/s;    643 sec;\n",
      "[2024-03-14 12:48:30,572 INFO] Step 1840/11000; acc: 46.2; ppl:  21.1; xent: 3.0; lr: 1.00000; sents:     640; bsz:  270/ 303/32; 820/921 tok/s;    650 sec;\n",
      "[2024-03-14 12:48:38,242 INFO] Step 1860/11000; acc: 46.9; ppl:  21.7; xent: 3.1; lr: 1.00000; sents:     640; bsz:  288/ 306/32; 751/797 tok/s;    657 sec;\n",
      "[2024-03-14 12:48:44,443 INFO] Step 1880/11000; acc: 47.6; ppl:  19.5; xent: 3.0; lr: 1.00000; sents:     640; bsz:  251/ 280/32; 810/905 tok/s;    663 sec;\n",
      "[2024-03-14 12:48:50,744 INFO] Step 1900/11000; acc: 48.9; ppl:  18.3; xent: 2.9; lr: 1.00000; sents:     640; bsz:  274/ 281/32; 868/892 tok/s;    670 sec;\n",
      "[2024-03-14 12:48:57,488 INFO] Step 1920/11000; acc: 47.2; ppl:  19.7; xent: 3.0; lr: 1.00000; sents:     640; bsz:  267/ 306/32; 792/906 tok/s;    676 sec;\n",
      "[2024-03-14 12:49:03,465 INFO] Step 1940/11000; acc: 49.5; ppl:  18.6; xent: 2.9; lr: 1.00000; sents:     640; bsz:  250/ 270/32; 835/902 tok/s;    682 sec;\n",
      "[2024-03-14 12:49:10,013 INFO] Step 1960/11000; acc: 48.2; ppl:  19.5; xent: 3.0; lr: 1.00000; sents:     640; bsz:  272/ 296/32; 831/904 tok/s;    689 sec;\n",
      "[2024-03-14 12:49:17,423 INFO] Step 1980/11000; acc: 46.2; ppl:  22.4; xent: 3.1; lr: 1.00000; sents:     640; bsz:  310/ 325/32; 838/877 tok/s;    696 sec;\n",
      "[2024-03-14 12:49:24,096 INFO] Step 2000/11000; acc: 47.7; ppl:  21.0; xent: 3.0; lr: 1.00000; sents:     640; bsz:  285/ 296/32; 854/887 tok/s;    703 sec;\n",
      "[2024-03-14 12:49:31,189 INFO] valid stats calculation\n",
      "                           took: 7.091670513153076 s.\n",
      "[2024-03-14 12:49:31,189 INFO] Train perplexity: 76.0214\n",
      "[2024-03-14 12:49:31,189 INFO] Train accuracy: 34.5201\n",
      "[2024-03-14 12:49:31,189 INFO] Sentences processed: 64000\n",
      "[2024-03-14 12:49:31,189 INFO] Average bsz:  280/ 302/32\n",
      "[2024-03-14 12:49:31,190 INFO] Validation perplexity: 15.024\n",
      "[2024-03-14 12:49:31,190 INFO] Validation accuracy: 53.593\n",
      "[2024-03-14 12:49:38,293 INFO] Step 2020/11000; acc: 49.3; ppl:  18.9; xent: 2.9; lr: 1.00000; sents:     640; bsz:  264/ 284/32; 372/400 tok/s;    717 sec;\n",
      "[2024-03-14 12:49:46,093 INFO] Step 2040/11000; acc: 46.1; ppl:  23.7; xent: 3.2; lr: 1.00000; sents:     640; bsz:  314/ 309/32; 805/793 tok/s;    725 sec;\n",
      "[2024-03-14 12:49:54,061 INFO] Step 2060/11000; acc: 45.2; ppl:  24.5; xent: 3.2; lr: 1.00000; sents:     640; bsz:  317/ 322/32; 797/809 tok/s;    733 sec;\n",
      "[2024-03-14 12:50:01,350 INFO] Step 2080/11000; acc: 47.6; ppl:  19.7; xent: 3.0; lr: 1.00000; sents:     640; bsz:  314/ 326/32; 861/896 tok/s;    740 sec;\n",
      "[2024-03-14 12:50:08,854 INFO] Step 2100/11000; acc: 47.3; ppl:  20.5; xent: 3.0; lr: 1.00000; sents:     640; bsz:  312/ 340/32; 832/905 tok/s;    748 sec;\n",
      "[2024-03-14 12:50:17,204 INFO] Step 2120/11000; acc: 48.6; ppl:  18.0; xent: 2.9; lr: 1.00000; sents:     640; bsz:  309/ 327/32; 740/783 tok/s;    756 sec;\n",
      "[2024-03-14 12:50:24,217 INFO] Step 2140/11000; acc: 49.2; ppl:  17.8; xent: 2.9; lr: 1.00000; sents:     640; bsz:  302/ 306/32; 862/872 tok/s;    763 sec;\n",
      "[2024-03-14 12:50:30,372 INFO] Step 2160/11000; acc: 52.1; ppl:  14.6; xent: 2.7; lr: 1.00000; sents:     640; bsz:  259/ 277/32; 843/900 tok/s;    769 sec;\n",
      "[2024-03-14 12:50:36,404 INFO] Step 2180/11000; acc: 53.6; ppl:  13.9; xent: 2.6; lr: 1.00000; sents:     640; bsz:  245/ 277/32; 812/918 tok/s;    775 sec;\n",
      "[2024-03-14 12:50:42,651 INFO] Step 2200/11000; acc: 52.7; ppl:  15.1; xent: 2.7; lr: 1.00000; sents:     640; bsz:  264/ 277/32; 845/886 tok/s;    782 sec;\n",
      "[2024-03-14 12:50:49,842 INFO] Step 2220/11000; acc: 50.2; ppl:  17.3; xent: 2.8; lr: 1.00000; sents:     640; bsz:  264/ 280/32; 734/779 tok/s;    789 sec;\n",
      "[2024-03-14 12:50:56,158 INFO] Step 2240/11000; acc: 51.7; ppl:  15.8; xent: 2.8; lr: 1.00000; sents:     640; bsz:  261/ 270/32; 826/856 tok/s;    795 sec;\n",
      "[2024-03-14 12:51:03,034 INFO] Step 2260/11000; acc: 50.5; ppl:  16.0; xent: 2.8; lr: 1.00000; sents:     640; bsz:  286/ 301/32; 833/875 tok/s;    802 sec;\n",
      "[2024-03-14 12:51:10,071 INFO] Step 2280/11000; acc: 50.6; ppl:  16.6; xent: 2.8; lr: 1.00000; sents:     640; bsz:  283/ 301/32; 804/855 tok/s;    809 sec;\n",
      "[2024-03-14 12:51:16,994 INFO] Step 2300/11000; acc: 51.0; ppl:  15.3; xent: 2.7; lr: 1.00000; sents:     640; bsz:  286/ 314/32; 827/907 tok/s;    816 sec;\n",
      "[2024-03-14 12:51:25,099 INFO] Step 2320/11000; acc: 48.7; ppl:  17.7; xent: 2.9; lr: 1.00000; sents:     640; bsz:  306/ 324/32; 754/798 tok/s;    824 sec;\n",
      "[2024-03-14 12:51:31,947 INFO] Step 2340/11000; acc: 49.9; ppl:  17.1; xent: 2.8; lr: 1.00000; sents:     640; bsz:  293/ 304/32; 855/888 tok/s;    831 sec;\n",
      "[2024-03-14 12:51:38,605 INFO] Step 2360/11000; acc: 50.8; ppl:  15.6; xent: 2.7; lr: 1.00000; sents:     640; bsz:  288/ 298/32; 865/894 tok/s;    838 sec;\n",
      "[2024-03-14 12:51:44,960 INFO] Step 2380/11000; acc: 53.4; ppl:  13.9; xent: 2.6; lr: 1.00000; sents:     640; bsz:  267/ 291/32; 841/916 tok/s;    844 sec;\n",
      "[2024-03-14 12:51:51,272 INFO] Step 2400/11000; acc: 50.9; ppl:  16.5; xent: 2.8; lr: 1.00000; sents:     640; bsz:  262/ 288/32; 831/913 tok/s;    850 sec;\n",
      "[2024-03-14 12:51:58,144 INFO] Step 2420/11000; acc: 55.9; ppl:  12.2; xent: 2.5; lr: 1.00000; sents:     640; bsz:  251/ 264/32; 731/768 tok/s;    857 sec;\n",
      "[2024-03-14 12:52:05,010 INFO] Step 2440/11000; acc: 52.5; ppl:  13.7; xent: 2.6; lr: 1.00000; sents:     640; bsz:  262/ 299/32; 764/872 tok/s;    864 sec;\n",
      "[2024-03-14 12:52:11,141 INFO] Step 2460/11000; acc: 53.5; ppl:  13.6; xent: 2.6; lr: 1.00000; sents:     640; bsz:  264/ 272/32; 861/887 tok/s;    870 sec;\n",
      "[2024-03-14 12:52:17,497 INFO] Step 2480/11000; acc: 54.3; ppl:  13.6; xent: 2.6; lr: 1.00000; sents:     640; bsz:  278/ 279/32; 876/878 tok/s;    876 sec;\n",
      "[2024-03-14 12:52:23,893 INFO] Step 2500/11000; acc: 52.5; ppl:  14.2; xent: 2.7; lr: 1.00000; sents:     640; bsz:  275/ 290/32; 861/906 tok/s;    883 sec;\n",
      "[2024-03-14 12:52:31,641 INFO] Step 2520/11000; acc: 53.2; ppl:  13.0; xent: 2.6; lr: 1.00000; sents:     640; bsz:  291/ 302/32; 752/779 tok/s;    891 sec;\n",
      "[2024-03-14 12:52:38,617 INFO] Step 2540/11000; acc: 52.5; ppl:  14.0; xent: 2.6; lr: 1.00000; sents:     640; bsz:  294/ 310/32; 844/890 tok/s;    898 sec;\n",
      "[2024-03-14 12:52:45,442 INFO] Step 2560/11000; acc: 52.2; ppl:  14.8; xent: 2.7; lr: 1.00000; sents:     640; bsz:  288/ 308/32; 844/904 tok/s;    904 sec;\n",
      "[2024-03-14 12:52:52,593 INFO] Step 2580/11000; acc: 50.0; ppl:  15.7; xent: 2.8; lr: 1.00000; sents:     640; bsz:  310/ 322/32; 868/899 tok/s;    912 sec;\n",
      "[2024-03-14 12:52:59,251 INFO] Step 2600/11000; acc: 52.7; ppl:  14.2; xent: 2.7; lr: 1.00000; sents:     640; bsz:  296/ 291/32; 889/875 tok/s;    918 sec;\n",
      "[2024-03-14 12:53:06,902 INFO] Step 2620/11000; acc: 52.7; ppl:  12.9; xent: 2.6; lr: 1.00000; sents:     640; bsz:  286/ 307/32; 749/803 tok/s;    926 sec;\n",
      "[2024-03-14 12:53:14,230 INFO] Step 2640/11000; acc: 51.7; ppl:  14.5; xent: 2.7; lr: 1.00000; sents:     640; bsz:  294/ 322/32; 804/880 tok/s;    933 sec;\n",
      "[2024-03-14 12:53:21,057 INFO] Step 2660/11000; acc: 53.5; ppl:  12.2; xent: 2.5; lr: 1.00000; sents:     640; bsz:  286/ 309/32; 839/905 tok/s;    940 sec;\n",
      "[2024-03-14 12:53:27,421 INFO] Step 2680/11000; acc: 54.1; ppl:  12.2; xent: 2.5; lr: 1.00000; sents:     640; bsz:  264/ 284/32; 830/893 tok/s;    946 sec;\n",
      "[2024-03-14 12:53:34,838 INFO] Step 2700/11000; acc: 51.8; ppl:  14.1; xent: 2.6; lr: 1.00000; sents:     640; bsz:  288/ 317/32; 776/855 tok/s;    954 sec;\n",
      "[2024-03-14 12:53:43,357 INFO] Step 2720/11000; acc: 51.6; ppl:  13.4; xent: 2.6; lr: 1.00000; sents:     640; bsz:  306/ 336/32; 717/789 tok/s;    962 sec;\n",
      "[2024-03-14 12:53:50,614 INFO] Step 2740/11000; acc: 53.5; ppl:  13.2; xent: 2.6; lr: 1.00000; sents:     640; bsz:  317/ 321/32; 873/883 tok/s;    970 sec;\n",
      "[2024-03-14 12:53:57,060 INFO] Step 2760/11000; acc: 55.0; ppl:  11.2; xent: 2.4; lr: 1.00000; sents:     640; bsz:  277/ 288/32; 859/894 tok/s;    976 sec;\n",
      "[2024-03-14 12:54:03,439 INFO] Step 2780/11000; acc: 55.4; ppl:  10.8; xent: 2.4; lr: 1.00000; sents:     640; bsz:  269/ 290/32; 843/908 tok/s;    982 sec;\n",
      "[2024-03-14 12:54:11,074 INFO] Step 2800/11000; acc: 54.1; ppl:  12.3; xent: 2.5; lr: 1.00000; sents:     640; bsz:  291/ 309/32; 763/810 tok/s;    990 sec;\n",
      "[2024-03-14 12:54:17,914 INFO] Step 2820/11000; acc: 54.3; ppl:  12.4; xent: 2.5; lr: 1.00000; sents:     640; bsz:  288/ 300/32; 842/876 tok/s;    997 sec;\n",
      "[2024-03-14 12:54:24,406 INFO] Step 2840/11000; acc: 55.9; ppl:  10.8; xent: 2.4; lr: 1.00000; sents:     640; bsz:  282/ 292/32; 868/899 tok/s;   1003 sec;\n",
      "[2024-03-14 12:54:30,771 INFO] Step 2860/11000; acc: 55.8; ppl:  11.1; xent: 2.4; lr: 1.00000; sents:     640; bsz:  262/ 288/32; 825/905 tok/s;   1010 sec;\n",
      "[2024-03-14 12:54:37,032 INFO] Step 2880/11000; acc: 55.8; ppl:  11.7; xent: 2.5; lr: 1.00000; sents:     640; bsz:  259/ 288/32; 828/920 tok/s;   1016 sec;\n",
      "[2024-03-14 12:54:43,715 INFO] Step 2900/11000; acc: 57.3; ppl:  10.1; xent: 2.3; lr: 1.00000; sents:     640; bsz:  251/ 272/32; 752/814 tok/s;   1023 sec;\n",
      "[2024-03-14 12:54:50,608 INFO] Step 2920/11000; acc: 57.8; ppl:   9.6; xent: 2.3; lr: 1.00000; sents:     640; bsz:  262/ 280/32; 761/813 tok/s;   1030 sec;\n",
      "[2024-03-14 12:54:57,246 INFO] Step 2940/11000; acc: 56.7; ppl:  10.1; xent: 2.3; lr: 1.00000; sents:     640; bsz:  275/ 296/32; 829/891 tok/s;   1036 sec;\n",
      "[2024-03-14 12:55:04,899 INFO] Step 2960/11000; acc: 51.4; ppl:  16.3; xent: 2.8; lr: 1.00000; sents:     640; bsz:  296/ 332/32; 774/867 tok/s;   1044 sec;\n",
      "[2024-03-14 12:55:13,492 INFO] Step 2980/11000; acc: 49.8; ppl:  16.3; xent: 2.8; lr: 1.00000; sents:     640; bsz:  350/ 360/32; 814/837 tok/s;   1052 sec;\n",
      "[2024-03-14 12:55:21,915 INFO] Step 3000/11000; acc: 53.8; ppl:  11.9; xent: 2.5; lr: 1.00000; sents:     640; bsz:  315/ 344/32; 748/817 tok/s;   1061 sec;\n",
      "[2024-03-14 12:55:29,602 INFO] valid stats calculation\n",
      "                           took: 7.6871185302734375 s.\n",
      "[2024-03-14 12:55:29,603 INFO] Train perplexity: 43.7273\n",
      "[2024-03-14 12:55:29,603 INFO] Train accuracy: 40.3808\n",
      "[2024-03-14 12:55:29,603 INFO] Sentences processed: 96000\n",
      "[2024-03-14 12:55:29,603 INFO] Average bsz:  282/ 302/32\n",
      "[2024-03-14 12:55:29,603 INFO] Validation perplexity: 9.45191\n",
      "[2024-03-14 12:55:29,603 INFO] Validation accuracy: 59.6894\n",
      "[2024-03-14 12:55:36,407 INFO] Step 3020/11000; acc: 56.5; ppl:  10.2; xent: 2.3; lr: 1.00000; sents:     640; bsz:  298/ 296/32; 411/408 tok/s;   1075 sec;\n",
      "[2024-03-14 12:55:43,284 INFO] Step 3040/11000; acc: 58.1; ppl:   8.9; xent: 2.2; lr: 1.00000; sents:     640; bsz:  275/ 288/32; 800/838 tok/s;   1082 sec;\n",
      "[2024-03-14 12:55:48,970 INFO] Step 3060/11000; acc: 59.4; ppl:   8.7; xent: 2.2; lr: 1.00000; sents:     640; bsz:  232/ 262/32; 816/923 tok/s;   1088 sec;\n",
      "[2024-03-14 12:55:57,668 INFO] Step 3080/11000; acc: 53.2; ppl:  11.7; xent: 2.5; lr: 1.00000; sents:     640; bsz:  310/ 342/32; 714/786 tok/s;   1097 sec;\n",
      "[2024-03-14 12:56:04,592 INFO] Step 3100/11000; acc: 57.3; ppl:   9.8; xent: 2.3; lr: 1.00000; sents:     640; bsz:  261/ 293/32; 753/846 tok/s;   1104 sec;\n",
      "[2024-03-14 12:56:11,097 INFO] Step 3120/11000; acc: 57.5; ppl:   9.2; xent: 2.2; lr: 1.00000; sents:     640; bsz:  259/ 301/32; 797/925 tok/s;   1110 sec;\n",
      "[2024-03-14 12:56:17,410 INFO] Step 3140/11000; acc: 57.0; ppl:   9.9; xent: 2.3; lr: 1.00000; sents:     640; bsz:  288/ 277/32; 913/877 tok/s;   1116 sec;\n",
      "[2024-03-14 12:56:24,587 INFO] Step 3160/11000; acc: 55.3; ppl:  10.8; xent: 2.4; lr: 1.00000; sents:     640; bsz:  298/ 307/32; 829/856 tok/s;   1124 sec;\n",
      "[2024-03-14 12:56:31,834 INFO] Step 3180/11000; acc: 59.1; ppl:   8.6; xent: 2.2; lr: 1.00000; sents:     640; bsz:  278/ 291/32; 768/804 tok/s;   1131 sec;\n",
      "[2024-03-14 12:56:37,860 INFO] Step 3200/11000; acc: 61.2; ppl:   7.5; xent: 2.0; lr: 1.00000; sents:     640; bsz:  248/ 264/32; 823/876 tok/s;   1137 sec;\n",
      "[2024-03-14 12:56:45,312 INFO] Step 3220/11000; acc: 54.8; ppl:  11.1; xent: 2.4; lr: 1.00000; sents:     640; bsz:  306/ 334/32; 820/895 tok/s;   1144 sec;\n",
      "[2024-03-14 12:56:52,161 INFO] Step 3240/11000; acc: 58.0; ppl:   9.1; xent: 2.2; lr: 1.00000; sents:     640; bsz:  288/ 312/32; 841/911 tok/s;   1151 sec;\n",
      "[2024-03-14 12:56:59,802 INFO] Step 3260/11000; acc: 56.5; ppl:  10.5; xent: 2.4; lr: 1.00000; sents:     640; bsz:  299/ 319/32; 783/836 tok/s;   1159 sec;\n",
      "[2024-03-14 12:57:06,889 INFO] Step 3280/11000; acc: 59.6; ppl:   8.3; xent: 2.1; lr: 1.00000; sents:     640; bsz:  256/ 299/32; 722/845 tok/s;   1166 sec;\n",
      "[2024-03-14 12:57:13,209 INFO] Step 3300/11000; acc: 60.4; ppl:   7.6; xent: 2.0; lr: 1.00000; sents:     640; bsz:  266/ 283/32; 841/896 tok/s;   1172 sec;\n",
      "[2024-03-14 12:57:19,118 INFO] Step 3320/11000; acc: 62.2; ppl:   6.8; xent: 1.9; lr: 1.00000; sents:     640; bsz:  251/ 266/32; 850/899 tok/s;   1178 sec;\n",
      "[2024-03-14 12:57:26,160 INFO] Step 3340/11000; acc: 58.5; ppl:   9.0; xent: 2.2; lr: 1.00000; sents:     640; bsz:  296/ 310/32; 841/881 tok/s;   1185 sec;\n",
      "[2024-03-14 12:57:34,150 INFO] Step 3360/11000; acc: 57.5; ppl:   9.2; xent: 2.2; lr: 1.00000; sents:     640; bsz:  307/ 328/32; 769/820 tok/s;   1193 sec;\n",
      "[2024-03-14 12:57:41,540 INFO] Step 3380/11000; acc: 57.9; ppl:   9.3; xent: 2.2; lr: 1.00000; sents:     640; bsz:  288/ 309/32; 779/836 tok/s;   1201 sec;\n",
      "[2024-03-14 12:57:47,962 INFO] Step 3400/11000; acc: 59.1; ppl:   8.8; xent: 2.2; lr: 1.00000; sents:     640; bsz:  291/ 280/32; 907/872 tok/s;   1207 sec;\n",
      "[2024-03-14 12:57:54,699 INFO] Step 3420/11000; acc: 57.7; ppl:   8.8; xent: 2.2; lr: 1.00000; sents:     640; bsz:  288/ 302/32; 855/898 tok/s;   1214 sec;\n",
      "[2024-03-14 12:58:02,516 INFO] Step 3440/11000; acc: 53.4; ppl:  13.6; xent: 2.6; lr: 1.00000; sents:     640; bsz:  318/ 338/32; 813/864 tok/s;   1221 sec;\n",
      "[2024-03-14 12:58:10,437 INFO] Step 3460/11000; acc: 56.9; ppl:  10.7; xent: 2.4; lr: 1.00000; sents:     640; bsz:  276/ 302/32; 698/762 tok/s;   1229 sec;\n",
      "[2024-03-14 12:58:16,005 INFO] Step 3480/11000; acc: 63.2; ppl:   6.8; xent: 1.9; lr: 1.00000; sents:     640; bsz:  219/ 246/32; 787/885 tok/s;   1235 sec;\n",
      "[2024-03-14 12:58:22,711 INFO] Step 3500/11000; acc: 56.7; ppl:   9.4; xent: 2.2; lr: 1.00000; sents:     640; bsz:  278/ 301/32; 830/897 tok/s;   1242 sec;\n",
      "[2024-03-14 12:58:28,939 INFO] Step 3520/11000; acc: 61.6; ppl:   6.9; xent: 1.9; lr: 1.00000; sents:     640; bsz:  259/ 274/32; 832/880 tok/s;   1248 sec;\n",
      "[2024-03-14 12:58:35,747 INFO] Step 3540/11000; acc: 60.2; ppl:   7.9; xent: 2.1; lr: 1.00000; sents:     640; bsz:  283/ 312/32; 832/917 tok/s;   1255 sec;\n",
      "[2024-03-14 12:58:43,157 INFO] Step 3560/11000; acc: 60.1; ppl:   7.8; xent: 2.1; lr: 1.00000; sents:     640; bsz:  258/ 293/32; 695/790 tok/s;   1262 sec;\n",
      "[2024-03-14 12:58:49,496 INFO] Step 3580/11000; acc: 60.7; ppl:   7.6; xent: 2.0; lr: 1.00000; sents:     640; bsz:  245/ 282/32; 772/889 tok/s;   1268 sec;\n",
      "[2024-03-14 12:58:55,674 INFO] Step 3600/11000; acc: 63.1; ppl:   6.6; xent: 1.9; lr: 1.00000; sents:     640; bsz:  242/ 278/32; 782/901 tok/s;   1275 sec;\n",
      "[2024-03-14 12:59:01,349 INFO] Step 3620/11000; acc: 64.6; ppl:   6.3; xent: 1.8; lr: 1.00000; sents:     640; bsz:  240/ 258/32; 846/908 tok/s;   1280 sec;\n",
      "[2024-03-14 12:59:07,494 INFO] Step 3640/11000; acc: 61.8; ppl:   6.8; xent: 1.9; lr: 1.00000; sents:     640; bsz:  266/ 270/32; 864/880 tok/s;   1286 sec;\n",
      "[2024-03-14 12:59:15,809 INFO] Step 3660/11000; acc: 57.9; ppl:   9.2; xent: 2.2; lr: 1.00000; sents:     640; bsz:  338/ 336/32; 812/808 tok/s;   1295 sec;\n",
      "[2024-03-14 12:59:22,455 INFO] Step 3680/11000; acc: 62.6; ppl:   7.0; xent: 1.9; lr: 1.00000; sents:     640; bsz:  272/ 283/32; 819/852 tok/s;   1301 sec;\n",
      "[2024-03-14 12:59:29,658 INFO] Step 3700/11000; acc: 58.3; ppl:   8.8; xent: 2.2; lr: 1.00000; sents:     640; bsz:  320/ 314/32; 889/873 tok/s;   1309 sec;\n",
      "[2024-03-14 12:59:36,017 INFO] Step 3720/11000; acc: 62.7; ppl:   6.5; xent: 1.9; lr: 1.00000; sents:     640; bsz:  266/ 286/32; 835/901 tok/s;   1315 sec;\n",
      "[2024-03-14 12:59:42,832 INFO] Step 3740/11000; acc: 59.2; ppl:   8.2; xent: 2.1; lr: 1.00000; sents:     640; bsz:  290/ 304/32; 850/892 tok/s;   1322 sec;\n",
      "[2024-03-14 12:59:50,934 INFO] Step 3760/11000; acc: 57.3; ppl:   9.0; xent: 2.2; lr: 1.00000; sents:     640; bsz:  294/ 325/32; 727/802 tok/s;   1330 sec;\n",
      "[2024-03-14 12:59:57,736 INFO] Step 3780/11000; acc: 60.8; ppl:   8.0; xent: 2.1; lr: 1.00000; sents:     640; bsz:  272/ 301/32; 800/884 tok/s;   1337 sec;\n",
      "[2024-03-14 13:00:04,484 INFO] Step 3800/11000; acc: 60.2; ppl:   7.7; xent: 2.0; lr: 1.00000; sents:     640; bsz:  285/ 301/32; 844/892 tok/s;   1343 sec;\n",
      "[2024-03-14 13:00:11,218 INFO] Step 3820/11000; acc: 60.9; ppl:   7.5; xent: 2.0; lr: 1.00000; sents:     640; bsz:  280/ 302/32; 832/898 tok/s;   1350 sec;\n",
      "[2024-03-14 13:00:18,795 INFO] Step 3840/11000; acc: 59.5; ppl:   8.1; xent: 2.1; lr: 1.00000; sents:     640; bsz:  310/ 326/32; 819/860 tok/s;   1358 sec;\n",
      "[2024-03-14 13:00:26,297 INFO] Step 3860/11000; acc: 64.1; ppl:   5.9; xent: 1.8; lr: 1.00000; sents:     640; bsz:  277/ 294/32; 738/785 tok/s;   1365 sec;\n",
      "[2024-03-14 13:00:33,613 INFO] Step 3880/11000; acc: 60.8; ppl:   7.9; xent: 2.1; lr: 1.00000; sents:     640; bsz:  285/ 309/32; 779/844 tok/s;   1373 sec;\n",
      "[2024-03-14 13:00:40,455 INFO] Step 3900/11000; acc: 61.0; ppl:   7.1; xent: 2.0; lr: 1.00000; sents:     640; bsz:  285/ 306/32; 833/893 tok/s;   1379 sec;\n",
      "[2024-03-14 13:00:47,752 INFO] Step 3920/11000; acc: 59.9; ppl:   7.9; xent: 2.1; lr: 1.00000; sents:     640; bsz:  299/ 322/32; 819/883 tok/s;   1387 sec;\n",
      "[2024-03-14 13:00:54,579 INFO] Step 3940/11000; acc: 63.5; ppl:   6.1; xent: 1.8; lr: 1.00000; sents:     640; bsz:  259/ 311/32; 759/912 tok/s;   1394 sec;\n",
      "[2024-03-14 13:01:02,678 INFO] Step 3960/11000; acc: 61.7; ppl:   7.1; xent: 2.0; lr: 1.00000; sents:     640; bsz:  307/ 315/32; 759/778 tok/s;   1402 sec;\n",
      "[2024-03-14 13:01:09,652 INFO] Step 3980/11000; acc: 61.4; ppl:   7.0; xent: 1.9; lr: 1.00000; sents:     640; bsz:  293/ 310/32; 840/890 tok/s;   1409 sec;\n",
      "[2024-03-14 13:01:16,270 INFO] Step 4000/11000; acc: 63.1; ppl:   6.3; xent: 1.8; lr: 1.00000; sents:     640; bsz:  280/ 301/32; 846/909 tok/s;   1415 sec;\n",
      "[2024-03-14 13:01:23,402 INFO] valid stats calculation\n",
      "                           took: 7.131548881530762 s.\n",
      "[2024-03-14 13:01:23,408 INFO] Train perplexity: 28.9491\n",
      "[2024-03-14 13:01:23,408 INFO] Train accuracy: 45.0975\n",
      "[2024-03-14 13:01:23,408 INFO] Sentences processed: 128000\n",
      "[2024-03-14 13:01:23,408 INFO] Average bsz:  281/ 301/32\n",
      "[2024-03-14 13:01:23,408 INFO] Validation perplexity: 7.59564\n",
      "[2024-03-14 13:01:23,408 INFO] Validation accuracy: 64.3023\n",
      "[2024-03-14 13:01:31,224 INFO] Step 4020/11000; acc: 59.3; ppl:   8.0; xent: 2.1; lr: 1.00000; sents:     640; bsz:  299/ 322/32; 400/430 tok/s;   1430 sec;\n",
      "[2024-03-14 13:01:38,464 INFO] Step 4040/11000; acc: 63.5; ppl:   6.4; xent: 1.9; lr: 1.00000; sents:     640; bsz:  288/ 298/32; 796/822 tok/s;   1437 sec;\n",
      "[2024-03-14 13:01:45,418 INFO] Step 4060/11000; acc: 61.7; ppl:   6.9; xent: 1.9; lr: 1.00000; sents:     640; bsz:  294/ 318/32; 847/915 tok/s;   1444 sec;\n",
      "[2024-03-14 13:01:52,510 INFO] Step 4080/11000; acc: 62.0; ppl:   7.0; xent: 2.0; lr: 1.00000; sents:     640; bsz:  307/ 318/32; 866/898 tok/s;   1451 sec;\n",
      "[2024-03-14 13:01:58,987 INFO] Step 4100/11000; acc: 63.5; ppl:   6.3; xent: 1.8; lr: 1.00000; sents:     640; bsz:  280/ 283/32; 865/875 tok/s;   1458 sec;\n",
      "[2024-03-14 13:02:06,140 INFO] Step 4120/11000; acc: 62.8; ppl:   6.4; xent: 1.9; lr: 1.00000; sents:     640; bsz:  270/ 286/32; 756/801 tok/s;   1465 sec;\n",
      "[2024-03-14 13:02:12,845 INFO] Step 4140/11000; acc: 64.9; ppl:   5.5; xent: 1.7; lr: 1.00000; sents:     640; bsz:  267/ 284/32; 797/848 tok/s;   1472 sec;\n",
      "[2024-03-14 13:02:19,447 INFO] Step 4160/11000; acc: 64.3; ppl:   5.6; xent: 1.7; lr: 1.00000; sents:     640; bsz:  267/ 301/32; 810/911 tok/s;   1478 sec;\n",
      "[2024-03-14 13:02:26,030 INFO] Step 4180/11000; acc: 63.9; ppl:   5.9; xent: 1.8; lr: 1.00000; sents:     640; bsz:  283/ 294/32; 860/895 tok/s;   1485 sec;\n",
      "[2024-03-14 13:02:32,842 INFO] Step 4200/11000; acc: 62.8; ppl:   5.9; xent: 1.8; lr: 1.00000; sents:     640; bsz:  283/ 306/32; 831/897 tok/s;   1492 sec;\n",
      "[2024-03-14 13:02:40,168 INFO] Step 4220/11000; acc: 64.9; ppl:   5.9; xent: 1.8; lr: 1.00000; sents:     640; bsz:  291/ 292/32; 795/798 tok/s;   1499 sec;\n",
      "[2024-03-14 13:02:46,424 INFO] Step 4240/11000; acc: 67.6; ppl:   5.1; xent: 1.6; lr: 1.00000; sents:     640; bsz:  243/ 259/32; 778/829 tok/s;   1505 sec;\n",
      "[2024-03-14 13:02:52,855 INFO] Step 4260/11000; acc: 65.0; ppl:   5.8; xent: 1.8; lr: 1.00000; sents:     640; bsz:  269/ 291/32; 836/904 tok/s;   1512 sec;\n",
      "[2024-03-14 13:03:00,139 INFO] Step 4280/11000; acc: 63.4; ppl:   6.4; xent: 1.9; lr: 1.00000; sents:     640; bsz:  299/ 316/32; 821/868 tok/s;   1519 sec;\n",
      "[2024-03-14 13:03:07,077 INFO] Step 4300/11000; acc: 65.1; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  299/ 309/32; 863/890 tok/s;   1526 sec;\n",
      "[2024-03-14 13:03:15,652 INFO] Step 4320/11000; acc: 64.0; ppl:   6.2; xent: 1.8; lr: 1.00000; sents:     640; bsz:  307/ 336/32; 717/783 tok/s;   1535 sec;\n",
      "[2024-03-14 13:03:22,508 INFO] Step 4340/11000; acc: 64.9; ppl:   5.7; xent: 1.7; lr: 1.00000; sents:     640; bsz:  280/ 298/32; 817/869 tok/s;   1541 sec;\n",
      "[2024-03-14 13:03:28,806 INFO] Step 4360/11000; acc: 66.9; ppl:   5.1; xent: 1.6; lr: 1.00000; sents:     640; bsz:  269/ 277/32; 854/879 tok/s;   1548 sec;\n",
      "[2024-03-14 13:03:35,419 INFO] Step 4380/11000; acc: 63.9; ppl:   6.5; xent: 1.9; lr: 1.00000; sents:     640; bsz:  269/ 287/32; 813/869 tok/s;   1554 sec;\n",
      "[2024-03-14 13:03:42,726 INFO] Step 4400/11000; acc: 60.1; ppl:   8.0; xent: 2.1; lr: 1.00000; sents:     640; bsz:  301/ 323/32; 823/885 tok/s;   1562 sec;\n",
      "[2024-03-14 13:03:50,641 INFO] Step 4420/11000; acc: 61.8; ppl:   7.7; xent: 2.0; lr: 1.00000; sents:     640; bsz:  306/ 309/32; 772/781 tok/s;   1570 sec;\n",
      "[2024-03-14 13:03:57,836 INFO] Step 4440/11000; acc: 62.2; ppl:   6.7; xent: 1.9; lr: 1.00000; sents:     640; bsz:  294/ 308/32; 818/856 tok/s;   1577 sec;\n",
      "[2024-03-14 13:04:04,267 INFO] Step 4460/11000; acc: 66.3; ppl:   5.2; xent: 1.7; lr: 1.00000; sents:     640; bsz:  275/ 291/32; 856/904 tok/s;   1583 sec;\n",
      "[2024-03-14 13:04:10,714 INFO] Step 4480/11000; acc: 64.8; ppl:   5.2; xent: 1.7; lr: 1.00000; sents:     640; bsz:  272/ 293/32; 844/908 tok/s;   1590 sec;\n",
      "[2024-03-14 13:04:16,684 INFO] Step 4500/11000; acc: 69.9; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  245/ 274/32; 820/917 tok/s;   1596 sec;\n",
      "[2024-03-14 13:04:23,590 INFO] Step 4520/11000; acc: 68.5; ppl:   4.6; xent: 1.5; lr: 1.00000; sents:     640; bsz:  250/ 269/32; 723/779 tok/s;   1603 sec;\n",
      "[2024-03-14 13:04:30,455 INFO] Step 4540/11000; acc: 63.3; ppl:   6.2; xent: 1.8; lr: 1.00000; sents:     640; bsz:  283/ 304/32; 825/886 tok/s;   1609 sec;\n",
      "[2024-03-14 13:04:37,421 INFO] Step 4560/11000; acc: 63.3; ppl:   6.5; xent: 1.9; lr: 1.00000; sents:     640; bsz:  299/ 312/32; 859/895 tok/s;   1616 sec;\n",
      "[2024-03-14 13:04:44,110 INFO] Step 4580/11000; acc: 63.2; ppl:   6.4; xent: 1.9; lr: 1.00000; sents:     640; bsz:  294/ 296/32; 880/885 tok/s;   1623 sec;\n",
      "[2024-03-14 13:04:51,119 INFO] Step 4600/11000; acc: 66.5; ppl:   5.2; xent: 1.7; lr: 1.00000; sents:     640; bsz:  296/ 317/32; 845/904 tok/s;   1630 sec;\n",
      "[2024-03-14 13:04:58,481 INFO] Step 4620/11000; acc: 67.0; ppl:   4.8; xent: 1.6; lr: 1.00000; sents:     640; bsz:  262/ 286/32; 713/778 tok/s;   1637 sec;\n",
      "[2024-03-14 13:05:04,421 INFO] Step 4640/11000; acc: 67.3; ppl:   5.2; xent: 1.7; lr: 1.00000; sents:     640; bsz:  250/ 256/32; 840/862 tok/s;   1643 sec;\n",
      "[2024-03-14 13:05:11,505 INFO] Step 4660/11000; acc: 66.1; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  304/ 314/32; 858/885 tok/s;   1650 sec;\n",
      "[2024-03-14 13:05:18,106 INFO] Step 4680/11000; acc: 65.3; ppl:   5.4; xent: 1.7; lr: 1.00000; sents:     640; bsz:  272/ 298/32; 824/902 tok/s;   1657 sec;\n",
      "[2024-03-14 13:05:24,710 INFO] Step 4700/11000; acc: 67.1; ppl:   5.1; xent: 1.6; lr: 1.00000; sents:     640; bsz:  288/ 297/32; 872/899 tok/s;   1664 sec;\n",
      "[2024-03-14 13:05:31,964 INFO] Step 4720/11000; acc: 66.8; ppl:   5.1; xent: 1.6; lr: 1.00000; sents:     640; bsz:  259/ 285/32; 715/785 tok/s;   1671 sec;\n",
      "[2024-03-14 13:05:38,910 INFO] Step 4740/11000; acc: 64.7; ppl:   5.7; xent: 1.7; lr: 1.00000; sents:     640; bsz:  290/ 303/32; 834/872 tok/s;   1678 sec;\n",
      "[2024-03-14 13:05:46,701 INFO] Step 4760/11000; acc: 60.1; ppl:   8.1; xent: 2.1; lr: 1.00000; sents:     640; bsz:  316/ 336/32; 810/862 tok/s;   1686 sec;\n",
      "[2024-03-14 13:05:53,420 INFO] Step 4780/11000; acc: 67.2; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  293/ 293/32; 872/872 tok/s;   1692 sec;\n",
      "[2024-03-14 13:06:00,256 INFO] Step 4800/11000; acc: 66.7; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  286/ 310/32; 838/908 tok/s;   1699 sec;\n",
      "[2024-03-14 13:06:07,296 INFO] Step 4820/11000; acc: 69.7; ppl:   4.2; xent: 1.4; lr: 1.00000; sents:     640; bsz:  235/ 277/32; 668/786 tok/s;   1706 sec;\n",
      "[2024-03-14 13:06:14,534 INFO] Step 4840/11000; acc: 64.6; ppl:   5.7; xent: 1.7; lr: 1.00000; sents:     640; bsz:  290/ 328/32; 800/906 tok/s;   1713 sec;\n",
      "[2024-03-14 13:06:21,195 INFO] Step 4860/11000; acc: 64.0; ppl:   6.4; xent: 1.9; lr: 1.00000; sents:     640; bsz:  287/ 289/32; 862/869 tok/s;   1720 sec;\n",
      "[2024-03-14 13:06:27,960 INFO] Step 4880/11000; acc: 68.5; ppl:   4.3; xent: 1.5; lr: 1.00000; sents:     640; bsz:  306/ 291/32; 903/862 tok/s;   1727 sec;\n",
      "[2024-03-14 13:06:34,213 INFO] Step 4900/11000; acc: 68.6; ppl:   4.5; xent: 1.5; lr: 1.00000; sents:     640; bsz:  258/ 278/32; 824/891 tok/s;   1733 sec;\n",
      "[2024-03-14 13:06:41,761 INFO] Step 4920/11000; acc: 66.5; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  269/ 300/32; 712/796 tok/s;   1741 sec;\n",
      "[2024-03-14 13:06:48,678 INFO] Step 4940/11000; acc: 66.9; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  283/ 306/32; 819/884 tok/s;   1748 sec;\n",
      "[2024-03-14 13:06:55,263 INFO] Step 4960/11000; acc: 67.0; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  274/ 301/32; 831/914 tok/s;   1754 sec;\n",
      "[2024-03-14 13:07:01,558 INFO] Step 4980/11000; acc: 69.8; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  270/ 278/32; 859/885 tok/s;   1761 sec;\n",
      "[2024-03-14 13:07:07,351 INFO] Step 5000/11000; acc: 71.8; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  243/ 261/32; 840/900 tok/s;   1766 sec;\n",
      "[2024-03-14 13:07:15,597 INFO] valid stats calculation\n",
      "                           took: 8.245374202728271 s.\n",
      "[2024-03-14 13:07:15,597 INFO] Train perplexity: 20.9387\n",
      "[2024-03-14 13:07:15,597 INFO] Train accuracy: 49.0534\n",
      "[2024-03-14 13:07:15,597 INFO] Sentences processed: 160000\n",
      "[2024-03-14 13:07:15,597 INFO] Average bsz:  281/ 300/32\n",
      "[2024-03-14 13:07:15,598 INFO] Validation perplexity: 7.5341\n",
      "[2024-03-14 13:07:15,598 INFO] Validation accuracy: 65.044\n",
      "[2024-03-14 13:07:22,221 INFO] Step 5020/11000; acc: 66.2; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  267/ 297/32; 359/400 tok/s;   1781 sec;\n",
      "[2024-03-14 13:07:29,085 INFO] Step 5040/11000; acc: 66.3; ppl:   5.3; xent: 1.7; lr: 1.00000; sents:     640; bsz:  293/ 306/32; 853/891 tok/s;   1788 sec;\n",
      "[2024-03-14 13:07:36,526 INFO] Step 5060/11000; acc: 64.9; ppl:   5.4; xent: 1.7; lr: 1.00000; sents:     640; bsz:  323/ 331/32; 869/890 tok/s;   1795 sec;\n",
      "[2024-03-14 13:07:44,030 INFO] Step 5080/11000; acc: 67.0; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  304/ 299/32; 810/797 tok/s;   1803 sec;\n",
      "[2024-03-14 13:07:51,764 INFO] Step 5100/11000; acc: 66.7; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  312/ 318/32; 807/823 tok/s;   1811 sec;\n",
      "[2024-03-14 13:07:58,149 INFO] Step 5120/11000; acc: 71.3; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  277/ 285/32; 868/893 tok/s;   1817 sec;\n",
      "[2024-03-14 13:08:04,911 INFO] Step 5140/11000; acc: 67.8; ppl:   4.5; xent: 1.5; lr: 1.00000; sents:     640; bsz:  283/ 306/32; 838/904 tok/s;   1824 sec;\n",
      "[2024-03-14 13:08:11,530 INFO] Step 5160/11000; acc: 67.8; ppl:   4.6; xent: 1.5; lr: 1.00000; sents:     640; bsz:  283/ 301/32; 856/909 tok/s;   1830 sec;\n",
      "[2024-03-14 13:08:19,348 INFO] Step 5180/11000; acc: 69.5; ppl:   4.3; xent: 1.5; lr: 1.00000; sents:     640; bsz:  294/ 309/32; 753/792 tok/s;   1838 sec;\n",
      "[2024-03-14 13:08:26,644 INFO] Step 5200/11000; acc: 67.6; ppl:   4.6; xent: 1.5; lr: 1.00000; sents:     640; bsz:  299/ 320/32; 820/877 tok/s;   1846 sec;\n",
      "[2024-03-14 13:08:32,984 INFO] Step 5220/11000; acc: 70.1; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  267/ 284/32; 843/895 tok/s;   1852 sec;\n",
      "[2024-03-14 13:08:39,324 INFO] Step 5240/11000; acc: 68.8; ppl:   4.5; xent: 1.5; lr: 1.00000; sents:     640; bsz:  262/ 290/32; 828/914 tok/s;   1858 sec;\n",
      "[2024-03-14 13:08:46,712 INFO] Step 5260/11000; acc: 66.5; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  334/ 327/32; 905/885 tok/s;   1866 sec;\n",
      "[2024-03-14 13:08:54,050 INFO] Step 5280/11000; acc: 71.4; ppl:   3.5; xent: 1.3; lr: 1.00000; sents:     640; bsz:  272/ 281/32; 741/767 tok/s;   1873 sec;\n",
      "[2024-03-14 13:09:00,893 INFO] Step 5300/11000; acc: 68.0; ppl:   4.4; xent: 1.5; lr: 1.00000; sents:     640; bsz:  277/ 299/32; 809/874 tok/s;   1880 sec;\n",
      "[2024-03-14 13:09:07,453 INFO] Step 5320/11000; acc: 71.1; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  270/ 298/32; 825/907 tok/s;   1886 sec;\n",
      "[2024-03-14 13:09:13,323 INFO] Step 5340/11000; acc: 71.7; ppl:   3.5; xent: 1.3; lr: 1.00000; sents:     640; bsz:  240/ 266/32; 818/905 tok/s;   1892 sec;\n",
      "[2024-03-14 13:09:20,250 INFO] Step 5360/11000; acc: 68.5; ppl:   4.4; xent: 1.5; lr: 1.00000; sents:     640; bsz:  302/ 309/32; 873/892 tok/s;   1899 sec;\n",
      "[2024-03-14 13:09:28,075 INFO] Step 5380/11000; acc: 69.5; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  304/ 309/32; 777/789 tok/s;   1907 sec;\n",
      "[2024-03-14 13:09:34,708 INFO] Step 5400/11000; acc: 69.3; ppl:   4.3; xent: 1.5; lr: 1.00000; sents:     640; bsz:  258/ 290/32; 777/873 tok/s;   1914 sec;\n",
      "[2024-03-14 13:09:41,390 INFO] Step 5420/11000; acc: 67.1; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  298/ 296/32; 891/886 tok/s;   1920 sec;\n",
      "[2024-03-14 13:09:49,002 INFO] Step 5440/11000; acc: 66.9; ppl:   4.7; xent: 1.5; lr: 1.00000; sents:     640; bsz:  322/ 346/32; 845/908 tok/s;   1928 sec;\n",
      "[2024-03-14 13:09:54,580 INFO] Step 5460/11000; acc: 74.2; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  222/ 258/32; 797/924 tok/s;   1934 sec;\n",
      "[2024-03-14 13:10:02,775 INFO] Step 5480/11000; acc: 68.1; ppl:   4.7; xent: 1.5; lr: 1.00000; sents:     640; bsz:  312/ 328/32; 761/801 tok/s;   1942 sec;\n",
      "[2024-03-14 13:10:09,548 INFO] Step 5500/11000; acc: 69.4; ppl:   4.4; xent: 1.5; lr: 1.00000; sents:     640; bsz:  293/ 307/32; 865/907 tok/s;   1949 sec;\n",
      "[2024-03-14 13:10:16,151 INFO] Step 5520/11000; acc: 67.9; ppl:   5.0; xent: 1.6; lr: 1.00000; sents:     640; bsz:  280/ 290/32; 848/879 tok/s;   1955 sec;\n",
      "[2024-03-14 13:10:23,019 INFO] Step 5540/11000; acc: 70.0; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  290/ 312/32; 843/909 tok/s;   1962 sec;\n",
      "[2024-03-14 13:10:29,525 INFO] Step 5560/11000; acc: 70.5; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  285/ 288/32; 876/885 tok/s;   1968 sec;\n",
      "[2024-03-14 13:10:37,308 INFO] Step 5580/11000; acc: 70.5; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  282/ 296/32; 724/761 tok/s;   1976 sec;\n",
      "[2024-03-14 13:10:43,988 INFO] Step 5600/11000; acc: 69.7; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  280/ 285/32; 838/853 tok/s;   1983 sec;\n",
      "[2024-03-14 13:10:50,551 INFO] Step 5620/11000; acc: 70.9; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  267/ 301/32; 814/917 tok/s;   1990 sec;\n",
      "[2024-03-14 13:10:56,820 INFO] Step 5640/11000; acc: 72.2; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  270/ 277/32; 863/883 tok/s;   1996 sec;\n",
      "[2024-03-14 13:11:03,885 INFO] Step 5660/11000; acc: 67.7; ppl:   4.6; xent: 1.5; lr: 1.00000; sents:     640; bsz:  291/ 299/32; 824/847 tok/s;   2003 sec;\n",
      "[2024-03-14 13:11:11,263 INFO] Step 5680/11000; acc: 71.2; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  266/ 294/32; 720/798 tok/s;   2010 sec;\n",
      "[2024-03-14 13:11:17,846 INFO] Step 5700/11000; acc: 71.0; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  259/ 290/32; 788/880 tok/s;   2017 sec;\n",
      "[2024-03-14 13:11:24,608 INFO] Step 5720/11000; acc: 70.4; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  280/ 310/32; 828/918 tok/s;   2024 sec;\n",
      "[2024-03-14 13:11:30,737 INFO] Step 5740/11000; acc: 75.3; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  243/ 274/32; 794/893 tok/s;   2030 sec;\n",
      "[2024-03-14 13:11:37,421 INFO] Step 5760/11000; acc: 72.7; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  278/ 289/32; 833/864 tok/s;   2036 sec;\n",
      "[2024-03-14 13:11:45,281 INFO] Step 5780/11000; acc: 67.9; ppl:   4.6; xent: 1.5; lr: 1.00000; sents:     640; bsz:  291/ 310/32; 741/788 tok/s;   2044 sec;\n",
      "[2024-03-14 13:11:52,234 INFO] Step 5800/11000; acc: 69.6; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  291/ 304/32; 838/874 tok/s;   2051 sec;\n",
      "[2024-03-14 13:11:59,905 INFO] Step 5820/11000; acc: 65.7; ppl:   5.5; xent: 1.7; lr: 1.00000; sents:     640; bsz:  338/ 330/32; 880/860 tok/s;   2059 sec;\n",
      "[2024-03-14 13:12:06,614 INFO] Step 5840/11000; acc: 70.5; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  277/ 306/32; 825/911 tok/s;   2066 sec;\n",
      "[2024-03-14 13:12:14,237 INFO] Step 5860/11000; acc: 65.6; ppl:   5.5; xent: 1.7; lr: 1.00000; sents:     640; bsz:  316/ 324/32; 829/849 tok/s;   2073 sec;\n",
      "[2024-03-14 13:12:21,550 INFO] Step 5880/11000; acc: 72.4; ppl:   3.5; xent: 1.2; lr: 1.00000; sents:     640; bsz:  280/ 293/32; 766/801 tok/s;   2081 sec;\n",
      "[2024-03-14 13:12:28,284 INFO] Step 5900/11000; acc: 71.3; ppl:   3.5; xent: 1.3; lr: 1.00000; sents:     640; bsz:  272/ 296/32; 808/879 tok/s;   2087 sec;\n",
      "[2024-03-14 13:12:34,907 INFO] Step 5920/11000; acc: 71.7; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  278/ 297/32; 841/898 tok/s;   2094 sec;\n",
      "[2024-03-14 13:12:41,421 INFO] Step 5940/11000; acc: 73.9; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  274/ 299/32; 840/919 tok/s;   2100 sec;\n",
      "[2024-03-14 13:12:47,540 INFO] Step 5960/11000; acc: 75.7; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  254/ 267/32; 832/872 tok/s;   2107 sec;\n",
      "[2024-03-14 13:12:55,053 INFO] Step 5980/11000; acc: 71.8; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  290/ 294/32; 771/784 tok/s;   2114 sec;\n",
      "[2024-03-14 13:13:02,031 INFO] Step 6000/11000; acc: 71.4; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  278/ 293/32; 798/839 tok/s;   2121 sec;\n",
      "[2024-03-14 13:13:09,513 INFO] valid stats calculation\n",
      "                           took: 7.48211407661438 s.\n",
      "[2024-03-14 13:13:09,514 INFO] Train perplexity: 16.0155\n",
      "[2024-03-14 13:13:09,514 INFO] Train accuracy: 52.4631\n",
      "[2024-03-14 13:13:09,514 INFO] Sentences processed: 192000\n",
      "[2024-03-14 13:13:09,514 INFO] Average bsz:  281/ 300/32\n",
      "[2024-03-14 13:13:09,514 INFO] Validation perplexity: 6.20235\n",
      "[2024-03-14 13:13:09,514 INFO] Validation accuracy: 68.4052\n",
      "[2024-03-14 13:13:17,157 INFO] Step 6020/11000; acc: 70.5; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  312/ 328/32; 413/434 tok/s;   2136 sec;\n",
      "[2024-03-14 13:13:25,120 INFO] Step 6040/11000; acc: 71.5; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  283/ 302/32; 711/760 tok/s;   2144 sec;\n",
      "[2024-03-14 13:13:32,047 INFO] Step 6060/11000; acc: 71.4; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  291/ 286/32; 841/827 tok/s;   2151 sec;\n",
      "[2024-03-14 13:13:39,296 INFO] Step 6080/11000; acc: 70.4; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  262/ 309/32; 724/852 tok/s;   2158 sec;\n",
      "[2024-03-14 13:13:45,081 INFO] Step 6100/11000; acc: 73.0; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  242/ 267/32; 835/924 tok/s;   2164 sec;\n",
      "[2024-03-14 13:13:52,042 INFO] Step 6120/11000; acc: 70.2; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  296/ 325/32; 850/933 tok/s;   2171 sec;\n",
      "[2024-03-14 13:13:59,086 INFO] Step 6140/11000; acc: 69.7; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  264/ 296/32; 750/841 tok/s;   2178 sec;\n",
      "[2024-03-14 13:14:05,752 INFO] Step 6160/11000; acc: 72.5; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  269/ 285/32; 807/855 tok/s;   2185 sec;\n",
      "[2024-03-14 13:14:12,064 INFO] Step 6180/11000; acc: 73.5; ppl:   3.5; xent: 1.2; lr: 1.00000; sents:     640; bsz:  282/ 286/32; 892/908 tok/s;   2191 sec;\n",
      "[2024-03-14 13:14:18,147 INFO] Step 6200/11000; acc: 73.0; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  262/ 289/32; 863/951 tok/s;   2197 sec;\n",
      "[2024-03-14 13:14:24,377 INFO] Step 6220/11000; acc: 72.2; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  256/ 286/32; 822/920 tok/s;   2203 sec;\n",
      "[2024-03-14 13:14:30,348 INFO] Step 6240/11000; acc: 75.1; ppl:   2.9; xent: 1.0; lr: 1.00000; sents:     640; bsz:  250/ 274/32; 836/916 tok/s;   2209 sec;\n",
      "[2024-03-14 13:14:38,464 INFO] Step 6260/11000; acc: 70.3; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     640; bsz:  301/ 302/32; 741/745 tok/s;   2217 sec;\n",
      "[2024-03-14 13:14:45,956 INFO] Step 6280/11000; acc: 73.2; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  285/ 301/32; 760/803 tok/s;   2225 sec;\n",
      "[2024-03-14 13:14:52,914 INFO] Step 6300/11000; acc: 72.0; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  278/ 304/32; 800/874 tok/s;   2232 sec;\n",
      "[2024-03-14 13:14:59,451 INFO] Step 6320/11000; acc: 73.1; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  278/ 280/32; 852/857 tok/s;   2238 sec;\n",
      "[2024-03-14 13:15:07,085 INFO] Step 6340/11000; acc: 73.5; ppl:   3.2; xent: 1.1; lr: 1.00000; sents:     640; bsz:  288/ 306/32; 755/801 tok/s;   2246 sec;\n",
      "[2024-03-14 13:15:14,824 INFO] Step 6360/11000; acc: 71.2; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  314/ 314/32; 810/810 tok/s;   2254 sec;\n",
      "[2024-03-14 13:15:21,609 INFO] Step 6380/11000; acc: 74.8; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  278/ 275/32; 821/811 tok/s;   2261 sec;\n",
      "[2024-03-14 13:15:29,755 INFO] Step 6400/11000; acc: 69.5; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  323/ 338/32; 794/829 tok/s;   2269 sec;\n",
      "[2024-03-14 13:15:37,167 INFO] Step 6420/11000; acc: 71.4; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  304/ 317/32; 820/856 tok/s;   2276 sec;\n",
      "[2024-03-14 13:15:45,497 INFO] Step 6440/11000; acc: 71.3; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  309/ 314/32; 741/753 tok/s;   2284 sec;\n",
      "[2024-03-14 13:15:53,130 INFO] Step 6460/11000; acc: 69.9; ppl:   4.1; xent: 1.4; lr: 1.00000; sents:     640; bsz:  312/ 330/32; 817/864 tok/s;   2292 sec;\n",
      "[2024-03-14 13:16:00,349 INFO] Step 6480/11000; acc: 75.1; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  277/ 298/32; 767/825 tok/s;   2299 sec;\n",
      "[2024-03-14 13:16:10,081 INFO] Step 6500/11000; acc: 67.5; ppl:   5.1; xent: 1.6; lr: 1.00000; sents:     640; bsz:  323/ 342/32; 664/702 tok/s;   2309 sec;\n",
      "[2024-03-14 13:16:18,423 INFO] Step 6520/11000; acc: 73.8; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  278/ 285/32; 667/683 tok/s;   2317 sec;\n",
      "[2024-03-14 13:16:28,062 INFO] Step 6540/11000; acc: 72.7; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  301/ 317/32; 624/658 tok/s;   2327 sec;\n",
      "[2024-03-14 13:16:38,912 INFO] Step 6560/11000; acc: 69.7; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  277/ 304/32; 511/560 tok/s;   2338 sec;\n",
      "[2024-03-14 13:16:47,566 INFO] Step 6580/11000; acc: 73.6; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  283/ 302/32; 655/698 tok/s;   2347 sec;\n",
      "[2024-03-14 13:16:56,596 INFO] Step 6600/11000; acc: 74.7; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  275/ 289/32; 610/640 tok/s;   2356 sec;\n",
      "[2024-03-14 13:17:03,997 INFO] Step 6620/11000; acc: 68.9; ppl:   4.4; xent: 1.5; lr: 1.00000; sents:     640; bsz:  309/ 319/32; 835/861 tok/s;   2363 sec;\n",
      "[2024-03-14 13:17:10,546 INFO] Step 6640/11000; acc: 74.6; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  278/ 284/32; 850/867 tok/s;   2370 sec;\n",
      "[2024-03-14 13:17:16,674 INFO] Step 6660/11000; acc: 76.4; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  258/ 274/32; 841/893 tok/s;   2376 sec;\n",
      "[2024-03-14 13:17:24,002 INFO] Step 6680/11000; acc: 74.9; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  282/ 296/32; 769/808 tok/s;   2383 sec;\n",
      "[2024-03-14 13:17:31,261 INFO] Step 6700/11000; acc: 74.8; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  274/ 301/32; 754/829 tok/s;   2390 sec;\n",
      "[2024-03-14 13:17:38,034 INFO] Step 6720/11000; acc: 75.6; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  296/ 301/32; 874/888 tok/s;   2397 sec;\n",
      "[2024-03-14 13:17:44,676 INFO] Step 6740/11000; acc: 74.9; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  294/ 286/32; 886/862 tok/s;   2404 sec;\n",
      "[2024-03-14 13:17:50,737 INFO] Step 6760/11000; acc: 75.7; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  269/ 266/32; 887/877 tok/s;   2410 sec;\n",
      "[2024-03-14 13:17:58,120 INFO] Step 6780/11000; acc: 72.1; ppl:   3.5; xent: 1.3; lr: 1.00000; sents:     640; bsz:  299/ 304/32; 811/824 tok/s;   2417 sec;\n",
      "[2024-03-14 13:18:05,253 INFO] Step 6800/11000; acc: 73.6; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  280/ 293/32; 785/822 tok/s;   2424 sec;\n",
      "[2024-03-14 13:18:11,329 INFO] Step 6820/11000; acc: 74.4; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  253/ 270/32; 832/890 tok/s;   2430 sec;\n",
      "[2024-03-14 13:18:18,058 INFO] Step 6840/11000; acc: 73.8; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  270/ 309/32; 804/918 tok/s;   2437 sec;\n",
      "[2024-03-14 13:18:24,792 INFO] Step 6860/11000; acc: 74.2; ppl:   3.2; xent: 1.1; lr: 1.00000; sents:     640; bsz:  294/ 295/32; 874/875 tok/s;   2444 sec;\n",
      "[2024-03-14 13:18:31,981 INFO] Step 6880/11000; acc: 74.6; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  282/ 294/32; 783/819 tok/s;   2451 sec;\n",
      "[2024-03-14 13:18:39,204 INFO] Step 6900/11000; acc: 73.7; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  290/ 310/32; 802/860 tok/s;   2458 sec;\n",
      "[2024-03-14 13:18:45,995 INFO] Step 6920/11000; acc: 74.1; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  274/ 310/32; 806/914 tok/s;   2465 sec;\n",
      "[2024-03-14 13:18:52,309 INFO] Step 6940/11000; acc: 72.2; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  266/ 274/32; 841/867 tok/s;   2471 sec;\n",
      "[2024-03-14 13:18:58,816 INFO] Step 6960/11000; acc: 71.7; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:     640; bsz:  253/ 285/32; 779/875 tok/s;   2478 sec;\n",
      "[2024-03-14 13:19:06,428 INFO] Step 6980/11000; acc: 71.5; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  286/ 317/32; 753/832 tok/s;   2485 sec;\n",
      "[2024-03-14 13:19:14,144 INFO] Step 7000/11000; acc: 72.1; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  302/ 318/32; 784/825 tok/s;   2493 sec;\n",
      "[2024-03-14 13:19:22,459 INFO] valid stats calculation\n",
      "                           took: 8.314384460449219 s.\n",
      "[2024-03-14 13:19:22,460 INFO] Train perplexity: 12.8552\n",
      "[2024-03-14 13:19:22,460 INFO] Train accuracy: 55.3318\n",
      "[2024-03-14 13:19:22,460 INFO] Sentences processed: 224000\n",
      "[2024-03-14 13:19:22,460 INFO] Average bsz:  282/ 300/32\n",
      "[2024-03-14 13:19:22,460 INFO] Validation perplexity: 5.83212\n",
      "[2024-03-14 13:19:22,460 INFO] Validation accuracy: 70.0742\n",
      "[2024-03-14 13:19:30,258 INFO] Step 7020/11000; acc: 68.4; ppl:   4.8; xent: 1.6; lr: 1.00000; sents:     640; bsz:  312/ 326/32; 387/404 tok/s;   2509 sec;\n",
      "[2024-03-14 13:19:37,788 INFO] Step 7040/11000; acc: 68.2; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:     640; bsz:  323/ 322/32; 859/856 tok/s;   2517 sec;\n",
      "[2024-03-14 13:19:45,668 INFO] Step 7060/11000; acc: 72.7; ppl:   3.5; xent: 1.3; lr: 1.00000; sents:     640; bsz:  296/ 307/32; 751/779 tok/s;   2525 sec;\n",
      "[2024-03-14 13:19:52,133 INFO] Step 7080/11000; acc: 77.2; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  275/ 282/32; 851/871 tok/s;   2531 sec;\n",
      "[2024-03-14 13:19:59,983 INFO] Step 7100/11000; acc: 74.1; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  288/ 333/32; 734/849 tok/s;   2539 sec;\n",
      "[2024-03-14 13:20:06,442 INFO] Step 7120/11000; acc: 75.5; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  277/ 291/32; 857/902 tok/s;   2545 sec;\n",
      "[2024-03-14 13:20:12,782 INFO] Step 7140/11000; acc: 74.5; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  277/ 285/32; 873/898 tok/s;   2552 sec;\n",
      "[2024-03-14 13:20:20,130 INFO] Step 7160/11000; acc: 74.3; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  286/ 286/32; 780/780 tok/s;   2559 sec;\n",
      "[2024-03-14 13:20:27,100 INFO] Step 7180/11000; acc: 74.7; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  301/ 301/32; 863/863 tok/s;   2566 sec;\n",
      "[2024-03-14 13:20:33,959 INFO] Step 7200/11000; acc: 75.4; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  307/ 302/32; 896/881 tok/s;   2573 sec;\n",
      "[2024-03-14 13:20:39,871 INFO] Step 7220/11000; acc: 76.6; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  250/ 264/32; 845/893 tok/s;   2579 sec;\n",
      "[2024-03-14 13:20:45,681 INFO] Step 7240/11000; acc: 77.2; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  237/ 264/32; 815/910 tok/s;   2585 sec;\n",
      "[2024-03-14 13:20:52,647 INFO] Step 7260/11000; acc: 78.0; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  237/ 270/32; 680/776 tok/s;   2592 sec;\n",
      "[2024-03-14 13:20:59,081 INFO] Step 7280/11000; acc: 76.5; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  253/ 286/32; 786/890 tok/s;   2598 sec;\n",
      "[2024-03-14 13:21:06,143 INFO] Step 7300/11000; acc: 71.0; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  286/ 312/32; 811/884 tok/s;   2605 sec;\n",
      "[2024-03-14 13:21:12,633 INFO] Step 7320/11000; acc: 75.6; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  275/ 291/32; 848/897 tok/s;   2612 sec;\n",
      "[2024-03-14 13:21:19,051 INFO] Step 7340/11000; acc: 75.0; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  274/ 289/32; 853/900 tok/s;   2618 sec;\n",
      "[2024-03-14 13:21:26,558 INFO] Step 7360/11000; acc: 75.8; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  283/ 290/32; 755/772 tok/s;   2626 sec;\n",
      "[2024-03-14 13:21:33,718 INFO] Step 7380/11000; acc: 73.4; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  291/ 323/32; 813/903 tok/s;   2633 sec;\n",
      "[2024-03-14 13:21:40,183 INFO] Step 7400/11000; acc: 76.7; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  266/ 285/32; 822/881 tok/s;   2639 sec;\n",
      "[2024-03-14 13:21:45,899 INFO] Step 7420/11000; acc: 78.9; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  250/ 259/32; 873/907 tok/s;   2645 sec;\n",
      "[2024-03-14 13:21:51,927 INFO] Step 7440/11000; acc: 74.6; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  258/ 266/32; 855/882 tok/s;   2651 sec;\n",
      "[2024-03-14 13:22:00,910 INFO] Step 7460/11000; acc: 65.8; ppl:   5.9; xent: 1.8; lr: 1.00000; sents:     640; bsz:  342/ 335/32; 761/745 tok/s;   2660 sec;\n",
      "[2024-03-14 13:22:08,409 INFO] Step 7480/11000; acc: 72.8; ppl:   3.2; xent: 1.1; lr: 1.00000; sents:     640; bsz:  315/ 325/32; 841/866 tok/s;   2667 sec;\n",
      "[2024-03-14 13:22:15,139 INFO] Step 7500/11000; acc: 75.5; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  270/ 291/32; 804/865 tok/s;   2674 sec;\n",
      "[2024-03-14 13:22:21,197 INFO] Step 7520/11000; acc: 77.2; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  258/ 274/32; 851/903 tok/s;   2680 sec;\n",
      "[2024-03-14 13:22:27,570 INFO] Step 7540/11000; acc: 75.2; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  274/ 288/32; 859/904 tok/s;   2687 sec;\n",
      "[2024-03-14 13:22:35,325 INFO] Step 7560/11000; acc: 76.5; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  285/ 310/32; 735/801 tok/s;   2694 sec;\n",
      "[2024-03-14 13:22:41,499 INFO] Step 7580/11000; acc: 77.8; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  248/ 266/32; 803/862 tok/s;   2700 sec;\n",
      "[2024-03-14 13:22:47,930 INFO] Step 7600/11000; acc: 76.1; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  277/ 286/32; 861/891 tok/s;   2707 sec;\n",
      "[2024-03-14 13:22:54,729 INFO] Step 7620/11000; acc: 77.0; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  299/ 302/32; 880/890 tok/s;   2714 sec;\n",
      "[2024-03-14 13:23:02,113 INFO] Step 7640/11000; acc: 74.1; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  307/ 338/32; 832/914 tok/s;   2721 sec;\n",
      "[2024-03-14 13:23:09,782 INFO] Step 7660/11000; acc: 75.3; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  288/ 299/32; 751/780 tok/s;   2729 sec;\n",
      "[2024-03-14 13:23:16,222 INFO] Step 7680/11000; acc: 76.8; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  254/ 285/32; 790/884 tok/s;   2735 sec;\n",
      "[2024-03-14 13:23:22,885 INFO] Step 7700/11000; acc: 77.4; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  277/ 302/32; 831/908 tok/s;   2742 sec;\n",
      "[2024-03-14 13:23:29,394 INFO] Step 7720/11000; acc: 72.5; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  282/ 288/32; 865/885 tok/s;   2748 sec;\n",
      "[2024-03-14 13:23:37,348 INFO] Step 7740/11000; acc: 69.0; ppl:   4.3; xent: 1.5; lr: 1.00000; sents:     640; bsz:  334/ 350/32; 841/879 tok/s;   2756 sec;\n",
      "[2024-03-14 13:23:44,321 INFO] Step 7760/11000; acc: 78.8; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  258/ 269/32; 739/771 tok/s;   2763 sec;\n",
      "[2024-03-14 13:23:50,664 INFO] Step 7780/11000; acc: 77.0; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  259/ 271/32; 817/856 tok/s;   2770 sec;\n",
      "[2024-03-14 13:23:57,448 INFO] Step 7800/11000; acc: 74.2; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  288/ 304/32; 849/896 tok/s;   2776 sec;\n",
      "[2024-03-14 13:24:04,174 INFO] Step 7820/11000; acc: 76.0; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  294/ 296/32; 875/880 tok/s;   2783 sec;\n",
      "[2024-03-14 13:24:11,039 INFO] Step 7840/11000; acc: 74.1; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  280/ 314/32; 816/914 tok/s;   2790 sec;\n",
      "[2024-03-14 13:24:17,719 INFO] Step 7860/11000; acc: 79.2; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  240/ 266/32; 719/795 tok/s;   2797 sec;\n",
      "[2024-03-14 13:24:24,783 INFO] Step 7880/11000; acc: 75.6; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  286/ 304/32; 811/861 tok/s;   2804 sec;\n",
      "[2024-03-14 13:24:31,586 INFO] Step 7900/11000; acc: 78.3; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  278/ 314/32; 818/922 tok/s;   2811 sec;\n",
      "[2024-03-14 13:24:38,095 INFO] Step 7920/11000; acc: 75.0; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  266/ 296/32; 816/910 tok/s;   2817 sec;\n",
      "[2024-03-14 13:24:45,774 INFO] Step 7940/11000; acc: 72.1; ppl:   3.5; xent: 1.3; lr: 1.00000; sents:     640; bsz:  339/ 339/32; 884/884 tok/s;   2825 sec;\n",
      "[2024-03-14 13:24:53,802 INFO] Step 7960/11000; acc: 76.0; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  289/ 307/32; 720/766 tok/s;   2833 sec;\n",
      "[2024-03-14 13:25:00,844 INFO] Step 7980/11000; acc: 72.6; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  294/ 318/32; 836/904 tok/s;   2840 sec;\n",
      "[2024-03-14 13:25:07,545 INFO] Step 8000/11000; acc: 77.4; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  274/ 291/32; 817/869 tok/s;   2847 sec;\n",
      "[2024-03-14 13:25:14,717 INFO] valid stats calculation\n",
      "                           took: 7.171391010284424 s.\n",
      "[2024-03-14 13:25:14,717 INFO] Train perplexity: 10.7376\n",
      "[2024-03-14 13:25:14,717 INFO] Train accuracy: 57.7499\n",
      "[2024-03-14 13:25:14,717 INFO] Sentences processed: 256000\n",
      "[2024-03-14 13:25:14,717 INFO] Average bsz:  282/ 300/32\n",
      "[2024-03-14 13:25:14,717 INFO] Validation perplexity: 5.98824\n",
      "[2024-03-14 13:25:14,717 INFO] Validation accuracy: 69.7265\n",
      "[2024-03-14 13:25:22,096 INFO] Step 8020/11000; acc: 76.8; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  294/ 299/32; 405/411 tok/s;   2861 sec;\n",
      "[2024-03-14 13:25:29,261 INFO] Step 8040/11000; acc: 77.3; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  296/ 304/32; 826/849 tok/s;   2868 sec;\n",
      "[2024-03-14 13:25:36,417 INFO] Step 8060/11000; acc: 73.8; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  301/ 318/32; 841/890 tok/s;   2875 sec;\n",
      "[2024-03-14 13:25:42,342 INFO] Step 8080/11000; acc: 82.7; ppl:   2.0; xent: 0.7; lr: 1.00000; sents:     640; bsz:  246/ 259/32; 833/876 tok/s;   2881 sec;\n",
      "[2024-03-14 13:25:48,695 INFO] Step 8100/11000; acc: 76.0; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  272/ 280/32; 856/882 tok/s;   2888 sec;\n",
      "[2024-03-14 13:25:55,753 INFO] Step 8120/11000; acc: 76.0; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  259/ 290/32; 734/820 tok/s;   2895 sec;\n",
      "[2024-03-14 13:26:01,670 INFO] Step 8140/11000; acc: 80.3; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  213/ 246/32; 719/831 tok/s;   2901 sec;\n",
      "[2024-03-14 13:26:08,242 INFO] Step 8160/11000; acc: 77.5; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  269/ 286/32; 818/872 tok/s;   2907 sec;\n",
      "[2024-03-14 13:26:14,041 INFO] Step 8180/11000; acc: 80.7; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  235/ 267/32; 811/922 tok/s;   2913 sec;\n",
      "[2024-03-14 13:26:19,343 INFO] Step 8200/11000; acc: 82.9; ppl:   2.0; xent: 0.7; lr: 1.00000; sents:     640; bsz:  208/ 243/32; 785/918 tok/s;   2918 sec;\n",
      "[2024-03-14 13:26:25,260 INFO] Step 8220/11000; acc: 81.1; ppl:   2.1; xent: 0.8; lr: 1.00000; sents:     640; bsz:  235/ 261/32; 795/881 tok/s;   2924 sec;\n",
      "[2024-03-14 13:26:32,935 INFO] Step 8240/11000; acc: 75.1; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  285/ 307/32; 742/801 tok/s;   2932 sec;\n",
      "[2024-03-14 13:26:40,102 INFO] Step 8260/11000; acc: 76.6; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  283/ 314/32; 790/878 tok/s;   2939 sec;\n",
      "[2024-03-14 13:26:47,647 INFO] Step 8280/11000; acc: 73.0; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  320/ 336/32; 848/890 tok/s;   2947 sec;\n",
      "[2024-03-14 13:26:54,555 INFO] Step 8300/11000; acc: 76.5; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  285/ 310/32; 825/899 tok/s;   2954 sec;\n",
      "[2024-03-14 13:27:00,323 INFO] Step 8320/11000; acc: 81.4; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  230/ 262/32; 799/910 tok/s;   2959 sec;\n",
      "[2024-03-14 13:27:07,221 INFO] Step 8340/11000; acc: 78.5; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  251/ 263/32; 728/763 tok/s;   2966 sec;\n",
      "[2024-03-14 13:27:14,462 INFO] Step 8360/11000; acc: 75.4; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  315/ 309/32; 871/853 tok/s;   2973 sec;\n",
      "[2024-03-14 13:27:21,191 INFO] Step 8380/11000; acc: 77.6; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  294/ 295/32; 875/878 tok/s;   2980 sec;\n",
      "[2024-03-14 13:27:27,751 INFO] Step 8400/11000; acc: 79.9; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  277/ 298/32; 844/907 tok/s;   2987 sec;\n",
      "[2024-03-14 13:27:34,606 INFO] Step 8420/11000; acc: 78.1; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  286/ 310/32; 836/906 tok/s;   2994 sec;\n",
      "[2024-03-14 13:27:41,673 INFO] Step 8440/11000; acc: 79.1; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  255/ 277/32; 720/784 tok/s;   3001 sec;\n",
      "[2024-03-14 13:27:48,865 INFO] Step 8460/11000; acc: 73.5; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:     640; bsz:  291/ 316/32; 810/879 tok/s;   3008 sec;\n",
      "[2024-03-14 13:27:55,797 INFO] Step 8480/11000; acc: 76.9; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  298/ 302/32; 859/873 tok/s;   3015 sec;\n",
      "[2024-03-14 13:28:02,454 INFO] Step 8500/11000; acc: 78.3; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  262/ 301/32; 788/904 tok/s;   3021 sec;\n",
      "[2024-03-14 13:28:09,002 INFO] Step 8520/11000; acc: 76.2; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  261/ 297/32; 797/906 tok/s;   3028 sec;\n",
      "[2024-03-14 13:28:16,297 INFO] Step 8540/11000; acc: 80.0; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  250/ 296/32; 684/812 tok/s;   3035 sec;\n",
      "[2024-03-14 13:28:22,535 INFO] Step 8560/11000; acc: 79.3; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  259/ 282/32; 831/903 tok/s;   3041 sec;\n",
      "[2024-03-14 13:28:28,683 INFO] Step 8580/11000; acc: 79.1; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  256/ 282/32; 833/916 tok/s;   3048 sec;\n",
      "[2024-03-14 13:28:35,829 INFO] Step 8600/11000; acc: 74.4; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  279/ 317/32; 780/887 tok/s;   3055 sec;\n",
      "[2024-03-14 13:28:41,969 INFO] Step 8620/11000; acc: 78.4; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  256/ 274/32; 834/891 tok/s;   3061 sec;\n",
      "[2024-03-14 13:28:49,078 INFO] Step 8640/11000; acc: 81.5; ppl:   2.1; xent: 0.8; lr: 1.00000; sents:     640; bsz:  259/ 278/32; 729/783 tok/s;   3068 sec;\n",
      "[2024-03-14 13:28:55,722 INFO] Step 8660/11000; acc: 78.9; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  259/ 283/32; 780/851 tok/s;   3075 sec;\n",
      "[2024-03-14 13:29:01,671 INFO] Step 8680/11000; acc: 80.0; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  243/ 264/32; 818/888 tok/s;   3081 sec;\n",
      "[2024-03-14 13:29:08,646 INFO] Step 8700/11000; acc: 78.1; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  290/ 304/32; 830/872 tok/s;   3088 sec;\n",
      "[2024-03-14 13:29:15,594 INFO] Step 8720/11000; acc: 76.9; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  301/ 303/32; 866/873 tok/s;   3095 sec;\n",
      "[2024-03-14 13:29:24,134 INFO] Step 8740/11000; acc: 76.3; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  306/ 336/32; 716/787 tok/s;   3103 sec;\n",
      "[2024-03-14 13:29:30,644 INFO] Step 8760/11000; acc: 78.3; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  258/ 291/32; 791/895 tok/s;   3110 sec;\n",
      "[2024-03-14 13:29:38,402 INFO] Step 8780/11000; acc: 72.2; ppl:   3.6; xent: 1.3; lr: 1.00000; sents:     640; bsz:  318/ 348/32; 821/897 tok/s;   3117 sec;\n",
      "[2024-03-14 13:29:45,608 INFO] Step 8800/11000; acc: 77.4; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  310/ 326/32; 862/906 tok/s;   3125 sec;\n",
      "[2024-03-14 13:29:53,479 INFO] Step 8820/11000; acc: 75.7; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  326/ 315/32; 829/801 tok/s;   3132 sec;\n",
      "[2024-03-14 13:30:00,456 INFO] Step 8840/11000; acc: 77.9; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  277/ 290/32; 793/830 tok/s;   3139 sec;\n",
      "[2024-03-14 13:30:07,439 INFO] Step 8860/11000; acc: 78.0; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  296/ 314/32; 848/898 tok/s;   3146 sec;\n",
      "[2024-03-14 13:30:15,993 INFO] Step 8880/11000; acc: 72.6; ppl:   3.9; xent: 1.4; lr: 1.00000; sents:     618; bsz:  322/ 330/31; 754/773 tok/s;   3155 sec;\n",
      "[2024-03-14 13:30:23,462 INFO] Step 8900/11000; acc: 74.3; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  309/ 332/32; 827/889 tok/s;   3162 sec;\n",
      "[2024-03-14 13:30:32,158 INFO] Step 8920/11000; acc: 71.6; ppl:   3.8; xent: 1.3; lr: 1.00000; sents:     640; bsz:  316/ 328/32; 727/754 tok/s;   3171 sec;\n",
      "[2024-03-14 13:30:38,985 INFO] Step 8940/11000; acc: 75.6; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:     640; bsz:  290/ 296/32; 848/867 tok/s;   3178 sec;\n",
      "[2024-03-14 13:30:45,551 INFO] Step 8960/11000; acc: 80.2; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  283/ 293/32; 863/892 tok/s;   3185 sec;\n",
      "[2024-03-14 13:30:52,613 INFO] Step 8980/11000; acc: 77.1; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  294/ 314/32; 834/888 tok/s;   3192 sec;\n",
      "[2024-03-14 13:31:00,262 INFO] Step 9000/11000; acc: 74.4; ppl:   3.4; xent: 1.2; lr: 1.00000; sents:     640; bsz:  302/ 310/32; 791/812 tok/s;   3199 sec;\n",
      "[2024-03-14 13:31:08,406 INFO] valid stats calculation\n",
      "                           took: 8.143891334533691 s.\n",
      "[2024-03-14 13:31:08,406 INFO] Train perplexity: 9.20253\n",
      "[2024-03-14 13:31:08,406 INFO] Train accuracy: 59.8961\n",
      "[2024-03-14 13:31:08,407 INFO] Sentences processed: 287978\n",
      "[2024-03-14 13:31:08,407 INFO] Average bsz:  281/ 299/32\n",
      "[2024-03-14 13:31:08,407 INFO] Validation perplexity: 6.32434\n",
      "[2024-03-14 13:31:08,407 INFO] Validation accuracy: 71.0478\n",
      "[2024-03-14 13:31:15,476 INFO] Step 9020/11000; acc: 76.1; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  296/ 320/32; 389/420 tok/s;   3214 sec;\n",
      "[2024-03-14 13:31:21,855 INFO] Step 9040/11000; acc: 80.9; ppl:   2.1; xent: 0.8; lr: 1.00000; sents:     640; bsz:  272/ 282/32; 853/883 tok/s;   3221 sec;\n",
      "[2024-03-14 13:31:28,631 INFO] Step 9060/11000; acc: 77.9; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  275/ 309/32; 813/912 tok/s;   3228 sec;\n",
      "[2024-03-14 13:31:36,466 INFO] Step 9080/11000; acc: 77.0; ppl:   2.6; xent: 0.9; lr: 1.00000; sents:     640; bsz:  294/ 293/32; 752/747 tok/s;   3235 sec;\n",
      "[2024-03-14 13:31:43,134 INFO] Step 9100/11000; acc: 80.5; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  274/ 288/32; 821/864 tok/s;   3242 sec;\n",
      "[2024-03-14 13:31:49,372 INFO] Step 9120/11000; acc: 81.0; ppl:   2.1; xent: 0.8; lr: 1.00000; sents:     640; bsz:  267/ 280/32; 857/898 tok/s;   3248 sec;\n",
      "[2024-03-14 13:31:56,260 INFO] Step 9140/11000; acc: 77.2; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  294/ 307/32; 855/892 tok/s;   3255 sec;\n",
      "[2024-03-14 13:32:02,590 INFO] Step 9160/11000; acc: 78.4; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  266/ 283/32; 839/895 tok/s;   3262 sec;\n",
      "[2024-03-14 13:32:11,040 INFO] Step 9180/11000; acc: 75.8; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  307/ 318/32; 727/754 tok/s;   3270 sec;\n",
      "[2024-03-14 13:32:17,791 INFO] Step 9200/11000; acc: 78.5; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  285/ 296/32; 844/877 tok/s;   3277 sec;\n",
      "[2024-03-14 13:32:25,218 INFO] Step 9220/11000; acc: 75.7; ppl:   3.0; xent: 1.1; lr: 1.00000; sents:     640; bsz:  288/ 322/32; 776/868 tok/s;   3284 sec;\n",
      "[2024-03-14 13:32:31,950 INFO] Step 9240/11000; acc: 78.9; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  274/ 312/32; 813/927 tok/s;   3291 sec;\n",
      "[2024-03-14 13:32:38,379 INFO] Step 9260/11000; acc: 77.9; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  274/ 289/32; 851/898 tok/s;   3297 sec;\n",
      "[2024-03-14 13:32:45,869 INFO] Step 9280/11000; acc: 79.1; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  280/ 293/32; 748/782 tok/s;   3305 sec;\n",
      "[2024-03-14 13:32:52,381 INFO] Step 9300/11000; acc: 78.5; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  266/ 282/32; 816/865 tok/s;   3311 sec;\n",
      "[2024-03-14 13:32:59,374 INFO] Step 9320/11000; acc: 78.1; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  304/ 314/32; 869/897 tok/s;   3318 sec;\n",
      "[2024-03-14 13:33:06,184 INFO] Step 9340/11000; acc: 78.9; ppl:   2.3; xent: 0.9; lr: 1.00000; sents:     640; bsz:  294/ 301/32; 865/883 tok/s;   3325 sec;\n",
      "[2024-03-14 13:33:13,260 INFO] Step 9360/11000; acc: 78.1; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  284/ 307/32; 804/867 tok/s;   3332 sec;\n",
      "[2024-03-14 13:33:21,460 INFO] Step 9380/11000; acc: 78.8; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  304/ 328/32; 741/800 tok/s;   3340 sec;\n",
      "[2024-03-14 13:33:28,251 INFO] Step 9400/11000; acc: 76.8; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  278/ 295/32; 818/870 tok/s;   3347 sec;\n",
      "[2024-03-14 13:33:35,064 INFO] Step 9420/11000; acc: 77.3; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  280/ 305/32; 822/897 tok/s;   3354 sec;\n",
      "[2024-03-14 13:33:42,726 INFO] Step 9440/11000; acc: 72.2; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:     640; bsz:  313/ 324/32; 816/847 tok/s;   3362 sec;\n",
      "[2024-03-14 13:33:49,907 INFO] Step 9460/11000; acc: 78.4; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  258/ 295/32; 719/821 tok/s;   3369 sec;\n",
      "[2024-03-14 13:33:57,208 INFO] Step 9480/11000; acc: 80.7; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  283/ 304/32; 776/833 tok/s;   3376 sec;\n",
      "[2024-03-14 13:34:04,079 INFO] Step 9500/11000; acc: 78.6; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  291/ 302/32; 848/880 tok/s;   3383 sec;\n",
      "[2024-03-14 13:34:11,093 INFO] Step 9520/11000; acc: 77.4; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  302/ 314/32; 862/894 tok/s;   3390 sec;\n",
      "[2024-03-14 13:34:18,622 INFO] Step 9540/11000; acc: 75.3; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  334/ 331/32; 888/880 tok/s;   3398 sec;\n",
      "[2024-03-14 13:34:25,423 INFO] Step 9560/11000; acc: 80.8; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  242/ 272/32; 711/799 tok/s;   3404 sec;\n",
      "[2024-03-14 13:34:32,880 INFO] Step 9580/11000; acc: 76.4; ppl:   2.6; xent: 0.9; lr: 1.00000; sents:     640; bsz:  317/ 331/32; 850/888 tok/s;   3412 sec;\n",
      "[2024-03-14 13:34:39,919 INFO] Step 9600/11000; acc: 78.1; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  299/ 325/32; 850/923 tok/s;   3419 sec;\n",
      "[2024-03-14 13:34:46,097 INFO] Step 9620/11000; acc: 78.9; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  255/ 279/32; 824/904 tok/s;   3425 sec;\n",
      "[2024-03-14 13:34:53,141 INFO] Step 9640/11000; acc: 76.4; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  304/ 310/32; 863/880 tok/s;   3432 sec;\n",
      "[2024-03-14 13:35:00,539 INFO] Step 9660/11000; acc: 79.8; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  259/ 290/32; 701/784 tok/s;   3439 sec;\n",
      "[2024-03-14 13:35:07,717 INFO] Step 9680/11000; acc: 80.0; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  298/ 322/32; 829/896 tok/s;   3447 sec;\n",
      "[2024-03-14 13:35:15,428 INFO] Step 9700/11000; acc: 74.7; ppl:   3.1; xent: 1.1; lr: 1.00000; sents:     640; bsz:  333/ 334/32; 865/866 tok/s;   3454 sec;\n",
      "[2024-03-14 13:35:22,109 INFO] Step 9720/11000; acc: 81.7; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  283/ 291/32; 848/872 tok/s;   3461 sec;\n",
      "[2024-03-14 13:35:27,745 INFO] Step 9740/11000; acc: 83.3; ppl:   1.9; xent: 0.6; lr: 1.00000; sents:     640; bsz:  238/ 255/32; 846/905 tok/s;   3467 sec;\n",
      "[2024-03-14 13:35:35,940 INFO] Step 9760/11000; acc: 74.6; ppl:   3.5; xent: 1.3; lr: 1.00000; sents:     640; bsz:  293/ 313/32; 714/763 tok/s;   3475 sec;\n",
      "[2024-03-14 13:35:42,513 INFO] Step 9780/11000; acc: 79.5; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  282/ 288/32; 857/876 tok/s;   3481 sec;\n",
      "[2024-03-14 13:35:49,353 INFO] Step 9800/11000; acc: 79.1; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  277/ 316/32; 809/925 tok/s;   3488 sec;\n",
      "[2024-03-14 13:35:55,839 INFO] Step 9820/11000; acc: 82.0; ppl:   2.0; xent: 0.7; lr: 1.00000; sents:     640; bsz:  270/ 288/32; 834/888 tok/s;   3495 sec;\n",
      "[2024-03-14 13:36:02,332 INFO] Step 9840/11000; acc: 81.9; ppl:   2.0; xent: 0.7; lr: 1.00000; sents:     640; bsz:  270/ 296/32; 833/912 tok/s;   3501 sec;\n",
      "[2024-03-14 13:36:10,149 INFO] Step 9860/11000; acc: 79.0; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  288/ 302/32; 737/774 tok/s;   3509 sec;\n",
      "[2024-03-14 13:36:16,899 INFO] Step 9880/11000; acc: 80.5; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  275/ 301/32; 815/891 tok/s;   3516 sec;\n",
      "[2024-03-14 13:36:23,202 INFO] Step 9900/11000; acc: 80.5; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  270/ 280/32; 858/887 tok/s;   3522 sec;\n",
      "[2024-03-14 13:36:28,981 INFO] Step 9920/11000; acc: 83.2; ppl:   1.9; xent: 0.6; lr: 1.00000; sents:     640; bsz:  230/ 268/32; 797/927 tok/s;   3528 sec;\n",
      "[2024-03-14 13:36:36,191 INFO] Step 9940/11000; acc: 77.8; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  310/ 325/32; 861/901 tok/s;   3535 sec;\n",
      "[2024-03-14 13:36:43,342 INFO] Step 9960/11000; acc: 80.5; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  254/ 279/32; 712/779 tok/s;   3542 sec;\n",
      "[2024-03-14 13:36:50,713 INFO] Step 9980/11000; acc: 77.3; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  326/ 325/32; 886/881 tok/s;   3550 sec;\n",
      "[2024-03-14 13:36:56,902 INFO] Step 10000/11000; acc: 81.5; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  259/ 278/32; 838/900 tok/s;   3556 sec;\n",
      "[2024-03-14 13:37:04,537 INFO] valid stats calculation\n",
      "                           took: 7.634978294372559 s.\n",
      "[2024-03-14 13:37:04,543 INFO] Train perplexity: 8.05479\n",
      "[2024-03-14 13:37:04,543 INFO] Train accuracy: 61.7693\n",
      "[2024-03-14 13:37:04,543 INFO] Sentences processed: 319978\n",
      "[2024-03-14 13:37:04,543 INFO] Average bsz:  281/ 300/32\n",
      "[2024-03-14 13:37:04,543 INFO] Validation perplexity: 6.4328\n",
      "[2024-03-14 13:37:04,543 INFO] Validation accuracy: 70.9318\n",
      "[2024-03-14 13:37:11,148 INFO] Step 10020/11000; acc: 78.3; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:     640; bsz:  275/ 295/32; 386/415 tok/s;   3570 sec;\n",
      "[2024-03-14 13:37:19,455 INFO] Step 10040/11000; acc: 75.9; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:     640; bsz:  320/ 311/32; 770/748 tok/s;   3578 sec;\n",
      "[2024-03-14 13:37:27,083 INFO] Step 10060/11000; acc: 76.9; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  334/ 331/32; 877/868 tok/s;   3586 sec;\n",
      "[2024-03-14 13:37:33,396 INFO] Step 10080/11000; acc: 81.0; ppl:   2.1; xent: 0.8; lr: 1.00000; sents:     640; bsz:  262/ 288/32; 831/913 tok/s;   3592 sec;\n",
      "[2024-03-14 13:37:39,678 INFO] Step 10100/11000; acc: 79.7; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  250/ 287/32; 795/913 tok/s;   3599 sec;\n",
      "[2024-03-14 13:37:46,394 INFO] Step 10120/11000; acc: 79.0; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  259/ 290/32; 772/862 tok/s;   3605 sec;\n",
      "[2024-03-14 13:37:54,138 INFO] Step 10140/11000; acc: 78.2; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  299/ 312/32; 773/806 tok/s;   3613 sec;\n",
      "[2024-03-14 13:38:00,784 INFO] Step 10160/11000; acc: 80.1; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  270/ 301/32; 814/907 tok/s;   3620 sec;\n",
      "[2024-03-14 13:38:07,804 INFO] Step 10180/11000; acc: 79.2; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  302/ 322/32; 862/916 tok/s;   3627 sec;\n",
      "[2024-03-14 13:38:14,759 INFO] Step 10200/11000; acc: 81.0; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  288/ 316/32; 828/907 tok/s;   3634 sec;\n",
      "[2024-03-14 13:38:21,187 INFO] Step 10220/11000; acc: 82.8; ppl:   1.9; xent: 0.6; lr: 1.00000; sents:     640; bsz:  250/ 280/32; 777/871 tok/s;   3640 sec;\n",
      "[2024-03-14 13:38:28,145 INFO] Step 10240/11000; acc: 79.3; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  264/ 284/32; 759/817 tok/s;   3647 sec;\n",
      "[2024-03-14 13:38:35,163 INFO] Step 10260/11000; acc: 78.4; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  296/ 301/32; 844/857 tok/s;   3654 sec;\n",
      "[2024-03-14 13:38:41,479 INFO] Step 10280/11000; acc: 80.1; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  269/ 280/32; 851/887 tok/s;   3660 sec;\n",
      "[2024-03-14 13:38:47,963 INFO] Step 10300/11000; acc: 82.7; ppl:   2.0; xent: 0.7; lr: 1.00000; sents:     640; bsz:  280/ 288/32; 864/888 tok/s;   3667 sec;\n",
      "[2024-03-14 13:38:55,153 INFO] Step 10320/11000; acc: 78.3; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  286/ 312/32; 797/868 tok/s;   3674 sec;\n",
      "[2024-03-14 13:39:03,453 INFO] Step 10340/11000; acc: 74.1; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  315/ 347/32; 760/836 tok/s;   3682 sec;\n",
      "[2024-03-14 13:39:09,626 INFO] Step 10360/11000; acc: 81.2; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  259/ 283/32; 840/918 tok/s;   3689 sec;\n",
      "[2024-03-14 13:39:16,128 INFO] Step 10380/11000; acc: 80.6; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  275/ 294/32; 847/906 tok/s;   3695 sec;\n",
      "[2024-03-14 13:39:22,913 INFO] Step 10400/11000; acc: 80.7; ppl:   2.1; xent: 0.8; lr: 1.00000; sents:     640; bsz:  291/ 306/32; 858/901 tok/s;   3702 sec;\n",
      "[2024-03-14 13:39:30,934 INFO] Step 10420/11000; acc: 79.4; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  294/ 325/32; 734/810 tok/s;   3710 sec;\n",
      "[2024-03-14 13:39:37,995 INFO] Step 10440/11000; acc: 77.7; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  293/ 313/32; 829/886 tok/s;   3717 sec;\n",
      "[2024-03-14 13:39:45,285 INFO] Step 10460/11000; acc: 76.8; ppl:   2.6; xent: 1.0; lr: 1.00000; sents:     640; bsz:  307/ 328/32; 843/900 tok/s;   3724 sec;\n",
      "[2024-03-14 13:39:51,825 INFO] Step 10480/11000; acc: 80.2; ppl:   2.1; xent: 0.8; lr: 1.00000; sents:     640; bsz:  285/ 288/32; 871/881 tok/s;   3731 sec;\n",
      "[2024-03-14 13:39:57,907 INFO] Step 10500/11000; acc: 83.1; ppl:   1.9; xent: 0.6; lr: 1.00000; sents:     640; bsz:  250/ 280/32; 821/921 tok/s;   3737 sec;\n",
      "[2024-03-14 13:40:05,335 INFO] Step 10520/11000; acc: 80.2; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  262/ 294/32; 707/793 tok/s;   3744 sec;\n",
      "[2024-03-14 13:40:11,765 INFO] Step 10540/11000; acc: 82.2; ppl:   2.0; xent: 0.7; lr: 1.00000; sents:     640; bsz:  280/ 280/32; 871/871 tok/s;   3751 sec;\n",
      "[2024-03-14 13:40:17,888 INFO] Step 10560/11000; acc: 81.8; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  254/ 278/32; 831/909 tok/s;   3757 sec;\n",
      "[2024-03-14 13:40:24,467 INFO] Step 10580/11000; acc: 77.8; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  277/ 290/32; 842/882 tok/s;   3763 sec;\n",
      "[2024-03-14 13:40:31,399 INFO] Step 10600/11000; acc: 78.6; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  306/ 304/32; 882/877 tok/s;   3770 sec;\n",
      "[2024-03-14 13:40:38,730 INFO] Step 10620/11000; acc: 81.1; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  283/ 285/32; 773/777 tok/s;   3778 sec;\n",
      "[2024-03-14 13:40:45,576 INFO] Step 10640/11000; acc: 75.7; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:     640; bsz:  261/ 293/32; 762/855 tok/s;   3785 sec;\n",
      "[2024-03-14 13:40:52,035 INFO] Step 10660/11000; acc: 80.4; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  261/ 290/32; 808/897 tok/s;   3791 sec;\n",
      "[2024-03-14 13:40:59,194 INFO] Step 10680/11000; acc: 81.3; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  301/ 320/32; 840/894 tok/s;   3798 sec;\n",
      "[2024-03-14 13:41:05,419 INFO] Step 10700/11000; acc: 84.6; ppl:   1.8; xent: 0.6; lr: 1.00000; sents:     640; bsz:  267/ 275/32; 859/884 tok/s;   3804 sec;\n",
      "[2024-03-14 13:41:12,757 INFO] Step 10720/11000; acc: 79.3; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  285/ 307/32; 776/837 tok/s;   3812 sec;\n",
      "[2024-03-14 13:41:19,699 INFO] Step 10740/11000; acc: 80.4; ppl:   2.1; xent: 0.8; lr: 1.00000; sents:     640; bsz:  266/ 298/32; 765/858 tok/s;   3819 sec;\n",
      "[2024-03-14 13:41:26,067 INFO] Step 10760/11000; acc: 81.4; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  261/ 283/32; 819/889 tok/s;   3825 sec;\n",
      "[2024-03-14 13:41:33,272 INFO] Step 10780/11000; acc: 79.2; ppl:   2.3; xent: 0.8; lr: 1.00000; sents:     640; bsz:  288/ 326/32; 799/905 tok/s;   3832 sec;\n",
      "[2024-03-14 13:41:39,981 INFO] Step 10800/11000; acc: 81.6; ppl:   2.0; xent: 0.7; lr: 1.00000; sents:     640; bsz:  275/ 304/32; 820/906 tok/s;   3839 sec;\n",
      "[2024-03-14 13:41:46,816 INFO] Step 10820/11000; acc: 79.5; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  253/ 290/32; 740/847 tok/s;   3846 sec;\n",
      "[2024-03-14 13:41:53,254 INFO] Step 10840/11000; acc: 84.1; ppl:   1.8; xent: 0.6; lr: 1.00000; sents:     640; bsz:  256/ 269/32; 795/835 tok/s;   3852 sec;\n",
      "[2024-03-14 13:41:59,977 INFO] Step 10860/11000; acc: 81.2; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  283/ 298/32; 842/885 tok/s;   3859 sec;\n",
      "[2024-03-14 13:42:06,558 INFO] Step 10880/11000; acc: 80.8; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:     640; bsz:  282/ 286/32; 856/870 tok/s;   3866 sec;\n",
      "[2024-03-14 13:42:13,266 INFO] Step 10900/11000; acc: 77.2; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:     640; bsz:  288/ 304/32; 859/907 tok/s;   3872 sec;\n",
      "[2024-03-14 13:42:20,328 INFO] Step 10920/11000; acc: 81.4; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  270/ 306/32; 766/865 tok/s;   3879 sec;\n",
      "[2024-03-14 13:42:27,604 INFO] Step 10940/11000; acc: 82.0; ppl:   2.0; xent: 0.7; lr: 1.00000; sents:     640; bsz:  283/ 302/32; 779/831 tok/s;   3887 sec;\n",
      "[2024-03-14 13:42:34,453 INFO] Step 10960/11000; acc: 81.5; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  280/ 301/32; 818/878 tok/s;   3893 sec;\n",
      "[2024-03-14 13:42:41,178 INFO] Step 10980/11000; acc: 78.8; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:     640; bsz:  288/ 306/32; 857/909 tok/s;   3900 sec;\n",
      "[2024-03-14 13:42:48,168 INFO] Step 11000/11000; acc: 81.2; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:     640; bsz:  307/ 312/32; 879/893 tok/s;   3907 sec;\n",
      "[2024-03-14 13:42:56,236 INFO] valid stats calculation\n",
      "                           took: 8.066473007202148 s.\n",
      "[2024-03-14 13:42:56,241 INFO] Train perplexity: 7.17806\n",
      "[2024-03-14 13:42:56,241 INFO] Train accuracy: 63.4142\n",
      "[2024-03-14 13:42:56,241 INFO] Sentences processed: 351978\n",
      "[2024-03-14 13:42:56,241 INFO] Average bsz:  281/ 300/32\n",
      "[2024-03-14 13:42:56,241 INFO] Validation perplexity: 6.50143\n",
      "[2024-03-14 13:42:56,241 INFO] Validation accuracy: 71.3491\n",
      "[2024-03-14 13:42:56,247 INFO] Saving checkpoint ./models/futur/model_step_11000.pt\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config ./configs/config-best.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-14 14:00:22,013 INFO] Loading checkpoint from ./models/futur/model_step_11000.pt\n",
      "[2024-03-14 14:00:22,388 INFO] Loading data into the model\n",
      "[2024-03-14 14:00:26,759 INFO] PRED SCORE: -0.2282, PRED PPL: 1.26 NB SENTENCES: 469\n",
      "Time w/o python interpreter load/terminate:  4.753257751464844\n",
      "BLEU = 39.21, 68.6/45.8/33.9/24.2 (BP=0.978, ratio=0.978, hyp_len=3497, ref_len=3574)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!onmt_translate -model ./models/futur/model_step_11000.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.tok.txt -output ./BTEC-en-fr/predictions/pred_11000.txt\n",
    "!perl multi-bleu.perl BTEC-en-fr/test/IWSLT09_BTEC.testset.en.tok.txt < BTEC-en-fr/predictions/pred_11000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 17**: Le meilleur score bleu est obtenu pour le modèle à 11000 pas avec les optimisations qu'on a vu ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 18**: On a l'impression que le modèle s'améliore:  \n",
    "Phrase à traduire: Pouvez-vous conduire plus lentement, s'il vous plaît?    \n",
    "Phrase du modèle à 2000 pas: Could you call me , please ?  \n",
    "Phrase du modèle à 6000 pas: Could you speak more slowly , please ? \n",
    "Phrase à traduire: Avez-vous un menu?      \n",
    "Phrase du modèle à 2000 pas: Do you have a room ?  \n",
    "Phrase du modèle à 6000 pas: Do you have a menu ?  \n",
    "Phrase à traduire: Toutes les dix minutes.    \n",
    "Phrase du modèle à 2000 pas: Let &apos;s check in Japan .  \n",
    "Phrase du modèle à 6000 pas: Every ten minutes ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
