{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfM_XbFlVnpO"
      },
      "source": [
        "# Hidden Markov Models for Sequence Tagging\n",
        "\n",
        "The aim of this lab session is to develop an HMM sequence tagger and evaluate it on classical sequence tagging\n",
        "tasks, such as **part-of-speech (POS) tagging** or **Name Entity Recognition**.\n",
        "Sequence tagging is a structured prediction problem consisting in assigning a sequence of $n$ tags $c = c_1,c_2,...,c_n$\n",
        "to an input sequence of the same length $w = w_1,w_2,...,w_n$.\n",
        "For exemple, in POS tagging, the French sentence `\"Le chat mange une pomme .\"` should be assigned the POS sequence: `\"D N V D N PONCT\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OswQOEHGMWX"
      },
      "source": [
        "**Note** : The whole implementation should be carried out without importing additional libraries (numpy, collections and datasets are allowed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltTCx-2DV0yF",
        "outputId": "9fa1139f-a544-45e1-adaf-4206771e1433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FcvHAzt2VtWx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1bQRuHqOT-J"
      },
      "source": [
        "## HiddenMarkovModel initial implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnhLVc12GkDP"
      },
      "source": [
        "Implement the `train` function in the `hiddenMarkovModel` class. This function must estimate the parameters of the HMM model from a corpus. The `test_estimation` function will test estimation on the 2 sentences in Section 2:\n",
        "  - `le/D chat/N ferme/V la/D porte/N`\n",
        "  - `le/D chien/N le/CL porte/N`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "OzzAbFauV7aA"
      },
      "outputs": [],
      "source": [
        "class HiddenMarkovModel():\n",
        "    \"\"\"\n",
        "    Sequence tagging model: Hidden Markov model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) :\n",
        "\n",
        "        # log probabilities of transitions P( tag_i | tag_i-1.)\n",
        "        # for example, self.transitions[\"NOUN\"][\"DET\"] should contain log P(DET | NOUN)\n",
        "        #              self.transitions[START][\"DET\"] should contain log P(DET | début de phrase)\n",
        "        #              self.transitions[\"V\"][END] should contain log  P(fin de phrase | \"V\")\n",
        "        self.transitions            = defaultdict(lambda : defaultdict(float))\n",
        "\n",
        "        # log probabilities of emissions: P( word | tag )\n",
        "        # For example, self.emissions[\"NOUN\"][\"chat\"] should contain log P(chat | NOUN)\n",
        "        self.emissions              = defaultdict(lambda : defaultdict(float))\n",
        "\n",
        "        self.tags = []              # list of unique possible tags (without END and START)\n",
        "        self.voc = {UNKNOWN}        # vocabulary\n",
        "    def train(self, minicorpusn, precision):\n",
        "      pass\n",
        "\n",
        "\n",
        "\n",
        "    def print_parameters(self, exp = np.exp) :\n",
        "        \"\"\"\n",
        "        Print all parameters of the model\n",
        "        \"\"\"\n",
        "        print(\"Transitions\")\n",
        "        for k1 in sorted(self.transitions) :\n",
        "            for k2 in sorted(self.transitions[k1]) :\n",
        "                v = self.transitions[k1][k2]\n",
        "                print(f\"P({k2}|{k1}) = {round(exp(v),5)}\\t\\t(log p = {round(v, 5)})\")\n",
        "\n",
        "        print(\"Emissions\")\n",
        "        for t in sorted(self.emissions) :\n",
        "            for w,v in sorted(self.emissions[t].items()) :\n",
        "                print(f\"P({w}|{t}) = {round(exp(v),5)}\\t\\t(log p = {round(v,5)})\")\n",
        "\n",
        "    def predict(self, sentence):\n",
        "        \"\"\"\n",
        "        Predict a sequence of tags for the input sentence (list of tokens)\n",
        "        \"\"\"\n",
        "        emissions_scores = [ {tag : self.emissions[tag][word] if word in self.emissions[tag] else self.emissions[tag][UNKNOWN] for tag in self.tags } for word in sentence ]\n",
        "        y = self.viterbi(self.transitions, emissions_scores)\n",
        "        return y\n",
        "\n",
        "    def predict_corpus(self, list_of_sentences):\n",
        "        \"\"\"\n",
        "        Perform  predictions for a list_of_sentences\n",
        "        \"\"\"\n",
        "        return [self.predict(sentence) for sentence in list_of_sentences]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "b20rzmCDMm-u"
      },
      "outputs": [],
      "source": [
        "def test_estimation():\n",
        "    minicorpus=[(\"le chat ferme la porte\", \"D N V D N\"),(\"le chien le porte\",\"D N CL V\")]\n",
        "    for i in range(len(minicorpus)) :\n",
        "        minicorpus[i] = {\"tokens\": minicorpus[i][0].split(), \"upos\": minicorpus[i][1].split()}\n",
        "    # print(minicorpus)\n",
        "\n",
        "    hmm = HiddenMarkovModel()\n",
        "    hmm.train(minicorpus, 1e-8)\n",
        "\n",
        "    hmm.print_parameters()\n",
        "\n",
        "    print()\n",
        "    print(\"Expected results\")\n",
        "    print('Transitions\\nP(</S>|<S>) = 0.0\t\t(log p = -18.42068)\\nP(CL|<S>) = 0.0\t\t(log p = -18.42068)\\nP(D|<S>) = 1.0\t\t(log p = 0.0)\\nP(N|<S>) = 0.0\t\t(log p = -18.42068)\\nP(V|<S>) = 0.0\t\t(log p = -18.42068)\\nP(</S>|CL) = 0.0\t\t(log p = -18.42068)\\nP(CL|CL) = 0.0\t\t(log p = -18.42068)\\nP(D|CL) = 0.0\t\t(log p = -18.42068)\\nP(N|CL) = 0.0\t\t(log p = -18.42068)\\nP(V|CL) = 1.0\t\t(log p = 0.0)\\nP(</S>|D) = 0.0\t\t(log p = -18.42068)\\nP(CL|D) = 0.0\t\t(log p = -18.42068)\\nP(D|D) = 0.0\t\t(log p = -18.42068)\\nP(N|D) = 1.0\t\t(log p = 0.0)\\nP(V|D) = 0.0\t\t(log p = -18.42068)\\nP(</S>|N) = 0.33333\t\t(log p = -1.09861)\\nP(CL|N) = 0.33333\t\t(log p = -1.09861)\\nP(D|N) = 0.0\t\t(log p = -18.42068)\\nP(N|N) = 0.0\t\t(log p = -18.42068)\\nP(V|N) = 0.33333\t\t(log p = -1.09861)\\nP(</S>|V) = 0.5\t\t(log p = -0.69315)\\nP(CL|V) = 0.0\t\t(log p = -18.42068)\\nP(D|V) = 0.5\t\t(log p = -0.69315)\\nP(N|V) = 0.0\t\t(log p = -18.42068)\\nP(V|V) = 0.0\t\t(log p = -18.42068)\\nEmissions\\nP(<UNK>|CL) = 0.0\t\t(log p = -18.42068)\\nP(chat|CL) = 0.0\t\t(log p = -18.42068)\\nP(chien|CL) = 0.0\t\t(log p = -18.42068)\\nP(ferme|CL) = 0.0\t\t(log p = -18.42068)\\nP(la|CL) = 0.0\t\t(log p = -18.42068)\\nP(le|CL) = 1.0\t\t(log p = 0.0)\\nP(porte|CL) = 0.0\t\t(log p = -18.42068)\\nP(<UNK>|D) = 0.0\t\t(log p = -18.42068)\\nP(chat|D) = 0.0\t\t(log p = -18.42068)\\nP(chien|D) = 0.0\t\t(log p = -18.42068)\\nP(ferme|D) = 0.0\t\t(log p = -18.42068)\\nP(la|D) = 0.33333\t\t(log p = -1.09861)\\nP(le|D) = 0.66667\t\t(log p = -0.40547)\\nP(porte|D) = 0.0\t\t(log p = -18.42068)\\nP(<UNK>|N) = 0.0\t\t(log p = -18.42068)\\nP(chat|N) = 0.33333\t\t(log p = -1.09861)\\nP(chien|N) = 0.33333\t\t(log p = -1.09861)\\nP(ferme|N) = 0.0\t\t(log p = -18.42068)\\nP(la|N) = 0.0\t\t(log p = -18.42068)\\nP(le|N) = 0.0\t\t(log p = -18.42068)\\nP(porte|N) = 0.33333\t\t(log p = -1.09861)\\nP(<UNK>|V) = 0.0\t\t(log p = -18.42068)\\nP(chat|V) = 0.0\t\t(log p = -18.42068)\\nP(chien|V) = 0.0\t\t(log p = -18.42068)\\nP(ferme|V) = 0.5\t\t(log p = -0.69315)\\nP(la|V) = 0.0\t\t(log p = -18.42068)\\nP(le|V) = 0.0\t\t(log p = -18.42068)\\nP(porte|V) = 0.5\t\t(log p = -0.69315)\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN_7FwotMQrJ",
        "outputId": "f10193b7-6a31-4960-f479-9a3c3e4d4330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transitions\n",
            "Emissions\n",
            "\n",
            "Expected results\n",
            "Transitions\n",
            "P(</S>|<S>) = 0.0\t\t(log p = -18.42068)\n",
            "P(CL|<S>) = 0.0\t\t(log p = -18.42068)\n",
            "P(D|<S>) = 1.0\t\t(log p = 0.0)\n",
            "P(N|<S>) = 0.0\t\t(log p = -18.42068)\n",
            "P(V|<S>) = 0.0\t\t(log p = -18.42068)\n",
            "P(</S>|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(CL|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(D|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(N|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(V|CL) = 1.0\t\t(log p = 0.0)\n",
            "P(</S>|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(CL|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(D|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(N|D) = 1.0\t\t(log p = 0.0)\n",
            "P(V|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(</S>|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(CL|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(D|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(N|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(V|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(</S>|V) = 0.5\t\t(log p = -0.69315)\n",
            "P(CL|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(D|V) = 0.5\t\t(log p = -0.69315)\n",
            "P(N|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(V|V) = 0.0\t\t(log p = -18.42068)\n",
            "Emissions\n",
            "P(<UNK>|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(chat|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(chien|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(ferme|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(la|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(le|CL) = 1.0\t\t(log p = 0.0)\n",
            "P(porte|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(<UNK>|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(chat|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(chien|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(ferme|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(la|D) = 0.33333\t\t(log p = -1.09861)\n",
            "P(le|D) = 0.66667\t\t(log p = -0.40547)\n",
            "P(porte|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(<UNK>|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(chat|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(chien|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(ferme|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(la|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(le|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(porte|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(<UNK>|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(chat|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(chien|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(ferme|V) = 0.5\t\t(log p = -0.69315)\n",
            "P(la|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(le|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(porte|V) = 0.5\t\t(log p = -0.69315)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Expected Results:\n",
        "\n",
        "START=\"<S>\"     # Start of sentence\n",
        "END=\"</S>\"      # End of sentence\n",
        "UNKNOWN=\"<UNK>\" # Unkown word s\n",
        "\n",
        "test_estimation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLH7pfvyOmxy"
      },
      "source": [
        "**Let's define the training function for the HiddenMarkovModel class:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVzx_m7cNMvY",
        "outputId": "14aed02b-d000-4105-a3e0-7b6f76529a46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transitions\n",
            "P(D|<S>) = 1.0\t\t(log p = 0.0)\n",
            "P(V|CL) = 1.0\t\t(log p = 0.0)\n",
            "P(N|D) = 1.0\t\t(log p = 0.0)\n",
            "P(</S>|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(CL|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(V|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(</S>|V) = 0.5\t\t(log p = -0.69315)\n",
            "P(D|V) = 0.5\t\t(log p = -0.69315)\n",
            "Emissions\n",
            "P(le|CL) = 1.0\t\t(log p = 0.0)\n",
            "P(la|D) = 0.33333\t\t(log p = -1.09861)\n",
            "P(le|D) = 0.66667\t\t(log p = -0.40547)\n",
            "P(chat|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(chien|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(porte|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(ferme|V) = 0.5\t\t(log p = -0.69315)\n",
            "P(porte|V) = 0.5\t\t(log p = -0.69315)\n",
            "\n",
            "Expected results\n",
            "Transitions\n",
            "P(</S>|<S>) = 0.0\t\t(log p = -18.42068)\n",
            "P(CL|<S>) = 0.0\t\t(log p = -18.42068)\n",
            "P(D|<S>) = 1.0\t\t(log p = 0.0)\n",
            "P(N|<S>) = 0.0\t\t(log p = -18.42068)\n",
            "P(V|<S>) = 0.0\t\t(log p = -18.42068)\n",
            "P(</S>|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(CL|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(D|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(N|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(V|CL) = 1.0\t\t(log p = 0.0)\n",
            "P(</S>|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(CL|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(D|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(N|D) = 1.0\t\t(log p = 0.0)\n",
            "P(V|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(</S>|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(CL|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(D|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(N|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(V|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(</S>|V) = 0.5\t\t(log p = -0.69315)\n",
            "P(CL|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(D|V) = 0.5\t\t(log p = -0.69315)\n",
            "P(N|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(V|V) = 0.0\t\t(log p = -18.42068)\n",
            "Emissions\n",
            "P(<UNK>|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(chat|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(chien|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(ferme|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(la|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(le|CL) = 1.0\t\t(log p = 0.0)\n",
            "P(porte|CL) = 0.0\t\t(log p = -18.42068)\n",
            "P(<UNK>|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(chat|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(chien|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(ferme|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(la|D) = 0.33333\t\t(log p = -1.09861)\n",
            "P(le|D) = 0.66667\t\t(log p = -0.40547)\n",
            "P(porte|D) = 0.0\t\t(log p = -18.42068)\n",
            "P(<UNK>|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(chat|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(chien|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(ferme|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(la|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(le|N) = 0.0\t\t(log p = -18.42068)\n",
            "P(porte|N) = 0.33333\t\t(log p = -1.09861)\n",
            "P(<UNK>|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(chat|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(chien|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(ferme|V) = 0.5\t\t(log p = -0.69315)\n",
            "P(la|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(le|V) = 0.0\t\t(log p = -18.42068)\n",
            "P(porte|V) = 0.5\t\t(log p = -0.69315)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def hmm_train(self, train_data, smooth=1e-8) :\n",
        "    \"\"\"\n",
        "    Parameter (transitions and emissions) estimation from a train corpus\n",
        "\n",
        "\n",
        "    parameters:\n",
        "        train_data : Dataset object with fields: \"tokens\" and \"upos\"\n",
        "        smooth : value for probability smoothing\n",
        "\n",
        "    \"\"\"\n",
        "    self.voc = {}\n",
        "    self.tags = {}\n",
        "    card = defaultdict(float) # store the number of occurences of each upos\n",
        "\n",
        "    # count the number of transitions and emissions by looping through each (token,upos)\n",
        "    for corpus in train_data:\n",
        "        last = START\n",
        "        card[START] += 1\n",
        "        for token, upos in zip(corpus[\"tokens\"], corpus[\"upos\"]):\n",
        "            self.transitions[last][upos] += 1\n",
        "            self.emissions[upos][token] += 1\n",
        "            last = upos\n",
        "            card[upos] += 1\n",
        "        self.transitions[last][END] += 1\n",
        "        card[END] += 1\n",
        "\n",
        "    # divide by the number of occurences and take log\n",
        "\n",
        "    for key,item in self.transitions.items():\n",
        "        for upos, val in item.items():\n",
        "            item[upos] = np.log(val/card[key])\n",
        "\n",
        "    for upos,tokens in self.emissions.items():\n",
        "        for token, val in tokens.items():\n",
        "            tokens[token] = np.log(val/card[upos])\n",
        "\n",
        "\n",
        "    # TODO: implement this function\n",
        "    # update self.transitions, self.emissions, self.tags and self.voc instance variables\n",
        "    # log probabilities of transitions P( tag_i | tag_i-1.)\n",
        "        # for example, self.transitions[\"NOUN\"][\"DET\"] should contain log P(DET | NOUN)\n",
        "        #              self.transitions[START][\"DET\"] should contain log P(DET | début de phrase)\n",
        "        #              self.transitions[\"V\"][END] should contain log  P(fin de phrase | \"V\")\n",
        "    # log probabilities of emissions: P( word | tag )\n",
        "        # For example, self.emissions[\"NOUN\"][\"chat\"] should contain log P(chat | NOUN)\n",
        "    # - don't forget to smooth probabilities\n",
        "    # - don't forget to switch to log space at the end of the function\n",
        "\n",
        "    pass\n",
        "\n",
        "HiddenMarkovModel.train = hmm_train\n",
        "\n",
        "test_estimation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDkwzMAVWl7r"
      },
      "source": [
        "## BaselineTagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4NSEsyR2QG"
      },
      "source": [
        "Implement a baseline tagger that uses the most-frequent class strategy:\n",
        "- For a known word: assign the most frequent tag for this word. For example, if ferme is tagged 5 time `VERB` and twice `NOUN` in the training corpus, tag all occurrences of ferme (in the test corpus) as `VERB`.\n",
        "- For an unknown word: assign the most frequent tag overall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rzm5aTDDQCrn"
      },
      "outputs": [],
      "source": [
        "class BaselineTagger() :\n",
        "    \"\"\"\n",
        "    Baseline tagger\n",
        "    \"\"\"\n",
        "\n",
        "    #### TODO:\n",
        "    # implement the methods: __init__, train and predict of this class\n",
        "\n",
        "    def __init__(self) :\n",
        "\n",
        "        self.frequency = defaultdict(float)\n",
        "        self.classification = defaultdict(float)\n",
        "\n",
        "\n",
        "        self.tags = set()           # list of unique possible tags (without END and START)\n",
        "        self.voc = set()\n",
        "        self.max_tag_glob = ''\n",
        "        self.max_tag_freq = 0.0\n",
        "\n",
        "\n",
        "    def train(self, sentences_lst) :\n",
        "\n",
        "        for sentence in sentences_lst:\n",
        "            mapper = ['NOUN', 'PUNCT', 'ADP', 'NUM', 'SYM', 'SCONJ', 'ADJ', 'PART', 'DET', 'CCONJ', 'PROPN', 'PRON', 'X', '_', 'ADV', 'INTJ', 'VERB', 'AUX']\n",
        "            tags = [mapper[tag_id] for tag_id in sentence[\"upos\"]]\n",
        "            for i in range(len(sentence['tokens'])):\n",
        "                self.tags.add(tags[i])\n",
        "                self.voc.add(sentence['tokens'][i])\n",
        "\n",
        "\n",
        "\n",
        "        for sentence in sentences_lst:\n",
        "            mapper = ['NOUN', 'PUNCT', 'ADP', 'NUM', 'SYM', 'SCONJ', 'ADJ', 'PART', 'DET', 'CCONJ', 'PROPN', 'PRON', 'X', '_', 'ADV', 'INTJ', 'VERB', 'AUX']\n",
        "            tags = [mapper[tag_id] for tag_id in sentence[\"upos\"]]\n",
        "            for i in range(len(sentence['tokens'])):\n",
        "\n",
        "\n",
        "              # tags = map_id_to_UPOS(sentence['tokens'])\n",
        "              assign = sentence['tokens'][i] +'|' + tags[i]\n",
        "              self.frequency[assign] = 1 + self.frequency[assign]\n",
        "        for word in self.voc:\n",
        "            max_freq = 0.0\n",
        "            max_tag = ''\n",
        "            for tag in self.tags:\n",
        "                if self.frequency[word + '|' + tag] > max_freq:\n",
        "                  max_freq = self.frequency[word + '|' + tag]\n",
        "                  max_tag = tag\n",
        "                if self.frequency[word + '|' + tag] > self.max_tag_freq:\n",
        "                  self.max_tag_freq = self.frequency[word + '|' + tag]\n",
        "                  self.max_tag_glob = tag\n",
        "\n",
        "            self.classification[word] = max_tag\n",
        "\n",
        "\n",
        "    def predict(self, sentence) :\n",
        "        pred = []\n",
        "        for token in sentence:\n",
        "            if self.classification[token] != 0:\n",
        "                pred.append(self.classification[token])\n",
        "            else :\n",
        "                pred.append(self.max_tag_glob)\n",
        "        return pred\n",
        "\n",
        "    def predict_corpus(self, list_of_sentences):\n",
        "        \"\"\"\n",
        "        Perform  predictions for a list_of_sentences\n",
        "        \"\"\"\n",
        "        return [self.predict(sentence) for sentence in list_of_sentences]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kUTt1V1oTFHW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpqXRLCzTtP-"
      },
      "source": [
        "**Testing the BaselineTagger**\n",
        "1. load the dataset `\"universal_dependencies\", \"fr_gsd\"`\n",
        "2. implement the accuracy function\n",
        "3. run the `test_baseline` code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udDkEKfAOjMS",
        "outputId": "c3b7dd00-eea3-4806-b39c-79fbaf3d0ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: conllu in /usr/local/lib/python3.10/dist-packages (4.5.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdFVYPVQTbit",
        "outputId": "459372b3-bc6b-4475-f6de-d261dc74972d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
            "    num_rows: 416\n",
            "}) \n",
            " Je sens qu'entre ça et les films de médecins et scientifiques fous que nous avons déjà vus, nous pourrions emprunter un autre chemin pour l'origine. \n",
            " [11, 16, 5, 2, 11, 9, 8, 0, 2, 0, 9, 0, 6, 11, 11, 17, 14, 16, 1, 11, 16, 16, 8, 6, 0, 2, 8, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "## 1. load the dataset\n",
        "def map_id_to_UPOS(example):\n",
        "    mapper = ['NOUN', 'PUNCT', 'ADP', 'NUM', 'SYM', 'SCONJ', 'ADJ', 'PART', 'DET', 'CCONJ', 'PROPN', 'PRON', 'X', '_', 'ADV', 'INTJ', 'VERB', 'AUX']\n",
        "    example[\"upos\"] = [mapper[tag_id] for tag_id in example[\"upos\"]]\n",
        "    return example\n",
        "\n",
        "corpus = datasets.load_dataset(\"universal_dependencies\", \"fr_gsd\")\n",
        "corpus = corpus.map(map_id_to_UPOS)\n",
        "\n",
        "train_data = corpus[\"train\"]\n",
        "dev_data = corpus[\"validation\"]\n",
        "test_data = corpus[\"test\"]\n",
        "print(test_data,'\\n', test_data['text'][0],'\\n', test_data['upos'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIdvw9AlQI0R"
      },
      "source": [
        "**Implement the `compute_accuracy` function:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8i5EHVGNQDJu"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(test_data, predictions):\n",
        "    \"\"\"\n",
        "    Computes token-level accuracy for\n",
        "\n",
        "    parameters:\n",
        "        test_data: Dataset object\n",
        "        predictions: list of list of tags\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    n = 0\n",
        "    n_good = 0\n",
        "    for t, p in zip(test_data, predictions):\n",
        "\n",
        "        test = map_id_to_UPOS(t)\n",
        "        for x, y in zip(test['upos'], p):\n",
        "          n+=1\n",
        "          if x == y:\n",
        "            n_good += 1\n",
        "    return n_good / n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "6V8CXaoeTrGc"
      },
      "outputs": [],
      "source": [
        "def test_baseline(train_data, test_data) :\n",
        "    baseline = BaselineTagger()\n",
        "    baseline.train(train_data)\n",
        "\n",
        "    test_sentences = [sentence[\"tokens\"] for sentence in test_data]\n",
        "\n",
        "    accuracy = compute_accuracy(test_data, baseline.predict_corpus(test_sentences))\n",
        "    print(f\"Baseline accuracy: {accuracy}, expected result ~= 90.8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wQzdUYFTZ21",
        "outputId": "29ac11c9-a104-49e1-fa5a-28f62321b221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 0.8934744610604001, expected result ~= 90.8\n"
          ]
        }
      ],
      "source": [
        "## 3. run the test\n",
        "test_baseline(train_data, test_data)    # test the baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6pzycOOASwQ0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geZ-xW31Wrsb"
      },
      "source": [
        "## HiddenMarkovModel virterbi implementation\n",
        "\n",
        "1. Implement the `viterbi` function for the `HiddenMarkovModel` class. The function should return the best sequence of tags (see inline documentation for details).\n",
        "\n",
        "\n",
        "2. Test your code by using the `test_viterbi()` function (evaluation on short examples).\n",
        "\n",
        "3. If everything goes well, you can evaluate the tagger on the whole corpus. by uncommenting the line test_tagger(train data, test data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ksG_kFYTXf39"
      },
      "outputs": [],
      "source": [
        "### 1. Implement the viterbi funtion\n",
        "def viterbi(self, transitions, emissions) :\n",
        "  \"\"\"\n",
        "  Uses the Viterbi algorithm to compute the best sequence\n",
        "  of tags for a given sentence.\n",
        "\n",
        "  parameters:\n",
        "      transitions : dict of dicts such that\n",
        "          transitions[previous_tag][tag] contains log(P(tag | previous_tag))\n",
        "\n",
        "      emissions : dict list such that\n",
        "          emissions[i][tag] contains log(P(w_i | tag))    (where w_i is the i^th token in the sentence\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  n_classes = len(self.tags)   # number of labels\n",
        "  n_words = len(emissions)     # length of sentence\n",
        "\n",
        "  # stores the weights of paths (initialized to -inf)\n",
        "  scores = np.zeros((n_classes, n_words), dtype = float) - np.inf\n",
        "\n",
        "  # backtrack will store pointers to recover the best paths\n",
        "  backtrack = np.zeros((n_classes, n_words), dtype = int) - 1\n",
        "\n",
        "\n",
        "  tags = list(emissions[0].keys())\n",
        "\n",
        "  for i in range(n_classes):\n",
        "      scores[i][0] = transitions[START][tags[i]] + emissions[0][tags[i]]\n",
        "\n",
        "  for j in range(1,n_words):\n",
        "      for i in range(n_classes):\n",
        "          maxi, index =  -np.inf, 0\n",
        "          for k, tag in enumerate(tags):\n",
        "              v = transitions[tag][tags[i]] + emissions[j][tags[i]] + scores[k][j-1]\n",
        "              if v > maxi:\n",
        "                  maxi, index = v, k\n",
        "          scores[i][j] = maxi\n",
        "          backtrack[i][j] = index\n",
        "\n",
        "  maxi, index =  -np.inf, 0\n",
        "  for k, tag in enumerate(tags):\n",
        "      v = transitions[tag][END] + scores[k][n_words-1]\n",
        "      if v > maxi:\n",
        "          maxi, index = v, k\n",
        "\n",
        "  res = [tags[index]]\n",
        "  for i in range(n_words-1, 0, -1):\n",
        "      res.append(tags[backtrack[index][i]])\n",
        "      index = backtrack[index][i]\n",
        "\n",
        "  res.reverse()\n",
        "  return res\n",
        "\n",
        "HiddenMarkovModel.viterbi = viterbi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tQ1a4__4SxAD"
      },
      "outputs": [],
      "source": [
        "def pretrainedHMM() :\n",
        "    tagger = HiddenMarkovModel()\n",
        "    tagger.transitions = {'V': {END: -18.420680743952367, 'V': -18.420680743952367, 'D': -0.69314720555994502, 'N': -18.420680743952367, 'P': -0.69314720555994502}, 'N': {'V': -0.69314719305994521, END: -0.69314719305994521, 'D': -18.420680743952367, 'N': -18.420680743952367, 'P': -18.420680743952367}, START: {END: -18.420680743952367, 'V': -18.420680743952367, 'D': -2.4999999716474007e-08, 'N': -18.420680743952367, 'P': -18.420680743952367}, 'P': {END: -18.420680743952367, 'V': -18.420680743952367, 'D': -4.9999998614658012e-08, 'N': -18.420680743952367, 'P': -18.420680743952367}, 'D': {END: -18.420680743952367, 'V': -18.420680743952367, 'D': -18.420680743952367, 'P': -18.420680743952367, 'N': -1.2499999891134309e-08}}\n",
        "    tagger.emissions =  {'V': {'mange': -0.69314723555994395, 'pomme': -18.420680743952367, 'dort': -0.69314723555994395, 'la': -18.420680743952367, 'le': -18.420680743952367, 'chien': -18.420680743952367, UNKNOWN: -18.420680743952367, 'chat': -18.420680743952367, 'dans': -18.420680743952367, 'cuisine': -18.420680743952367, 'une': -18.420680743952367}, 'D': {'mange': -18.420680743952367, 'pomme': -18.420680743952367, 'dort': -18.420680743952367, 'la': -1.3862943886198902, 'le': -0.69314720805994501, 'chien': -18.420680743952367, UNKNOWN: -18.420680743952367, 'chat': -18.420680743952367, 'dans': -18.420680743952367, 'cuisine': -18.420680743952367, 'une': -1.3862943886198902}, 'P': {'mange': -18.420680743952367, 'pomme': -18.420680743952367, 'dort': -18.420680743952367, 'la': -18.420680743952367, 'le': -18.420680743952367, 'chien': -18.420680743952367, UNKNOWN: -18.420680743952367, 'chat': -18.420680743952367, 'dans': -1.0999999394618015e-07, 'cuisine': -18.420680743952367, 'une': -18.420680743952367}, 'N': {'mange': -18.420680743952367, 'pomme': -1.3862943886198902, 'dort': -18.420680743952367, 'la': -18.420680743952367, 'cuisine': -1.3862943886198902, 'chien': -1.3862943886198902, UNKNOWN: -18.420680743952367, 'chat': -1.3862943886198902, 'dans': -18.420680743952367, 'le': -18.420680743952367, 'une': -18.420680743952367}}\n",
        "    tagger.tags= ['D', 'N', 'P', 'V']\n",
        "    return tagger\n",
        "\n",
        "\n",
        "def test_viterbi() :\n",
        "    print(\"Test viterbi function: \")\n",
        "    tagger = pretrainedHMM()\n",
        "    sentences = [sentence.split() for sentence in [\"le chat mange une pomme\", \"le chien dort dans la cuisine\"]]\n",
        "    tags      = [t.split() for t in [\"D N V D N\", \"D N V P D N\"]]\n",
        "    for i,sentence in enumerate(sentences):\n",
        "        print(sentence, \" : \")\n",
        "        print(f\"Prediction      : {tagger.predict(sentence)}\")\n",
        "        print(f\"Expected result : {tags[i]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ1qv_yvSxIt",
        "outputId": "d8df2d87-3dec-4fd9-e603-fe2728d2d1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test viterbi function: \n",
            "['le', 'chat', 'mange', 'une', 'pomme']  : \n",
            "Prediction      : ['D', 'N', 'V', 'D', 'N']\n",
            "Expected result : ['D', 'N', 'V', 'D', 'N']\n",
            "['le', 'chien', 'dort', 'dans', 'la', 'cuisine']  : \n",
            "Prediction      : ['D', 'N', 'V', 'P', 'D', 'N']\n",
            "Expected result : ['D', 'N', 'V', 'P', 'D', 'N']\n"
          ]
        }
      ],
      "source": [
        "test_viterbi()  # test the viterbi algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "VD-sM3MKXVG0"
      },
      "outputs": [],
      "source": [
        "def test_tagger(train_data, test_data, smooth=1e-7) :\n",
        "    print(\"Test tagger\")\n",
        "    print(f\"Train corpus size (number of sentences): {len(train_data)}\")\n",
        "    print(f\"Test corpus size (number of sentences): {len(test_data)}\")\n",
        "\n",
        "    print(\"Training HMM...\")\n",
        "    tagger = HiddenMarkovModel()\n",
        "    tagger.train(train_data, smooth)\n",
        "\n",
        "    print(\"HMM evaluation ...\")\n",
        "    test_sentences = [sentence[\"tokens\"] for sentence in test_data]\n",
        "    predictions = tagger.predict_corpus(test_sentences)\n",
        "    accuracy = compute_accuracy(test_data, predictions)\n",
        "    print(f\"Accuracy = {accuracy} , Expected result: > 93%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "R07gsjHIXVNS",
        "outputId": "3ac931b0-5645-44de-d89c-3d017da728b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test tagger\n",
            "Train corpus size (number of sentences): 14449\n",
            "Test corpus size (number of sentences): 416\n",
            "Training HMM...\n",
            "HMM evaluation ...\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-56c642df9919>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# evaluate the tagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-41718251a898>\u001b[0m in \u001b[0;36mtest_tagger\u001b[0;34m(train_data, test_data, smooth)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HMM evaluation ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtest_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy = {accuracy} , Expected result: > 93%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-880652092470>\u001b[0m in \u001b[0;36mpredict_corpus\u001b[0;34m(self, list_of_sentences)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mPerform\u001b[0m  \u001b[0mpredictions\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist_of_sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-880652092470>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mPerform\u001b[0m  \u001b[0mpredictions\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist_of_sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-880652092470>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \"\"\"\n\u001b[1;32m     44\u001b[0m         \u001b[0memissions_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUNKNOWN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m \u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviterbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memissions_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-d2064ea4c86d>\u001b[0m in \u001b[0;36mviterbi\u001b[0;34m(self, transitions, emissions)\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mmaxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbacktrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "smooth=1e-7\n",
        "test_tagger(train_data, test_data,smooth)      # evaluate the tagger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06K3CI_tZNyI"
      },
      "source": [
        "## Additional questions (go as fas as possible!):\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqTdgUnPZzUR"
      },
      "source": [
        "1. Test different values for the smoothing of probabilities and check how this impacts results on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O6dn068ZyOU"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKRqYcA7Z3Mw"
      },
      "source": [
        "2. Write a function that computes a confusion matrix that takes as input (i) the evaluation corpus (ii) the predicted sequences for the evaluation corpus. Test your function, what are the main types of mistakes made by the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPaUyXs8Z1z3"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pht7eZpOZ8Ry"
      },
      "source": [
        "We now want to evaluate the HMM model on a different task: named entity recognition (NER), on the CONLL-2003 dataset, a standard English benchmark for this task.\n",
        "\n",
        "To do so, load the copus using the following lines:\n",
        "\n",
        "```\n",
        "corpus = datasets.load_dataset(\"conllpp\")\n",
        "corpus = corpus.map(map_id_to_NER_TAGS)\n",
        "```\n",
        "\n",
        "And, write an evaluation function that computes the F1 score (standard\n",
        "evaluation metric for NER).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dRPUgtDaSIv"
      },
      "outputs": [],
      "source": [
        "def map_id_to_NER_TAGS(example):\n",
        "    mapper = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
        "    example[\"upos\"] = [mapper[tag_id] for tag_id in example[\"ner_tags\"]]\n",
        "    return example\n",
        "\n",
        "corpus = datasets.load_dataset(\"conllpp\")\n",
        "corpus = corpus.map(map_id_to_NER_TAGS)\n",
        "\n",
        "train_data = corpus[\"train\"]\n",
        "dev_data = corpus[\"validation\"]\n",
        "test_data = corpus[\"test\"]\n",
        "\n",
        "## TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI4pazYjaiZf"
      },
      "outputs": [],
      "source": [
        "##TODO compute_f1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
